{
  "Breast-shaped hill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eiffel Tower replicas and derivatives": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Folly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gravity hill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of cities claimed to be built on seven hills": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of micronations": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of tautological place names": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phantom island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pizza farm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Recursive islands and lakes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rocket garden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spite house": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Valeriepieris circle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Abuja Airplane House": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Akon City": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bir Tawil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blue Desert": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boulders Beach": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Congo Pedicle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dallol (hydrothermal system)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gaet'ale Pond": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jacob's Ladder (Saint Helena)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kalakuta Republic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lake Nyos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mauritania Railway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oklo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Palácio de Ferro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Peñón de Vélez de la Gomera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Republic of Benin (1967)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Socotra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "La Tante DC10 Restaurant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tromelin Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Owl House (museum)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Umoja, Kenya": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blood Falls": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mawson Peak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "McMurdo Dry Valleys": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marie Byrd Land": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New Swabia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pole of Inaccessibility research station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Villa Las Estrellas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "798 Art Zone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aoshima, Ehime": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Artsvashen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Atar, Padang Ganting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bust of Ferdinand Marcos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Camp Bonifas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chao Mae Tuptim shrine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christmas Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dahala Khagrabari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Darvaza gas crater": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dhekelia Power Station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Diomede Islands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gangkhar Puensum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gate Tower Building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hallstatt (China)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Haesindang Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hanazono Room": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Hằng Nga Guesthouse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Imsil Cheese Theme Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jackson Hole, China": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jatinga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jaxa (state)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jewish Autonomous Oblast": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kabul synagogue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kai Tak Airport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Karni Mata Temple": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kijong-dong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Daeseong-dong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Korea Central Zoo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kowloon Walled City": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Li's field": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Living root bridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Love Land (South Korea)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Maijishan Grottoes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Masuleh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Missing Post Office": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nahwa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nakhchivan Autonomous Republic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nanjie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "National Fisheries Development Board building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "North Sentinel Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Japan National Route 339": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neutrality Monument": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Okinoshima (Fukuoka)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ōkunoshima": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Om Banna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Omsk Metro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peanut Hole": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Porcelain Palace": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rednaxela Terrace": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robot Building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roopkund": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ryugyong Hotel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "San Serriffe": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Sansha": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kingdom of Sedang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Seikan Tunnel Tappi Shakō Line": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shani Shingnapur": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shingō, Aomori": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Snake Temple": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sokh District": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taiwan Province, People's Republic of China": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tashirojima": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thames Town": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thimmamma Marrimanu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tomb of Suleyman Shah": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trunyan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tsu Station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Underground City (Beijing)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Villaggio Mall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wonderland Amusement Park (Beijing)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "X-Seed 4000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Yongning Pagoda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zhangye National Geopark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zheltuga Republic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Abode of Chaos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ängelholm UFO memorial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Argleton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Baarle-Hertog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Baarle-Nassau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Barack Obama Plaza": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barcelona Supercomputing Center": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barentsburg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barra Airport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battersea Power Station tube station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beans and Bacon mine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Berlin Brandenburg Airport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bielefeld conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Brennender Berg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Broomway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brusio spiral viaduct": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bucket Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bunkers in Albania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Büsingen am Hochrhein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Butt Hole Road": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Buzludzha monument": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carpatho-Ukraine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cerne Abbas Giant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clachan Bridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colletto Fava": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cologne sewerage system": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Couto Misto": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crinkley Bottom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Crooked House": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crooked Forest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dancing House": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dartmouth railway station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dumb Woman's Lane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ebenezer Place, Wick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eichener See": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Muzeon Park of Arts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fr. Pat Noise plaque": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Ferdinand Cheval": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Graham Island (Mediterranean Sea)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flannan Isles Lighthouse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Forest swastika": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Free State of Bottleneck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fugging, Upper Austria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Galešnjak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gammalsvenskby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Graun im Vinschgau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Great Tower Neuwerk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Greetings from Jerusalem Avenue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gropecunt Lane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grūtas Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gutsbezirk Reinhardswald": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Icelandic Phallological Museum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "JASON reactor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kielce Bus Station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kőbánya cellar system": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Krzywy Domek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kursdorf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lacus Curtius": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lahn, Hesse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lake Karachay": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Leaning Tower of Suurhusen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of destroyed landmarks in Spain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Listenbourg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Llandegley International Airport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Llanfairpwllgwyngyll": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lupanar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Magic Roundabout (Hemel Hempstead)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manneken Pis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Märket": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metro-2": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Monte Kaolino": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mount Athos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Municipalities of Liechtenstein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Museum of Broken Relationships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nelson's Pillar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neutral Moresnet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Newhaven Marine railway station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Other World Kingdom": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Paradiskullen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pheasant Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Piața Romană metro station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pierre-sur-Haute military radio station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Principality of Sealand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Punkendeich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reality Checkpoint": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Röstigraben": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Saatse Boot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schwerbelastungskörper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Scottish Court in the Netherlands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sedlec Ossuary": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sexi (Phoenician colony)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shell Grotto, Margate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shit Museum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shitterton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smallest House in Great Britain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sovereign Military Order of Malta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spreuerhofstraße": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Svalbard Global Seed Vault": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Transnistria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uffington White Horse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unst Bus Shelter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uppland Runic Inscription 53": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vatican Railway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vennbahn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Veyshnoria": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Victor Noir": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Weißwurstäquator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "White's": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whip-Ma-Whop-Ma-Gate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wooden Spoons Museum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wrocław Dwarfs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zeitpyramide": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Željava Air Base": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Zone rouge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Americana, São Paulo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cancún Underwater Museum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cândido Godói": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cherán": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colonia Dignidad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Darién Gap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Devil's Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ernst Thälmann Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Guarapari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Guianas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fordlândia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Friendship Park (San Diego–Tijuana)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hacienda Nápoles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Isla Apipé": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Island of the Dolls": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Lennon Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lençóis Maranhenses National Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nazca lines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "El Ojo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Parícutin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pig Beach": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plymouth, Montserrat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Presidente Hayes Department": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Río Rico, Tamaulipas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Santa Cruz del Islote": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spiral Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Y Wladfa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yungas Road": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Norfolk Southern–Gregson Street Overpass": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "33 Thomas Street": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sentinel Peak (Arizona)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Agloe, New York": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alcohol and Drug Abuse Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aroma of Tacoma": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aquarius Reef Base": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Badlands Guardian": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Beatosu and Goblu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Borscht Belt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Big Blue Bug": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bishop Castle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bubblegum Alley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bubbly Creek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bullfrog County, Nevada": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Busta Rhymes Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Canusa Street": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Capitol Hill mystery soda machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cat Girl Manor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Centralia, Pennsylvania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clinton Road (New Jersey)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colma, California": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Conch Republic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Corporation Trust Center": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crash at Crush": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crazy Horse Memorial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cuyahoga River": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dave Thomas Circle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dixie Square Mall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Donald J. Trump State Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dorset, Minnesota": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dude Chilling Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fenelon Place Elevator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Florence Y'all Water Tower": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of former counties, cities, and towns of Virginia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gann Valley, South Dakota": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Greater Green River Intergalactic Spaceport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Gum Wall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Habitat 67": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hans Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hawaii 2": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Head-Smashed-In Buffalo Jump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hess triangle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Horace Burgess's Treehouse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Interstate 180 (Wyoming)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Interstate 19": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Island of California": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jackass Flats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jerimoth Hill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Oliver Memorial Sewer Plant": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Joker Stairs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Just Room Enough Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lake Peigneur": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Landsat Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of gaps in Interstate Highways": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of canceled Las Vegas casinos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "London Bridge (Lake Havasu City)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "M-185 (Michigan highway)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mary Ellis grave": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Memphis Pyramid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michigan left": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mickey pylon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mill Ends Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mojave phone booth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mountain Home Air Force Base": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mollie's Nipple": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Monowi, Nebraska": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mr. Trash Wheel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Murder Kroger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nataqua Territory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "National Raisin Reserve": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ned Flanders Crossing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Nettilling Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nitt Witt Ridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Northeast Greenland National Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peter Camani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Point Roberts, Washington": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Polar bear jail": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prada Marfa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of pyramid mausoleums in North America": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rabbit Hash, Kentucky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raising of Chicago": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rainbow Farm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Republic of Indian Stream": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Republic of Molossia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "McDonald's Chicago Flagship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rough and Ready, California": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Santa Claus, Arizona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sam Kee Building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Slab City, California": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "S.N.P.J., Pennsylvania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "State of Franklin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "State of Scott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Statue of Lenin (Seattle)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Texas State Highway 165": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Track 61 (New York City)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "U Thant Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "U.S. Route 19 Truck (Pittsburgh)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Truth or Consequences, New Mexico": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Weather Station Kurt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Delaware Wedge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whittier, Alaska": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Winchester Mystery House": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "World's littlest skyscraper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zilwaukee, Michigan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zone of Death (Yellowstone)": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "American Samoa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Baldwin Street": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ball's Pyramid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Banjawarn Station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bayswater Subway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Burning Mountain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cardrona Bra Fence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coober Pedy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Concrete bus shelters in Canberra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Egmont National Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Horizontal Falls": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hundertwasser Toilets": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hunga Tonga–Hunga Haʻapai": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jellyfish Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jervis Bay Territory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kalawao County, Hawaii": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kingman Reef": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Macquarie Island": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Montague Street Bridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mount Wycheproof": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Murray Valley Highway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nelson–Blenheim notional railway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "State Highway 78 (New Zealand)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ninety Mile Beach, New Zealand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Octopolis and Octlantis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Palmyra Atoll": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pitcairn Islands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pink Lake (Western Australia)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Princes Freeway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puncak Jaya": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sandy Island, New Caledonia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "That Wānaka Tree": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Taumatawhakatangi­hangakoauauotamatea­turipukakapikimaunga­horonukupokaiwhen­uakitanatahu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Te Urewera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whanganui River": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wedding Cake Rock": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whangamōmona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bal des Ardents": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Burned house horizon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cadaver Synod": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Cagot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Complaint tablet to Ea-nāṣir": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Criterion of embarrassment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Daughter of Emperor Xiaoming of Northern Wei": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elagabalus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Erfurt latrine disaster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colleoni": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John I of France": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kottabos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Máel Brigte of Moray": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nika riots": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Onfim": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phantom time conspiracy theory": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Pope Benedict IX": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pre-Columbian transoceanic contact theories": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Publius Afranius Potitus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Roland the Farter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sacred Band of Thebes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sanitation of the Indus Valley Civilisation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sino-Roman relations": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Affair of the Sausages": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Architecture terrible": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles II of Spain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Curonian colonisation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dancing plague of 1518": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Darien scheme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Defenestrations of Prague": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Timothy Dexter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "False Dmitry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Glass delusion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gilles de Rais": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Loveday (1458)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Makassan contact with Australia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Miracle of 1511": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Mutiny on the Bounty": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Order of the Pug": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George Psalmanazar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Crown Prince Sado": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yasuke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Watermelon Riot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Andrew Johnson's drunk vice-presidential inaugural address": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Kinjirō Ashiwara": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "John Bentinck, 5th Duke of Portland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Confederados": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Drapetomania": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Dublin whiskey fire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Johann Georg August Galletti": {
    "real": [
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Great Moon Hoax": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Great Stink": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles J. Guiteau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "History of Liberia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jerome of Sandy Cove": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Kentucky meat shower": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Knights of the Golden Circle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "London Beer Flood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Louis Antoine, Duke of Angoulême": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gregor MacGregor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nongqawuse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Heinrich Schliemann": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William Walker (filibuster)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Are There Men on the Moon?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anti-tobacco movement in Nazi Germany": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eduard Bloch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1980 Spanish embassy burning in Guatemala City": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chewing gum sales ban in Singapore": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Christmas truce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COINTELPRO": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Crocker Land Expedition": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Czechoslovak Togo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Đorđe Martinović incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "East Germany balloon escape": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth, Lady Hope": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dorothy Gibson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Great Michigan Pizza Funeral": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Great Molasses Flood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mango cult": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Masabumi Hosono": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Violet Jessop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Joughin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kilroy was here": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bobby Leach": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Li Guangchang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Madagascar Plan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Francisco Macías Nguema": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MKUltra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moscow Gold (Spain)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Franz Nopcsa von Felső-Szilvás": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "North Hollywood shootout": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Octobering": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kenzō Okuzaki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Paperclip": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emilio Palma": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Assassination of Olof Palme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Punjabi Mexican Americans": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puyi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Radcliffe Line": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rangoon bombing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reggio revolt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mathias Rust": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Satanic Verses controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Self-propelled barge T-36": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Khalid Sheldrake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Shindo Renmei": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Stanley Lord": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Albert Stevens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tanganyika laughter epidemic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ignaz Trebitsch-Lincoln": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tuskegee Syphilis Study": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roman von Ungern-Sternberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States involvement in regime change": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Western New Guinea": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Zegrus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cottage cheese boycott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dean scream": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rudi Dekkers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Great Canadian Maple Syrup Heist": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uday Hussein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Laser Kiwi flag": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Norwegian butter crisis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John P. O'Neill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pepsi fruit juice flood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stellar Wind": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Signed zero": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "0.999...": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2 + 2 = 5": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "616 (number)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "65537-gon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Million Random Digits with 100,000 Normal Deviates": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "All horses are the same color": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Almost everywhere": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Almost integer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Almost periodic function": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Banach–Tarski paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Belphegor's prime": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bertrand's postulate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Calculator spelling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Complexity of Songs": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Cox–Zucker machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Erdős–Bacon number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Extravagant number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gabriel's horn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Graham's number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hairy ball theorem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Happy number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hilbert's paradox of the Grand Hotel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Illegal number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Illumination problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Indiana pi bill": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Infinite monkey theorem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Interesting number paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kruskal's tree theorem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Legendre's constant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Look-and-say sequence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mathematical fallacy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mathematical joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Minkowski's question-mark function": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Monty Hall problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moving sofa problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Narcissistic number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nothing-up-my-sleeve number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Number of the beast": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Numbers station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pi is 3": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Pointless topology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Potato paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ramanujan summation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schizophrenic number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sexy prime": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Six nines in pi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tarski's circle-squaring problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spaghetti sort": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Squircle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taxicab number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tetraphobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Megaprime": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tits group": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Triskaidekaphobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tupper's self-referential formula": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Ulam spiral": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Umbral calculus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unexpected hanging paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unknot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vacuous truth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vampire number": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wheat and chessboard problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Will Rogers phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zenzizenzizenzic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zero-based numbering": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abolition of time zones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ruth Belville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Chrismukkah": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cinnamon Roll Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Festivus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "International Talk Like a Pirate Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of non-standard dates": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Manhattanhenge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mole Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pi Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pocky & Pretz Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Singles' Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Square Root Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Star Wars Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steak and Blowjob Day": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Cake and Cunnilingus Day": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Swatch Internet Time": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thanksgivukkah": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Towel Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Undecimber": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Winterval": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Year 2000 problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Year 2038 problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Year zero": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "-ussy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2002 renaming of Turkmen months and days of week": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Académie de la Carpette anglaise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Antiqua–Fraktur dispute": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Apples and oranges": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Argumentum ad crumenam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Argumentum ad lazarum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Belarusian Arabic alphabet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Book from the Sky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bouba/kiki effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Buffalo buffalo Buffalo buffalo buffalo buffalo Buffalo buffalo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Chaos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chinese characters of Empress Wu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Chinese word for \"crisis\"": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Codex Seraphinianus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Colorless green ideas sleep furiously": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Comparative illusion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Controversies about the word niggardly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crazy English": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cryptophasia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disambiguation (disambiguation)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dord": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dozens (game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Duck test": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "English as She Is Spoke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Engrish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eskimo words for snow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Etaoin shrdlu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Faggin–Nazzi alphabet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Faux Cyrillic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fictitious entry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fnord": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Garden-path sentence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ghoti": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Glossary of Wobbly terms": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hamburgevons": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hopi time controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "How now brown cow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hyphen War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ingressive sound": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Inherently funny word": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Intentionally blank page": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Irony punctuation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Irreversible binomial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James while John had had had had had had had had had had had a better effect on the teacher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Latin obscenity": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Law of holes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "La plume de ma tante (phrase)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lion-Eating Poet in the Stone Den": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of common false etymologies of English words": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of English words containing Q not followed by U": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of English words without rhymes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of ethnic slurs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of proposed etymologies of OK": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of shorthand systems": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Longest word in English": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mamihlapinatapai": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Martian language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "\"Yo mama\" joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "May you live in interesting times": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Metal umlaut": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "My postillion has been struck by lightning": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Mike Alder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nucular": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Phaistos Disc": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Placeholder name": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Pompatus": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Potrzebie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pronunciation of GIF": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RAS syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Response to sneezing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Retroflex click": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Shields (diarist)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rohonc Codex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Scientific wild-ass guess": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scots Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shavian alphabet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shibboleth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shit happens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shm-reduplication": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Spelling of Shakespeare's name": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taito (kanji)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Talk to the hand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tenevil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thagomizer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of linguistic example sentences": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Moon is made of green cheese": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "There is no sex in the USSR": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thinking about the immortality of the crab": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Time flies like an arrow; fruit flies like a banana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Toynbee tiles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tsundoku": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "There are unknown unknowns": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Voynich manuscript": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wine-dark sea (Homer)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yan tan tethera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zhemao hoaxes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zzxjoanw": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Abercraf English": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Algonquian–Basque pidgin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Basque–Icelandic pidgin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anāl language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andalusian language movement": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Antarctic English": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Arcaicam Esperantom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Boontling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Broome Pearling Lugger Pidgin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cia-Cia language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "DoggoLingo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Dravido-Korean languages": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "E-Prime": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "High Tider": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ithkuil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jamaican Maroon Creole": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kebabnorsk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lojban": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mediterranean Lingua Franca": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nicaraguan Sign Language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pandanus language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pirahã language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plains Indian Sign Language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Proto-Human language": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Russenorsk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Silbo Gomero": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Solresol": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Squamish language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toki Pona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ubykh language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wenzhounese": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taa language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yerkish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nominative determinism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amandagamani Abhaya of Anuradhapura": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Arses of Persia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dick Assman": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Harry Baals": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "C. H. D. Buys Ballot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Praise-God Barebone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bishop Bishop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Bong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cesar Chavez (perennial candidate)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Thursday October Christian I": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Seymour Cocks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deportivo Wanka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Donaudampfschiffahrtsgesellschaft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Preserved Fish": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "FM-2030": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gag name": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goodspaceguy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gregor Fučka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Guy Standing (economist)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "John le Fucker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Argel Fuchs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jakob Fugger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "States Rights Gist": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John B. Goodenough": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Curtis Hidden Page": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ima Hogg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Huang Hong-cheng": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christmas Humphreys": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tiny Kox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer 8. Lee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of examples of Stigler's law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Henry Lizardlover": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Seán Dublin Bay Rockall Loftus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Icelandic Naming Committee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adolf Lu Hitler Marak": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mister Mxyzptlk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Names of Soviet origin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Naming law in Sweden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neville Neville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metta Sandiford-Artest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pro-Life (politician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Public Universal Friend": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rinderkennzeichnungs- und Rindfleischetikettierungsüberwachungsaufgabenübertragungsgesetz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tokyo Sexwale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sjokz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mansfield Smith-Cumming": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "M. K. Stalin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Téa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Temple-Nugent-Brydges-Chandos-Grenville, 3rd Duke of Buckingham and Chandos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Leone Sextus Tollemache": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tonibler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turnipseed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hubert Blaine Wolfeschlegelsteinhausenbergerdorff Sr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Marijuana Pepsi Vandyck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Osama Vinladen": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Vladimiro Montesinos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bumpy Bumpus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Archaeoacoustics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Airborne radioactivity increase in Europe in autumn 2017": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ota Benga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beringer's Lying Stones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Buttered cat paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Buttered toast phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Campanology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Claude Émile Jean-Baptiste Litre": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Cneoridium dumosum (Nuttall) Hooker F. Collected March 26, 1960, at an Elevation of about 1450 Meters on Cerro Quemazón, 15 Miles South of Bahía de Los Angeles, Baja California, México, Apparently for a Southeastward Range Extension of Some 140 Miles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vladimir Demikhov": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Drake's Plate of Brass": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Elvis taxon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Further research is needed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gilbert U-238 Atomic Energy Laboratory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Greeble (psychology)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lazarus taxon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Ig Nobel Prize winners": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nylon-eating bacteria and creationism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "'Pataphysics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Archaeological interest of Pedra da Gávea": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Pathological science": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Project Steve": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raven paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sokal affair": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Timeline of the far future": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Halomonas titanicae": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "John G. Trump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Women-are-wonderful effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anatoli Bugorski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colors of noise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Hahn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Demon core": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deutsche Physik": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "F. D. C. Willard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "List of fictional elements, materials, isotopes and subatomic particles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Fourth, fifth, and sixth derivatives of position": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flying ice cube": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Frog battery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Impossible color": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kundt's tube": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of unusual units of measurement": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mpemba effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oh-My-God particle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pauli effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Quantum suicide and immortality": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vortex tube": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rheology of peanut butter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shower-curtain effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smoot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Chalkboard scraping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Hum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nicolia aegyptiaca": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Andrée's Arctic balloon expedition": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ararat anomaly": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bloop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catatumbo lightning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Floyd Collins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Continental drip": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Expanding Earth": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Gore effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Hector (cloud)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of unexplained sounds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2006 Mumbai sweet seawater incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Rain of animals": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Red rain in Kerala": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Snow in Florida": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "South-up map orientation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roy Sullivan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tinnunculite": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Waffle House Index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "9,10-Dithioanthracene": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Botulinum toxin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "26th Congress of the Communist Party of the Soviet Union (diamond)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Dihydrogen monoxide parody": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Elephant's Foot (Chernobyl)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fogbank": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goiânia accident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of chemical compounds with unusual names": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thomas Midgley Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NanoPutian": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New car smell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nitrogen triiodide": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Orotidine 5'-phosphate decarboxylase": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pitch drop experiment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James Price (chemist)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pykrete": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smell of freshly cut grass": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thiotimoline": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Trimethylaminuria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unobtainium": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "1561 celestial phenomenon over Nuremberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Apollo 15 postal covers incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blue Origin Federation, LLC v. United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Judith Love Cohen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cosmic latte": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cydonia (Mars)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edward Makuka Nkoloso": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elon Musk's Tesla Roadster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Embryo space colonization": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Extraterrestrial real estate": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fallen Astronaut": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fe, Fi, Fo, Fum, and Phooey": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Finger of God Globule": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gauss's Pythagorean right triangle proposal": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Harlan J. Smith Telescope": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hot, dust-obscured galaxy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "International Space Station cannabis experiment hoax": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Jovian–Plutonian gravitational effect": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of hypothetical Solar System objects": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lunarcrete": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mars Climate Orbiter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matrioshka brain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andromeda–Milky Way collision": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mimas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moon landing conspiracy theories": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moon Museum": {
    "real": [
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Nazi UFOs": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Nuclear pasta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peryton (astronomy)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Seatbelt basalt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sex in space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Solway Firth Spaceman": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Space advertising": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Space elevator competitions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spaghettification": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Space Poop Challenge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Space selfie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stolen and missing Moon rocks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Supermoon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sylacauga (meteorite)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tabby's Star": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Timekeeping on Mars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vatican Observatory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Voyager Golden Record": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "274301 Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wow! signal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Writing in space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "IPTF14hls": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Accessory breast": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alien hand syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anal wink": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Auto-brewery syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Banana equivalent dose": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black hairy tongue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bristol stool scale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ChIA-PET": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chronic Lyme disease": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Coffee enema": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Danger triangle of the face": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dimples of Venus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "DNA origami": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RNA origami": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dr. Young's Ideal Rectal Dilators": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eigengrau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fart lighting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fiddler's neck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Five-second rule": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Geographic tongue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gynecomastia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hair-grooming syncope": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Human–animal breastfeeding": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hypertrichosis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hypoalgesic effect of swearing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jenkem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Fissure of the nipple": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Louse-feeder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lucky iron fish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maggot therapy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Male lactation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maple syrup urine disease": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Medical students' disease": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mellified man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Michelin tire baby syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Moebius syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mucophagy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nacirema": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Lint (material)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nasal sebum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Old person smell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Osteo-odonto-keratoprosthesis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paleofeces": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peanut butter test": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Photic sneeze reflex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pneumonoultramicroscopicsilicovolcanoconiosis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Powder of sympathy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Rapunzel syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Resting bitch face": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Retained surgical instruments": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schmidt sting pain index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Supernumerary nipple": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Takotsubo cardiomyopathy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thumb twiddling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Traditional Chinese medicines derived from the human body": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trepanning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uncombable hair syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "White-nose syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Autocunnilingus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Autofellatio": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Armin Meiwes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bathroom sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bread dildo": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Cello scrotum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Orgasm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death during consensual sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Donkey punch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "Female hysteria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Footsies": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gerbilling": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Annual Global Orgasm for Peace": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hamster zona-free ovum test": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Human penis size": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Koro (disease)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lithopedion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Male pregnancy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Napoleon's penis": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "National Masturbation Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Parasitic twin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Persistent genital arousal disorder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Post-coital tristesse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puppy pregnancy syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Rumpology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Scrotal inflation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Self-inflicted caesarean section": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sexual headache": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sleep sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smoking fetishism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Soggy biscuit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Zombie pornography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elisabeth Anderson Sierra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jaxon Buell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeanne Calment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Legrand G. Capers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Stubbins Ffirth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Phineas Gage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Genie (feral child)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James Harrison (blood donor)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abby and Brittany Hensel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul Karason": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Benjaman Kyle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eugene Landy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hans Langseth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Liston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barry Marshall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alexis St. Martin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lina Medina": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Billy Milligan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wenceslao Moguel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blanche Monnier": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mariam Nabatanzi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chandre Oram": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Adam Rainer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tarrare": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mary Toft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Wadlow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alice in Wonderland syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anton syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bananadine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bicameral mentality": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Capgras delusion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cortical homunculus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cotard's syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Conversion disorder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cute aggression": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dancing mania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Electromagnetic hypersensitivity": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Encopresis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Exploding head syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Expressive aphasia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "False memory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dissociative fugue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Foreign accent syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fregoli delusion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Geophagia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sleepwalking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jumping Frenchmen of Maine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Klüver–Bucy syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mariko Aoki phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Paris syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rosenhan experiment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Somatoparaphrenia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stendhal syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Target fixation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tip of the tongue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Truman Show delusion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Urophagia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Visual release hallucinations": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zero stroke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Aversion to happiness": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chromophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coprophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dental fear": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emetophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Balloon phobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Genuphobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Koumpounophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mageiricophobia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Numerophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Osmophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phallophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Philophobia (fear)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phobophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pogonophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Submechanophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Technophobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Telephone phobia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adactylidium": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Animals in space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Animal attack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anting (behavior)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Apophallation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bee removal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blast fishing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Candiru (fish)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carcinisation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Common Surinam toad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Conservation-induced extinction": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Depopulation of cockroaches in post-Soviet states": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Cat–dog relationship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cymothoa exigua": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Epomis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eunice aphroditois": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goblin shark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goldfish swallowing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hallucinogenic fish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hebrew character": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Hotwheels sisyphus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Hurricane Shark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Israel-related animal conspiracy theories": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jenny Haniver": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lioconcha hieroglyphica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of animals displaying homosexual behavior": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of animal sounds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of animals awarded human credentials": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "London Underground mosquito": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Love dart": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lyall's wren": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metoecus paradoxus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uguisu no fun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Orbiting Frog Otolith": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paracerceis sculpta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pasilalinic-sympathetic compass": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Penis fencing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prostitution among animals": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Rotating locomotion in living systems": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shortarse feelerfish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Supernumerary body part": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Traumatic insemination": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trout tickling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Uraba lugens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Worm charming": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bonsai Kitten": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Cat burning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cats That Look Like Hitler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Demon Cat": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Odd-eyed cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pittsburgh refrigerator cat": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Popular cat names": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Polydactyl cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ray cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cow tipping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Craven Heifer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hardware disease": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cannibalism in poultry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken eyeglasses": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken Dance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken gun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken hypnotism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken or the egg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chick sexing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blue Peacock": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Empathy in chickens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tastes like chicken": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Arctic ground squirrel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Electrical disruptions caused by squirrels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Squirrel fishing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Squirrels on college campuses": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ambergris": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Berserk llama syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Husum Red Pied": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deer penis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Diving horse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The dog ate my homework": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Domesticated silver fox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Exploding whale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fainting goat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flying primate hypothesis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Globster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Guided rat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "House hippo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Human": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New Guinea singing dog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Overtoun Bridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Panda pornography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Quokka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Revival of the woolly mammoth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rhinogradentia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Skunks as pets": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Street dogs in Moscow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Weasel war dance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "What Is It Like to Be a Bat?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whale fall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "52-hertz whale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adwaita": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andy (goose)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Ken Allen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Benson (fish)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bubbles (chimpanzee)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Casper (cat)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Clever Hans": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cocaine Bear (bear)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Conan (Javier Milei's dog)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Domino Day 2005 sparrow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Dusty the Klepto Kitty": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Enumclaw horse sex case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fungie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gef": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "George (lobster)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Grape-kun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grumpy Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hachikō": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harambe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry the Hexapus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hoover (seal)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jack (baboon)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jackie (dog)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jeremy (snail)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Joe the Pigeon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Jonathan (tortoise)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Khanzir": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lily Flagg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lion of Gripsholm Castle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lonesome George": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Long Boi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mayor Max II": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mike the Headless Chicken": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ming (clam)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nim Chimpsky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nils Olav": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oscar (therapy cat)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Owen and Mzee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul the Octopus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Potoooooooo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Penelope (platypus)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ravens of the Tower of London": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "River Thames whale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sergeant Reckless": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stubbs (cat)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tamworth Two": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tillamook Cheddar (dog)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Timothy (tortoise)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tombili": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turra Coo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ubre Blanca": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unsinkable Sam": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vacanti mouse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whitney Chewston": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "William Windsor (goat)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Wojtek (bear)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abul-Abbas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hanno (elephant)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jumbo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lin Wang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mary (elephant)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Osama bin Laden (elephant)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Topsy (elephant)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aha ha": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anophthalmus hitleri": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aptostichus barackobamai": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aptostichus stephencolberti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bill Gates' flower fly": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Colon (beetle)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gamergate (ant)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Madidi titi monkey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Harryplax": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kimjongilia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kinda baboon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mini (frog)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mothers against decapentaplegic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Leptodactylus fallax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neopalpa donaldtrumpi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pachygnatha zappa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pikachurin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Setaceous Hebrew character": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Covered smut (barley)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sonic hedgehog protein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spongiforma squarepantsii": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Strigiphilus garylarsoni": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Synalpheus pinkfloydi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thaumatodryinus tuukkaraski": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Zombie taxon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zoosphaerium darthvaderi": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Zyzyxia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tubular sponge hydroid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Spiralix heisenbergi": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bialbero di Casorzo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chandelier Tree": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Echinopsis lageniformis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eisenhower Tree": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Golfballia ambusta": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Olympic oaks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Moon tree": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nepenthes lowii": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mimosa pudica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Old Man of the Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pando (tree)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plant arithmetic": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Plant rights": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Pomato": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Radiotrophic fungus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Tendril perversion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tree of Knowledge (Australia)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tree of Ténéré": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tree That Owns Itself": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "300-page iPhone bill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abraham Lincoln's patent": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Antikythera mechanism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Baby cage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Bild Lilli doll": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blåhaj": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Breakout (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Digesting Duck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Centennial Light": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chindōgu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clock of the Long Now": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clocky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Concealing objects in a book": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Digital sundial": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dreamachine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Electronic voice phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Friendly Floatees spill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gun-powered mousetrap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hitler teapot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Marvin Heemeyer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "History of perpetual motion machines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hitachi Magic Wand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jibba Jabber": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Klerksdorp sphere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Zbigniew Libera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of inventors killed by their own invention": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Love chair": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mengenlehreuhr": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moo box": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mosquito laser": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Museum of Failure": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "My Friend Cayla": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "One red paperclip": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Parking chair": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pigeon photography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Predictions of the end of Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Project Cybersyn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pythagorean cup": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Quartz crisis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Radio hat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Royal Mail rubber band": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Russian floating nuclear power station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sony timer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Splayd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tempest prognosticator": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turbo encabulator": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Uncanny valley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Useless machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vin Mariani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wrap rage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Xianxingzhe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Committee to End Pay Toilets in America": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Darlie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fatberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Female urination device": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Groom of the Stool": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hotel toilet paper folding": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Interactive urinal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ILoo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Jack Black (rat catcher)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Toilets in Japan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lloyds Bank coprolite": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shit flow diagram": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stainless steel soap": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Toilet-related injuries and deaths": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Toilet papering": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toilet paper orientation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whizzinator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aglet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The dress": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fatsuit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gorilla suit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Koteka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Meat dress of Lady Gaga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Muffin top": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shoe tossing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sweater curse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Three Wolf Moon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tin foil hat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2001 Japan Airlines mid-air incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2003 Angola Boeing 727 disappearance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "2018 Horizon Air Q400 incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aeroflot Flight 593": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Aeroflot Flight 6502": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aloha Airlines Flight 243": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ampelmännchen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amtrak paint schemes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Animals taking public transportation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "AVE Mizar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bayside Canadian Railway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Billups Neon Crossing Signal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boaty McBoatface": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brighton and Rottingdean Seashore Electric Railway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "British Rail flying saucer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "China National Highway 110 traffic jam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Daallo Airlines Flight 159": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cycloped": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dagen H": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deli Mike": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dymaxion car": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Experiment (horse-powered boat)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fastest Shed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ferry Lina": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gadgetbahn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Get Out and Push Railroad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gimli Glider": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Human mail": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Iron Dobbin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jesus nut": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Loose wheel nut indicator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nut rage incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "M-497 Black Beetle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mehran Karimi Nasseri": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Men's parking space": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mile high club": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Miss Belvedere": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MTT Turbine Superbike": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Northwest Airlines Flight 253": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Parliamentary train": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Passenger train toilet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paternoster lift": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peel P50": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pimpmobile": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plastic bicycle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "PZL M-15 Belphegor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reliant Regal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rocket mail": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rolligon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RP FLIP": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schienenzeppelin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "School bus yellow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Screw-propelled vehicle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shipping container architecture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Society for the Prevention of Calling Sleeping Car Porters \"George\"": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "South-pointing chariot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tall bike": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Train surfing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Unused highway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uruguayan Air Force Flight 571": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "USGlobal Airways": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "ValuJet Airlines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reduced-gravity aircraft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vortech Meg-2XH Strap-On": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Wallsend Metro station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Westray to Papa Westray flight": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The wrong type of snow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".bv": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".kp": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".nu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".su": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".tv": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "999 phone charging myth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Any key": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Blinkenlights": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bogosort": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Book of Mozilla": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Brainfuck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brian's Brain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bush hid the facts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Chudnovsky brothers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Creeper and Reaper": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Conway's Game of Life": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Electric unicycle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elvis operator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emojli": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Enshittification": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Esoteric programming language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Evil bit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Guru Meditation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Heisenbug": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hyper Text Coffee Pot Control Protocol": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "I Am Rich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Intelligence Quotient (IQ) and Browser Usage": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Obfuscated C Code Contest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "IP over Avian Carriers": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "ISmell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Leet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lenna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Loab": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Lp0 on fire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Macquarium": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Magic smoke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Million Dollar Homepage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phillips Machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mystery meat navigation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "On the Cruelty of Really Teaching Computer Science": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pentium F00F bug": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reality distortion field": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Red Star OS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rubber duck debugging": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RTFM": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deniable encryption": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scunthorpe problem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Send Me to Heaven": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tay (chatbot)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "TempleOS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trojan Room coffee pot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Utah teapot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yo (app)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Action Park": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Aristocrats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Balloonfest '86": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Baseball metaphors for sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Beezin'": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Bigipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Boys are stupid, throw rocks at them! controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "George P. Burdell": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Caltech–MIT rivalry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Campaign for North Africa": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Conan the Librarian": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Croydon facelift": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Cultural depictions of Napoleon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cultural history of the buttocks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicago rat hole": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Christo and Jeanne-Claude": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dick joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Evil clown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "F.A.T.A.L.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Flash mob": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Frozen Peas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fuck for Forest": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ashrita Furman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Garden hermit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ghost riding": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gongoozler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Great Stork Derby": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gurn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hacks at the Massachusetts Institute of Technology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "He lücht": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Human rainbow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hundeprutterutchebane": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Issei Sagawa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "K Foundation Burn a Million Quid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kayfabe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alvin \"Shipwreck\" Kelly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Killer toy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Kuchisake-onna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Lawnchair Larry flight": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Le Pétomane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lighthouse and naval vessel urban legend": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "List of defunct amusement parks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of games with concealed rules": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of incidents at Walt Disney World": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of stories set in a future now in the past": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Lincoln–Kennedy coincidences urban legend": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Love lock": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MacGuffin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Masturbate-a-thon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metafiction": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miss Bumbum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mooning the Cog": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nazi chic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "No soap radio": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Robert Opel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pass by catastrophe": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Ping pong show": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pen spinning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Purple Aki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Radio Yerevan joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aron Ralston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Real-life superhero": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sardarji joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Self-referential humor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sewer alligator": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Stunting (broadcasting)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Treacle mining": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Tube Bar prank calls": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Umarell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Voluntary Human Extinction Movement": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "When a white horse is not a horse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Willy's Chocolate Experience": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "List of works based on dreams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "World Famous Bushman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "You kids get off my lawn!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "747 (performance art)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "America (Cattelan)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Artist's Shit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Big things (Australia)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Augsburg Book of Miracles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Babylonokia": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Bog Standard Gallery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boll Weevil Monument": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joachim-Raphaël Boronali": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bottle Rack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pierre Brassau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Cabazon Dinosaurs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chamber of Art and Curiosities, Ambras Castle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cool S": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Degenerate Art exhibition": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Dream of the Fisherman's Wife": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Droste effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disumbrationism": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Earring Magic Ken": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ecce Homo (García Martínez and Giménez)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Equestrian statue of the Duke of Wellington, Glasgow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fire photography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fourth plinth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fremont Troll": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gävle goat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Geostationary Banana Over Texas": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Hahn/Cock": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Headington Shark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "He-gassen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hellmouth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hobby tunneling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Howard Hallis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Megumi Igarashi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jazz (design)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Katrina refrigerator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Knitta Please": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kryptos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Latte art": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Latrinalia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Musca depicta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Museum of Bad Art": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emil Nolde": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paintings by Adolf Hitler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pantone 448 C": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phallic architecture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pink Lady (art)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Piss Christ": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Portland International Airport carpet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pricasso": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "La Princesse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Project Graham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abel Ramírez Águilar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Le Rêve (Picasso)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roundabout dog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sacred Cod": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scandinavian Institute of Comparative Vandalism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Seedfeeder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Les songes drolatiques de Pantagruel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Superlambanana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tennis Girl": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hyperart Thomasson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tillie (murals)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tipu's Tiger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trump Buddha": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turnip Prize": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unique Forms of Continuity in Space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William Utermohlen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Les UX": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "101 Uses for a Dead Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Aachi & Ssipak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Acme Corporation": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Afghanis-tan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Archie Meets the Punisher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Archie vs. Predator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Behind Closed Doors (book)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Bobobo-bo Bo-bobo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bring Me the Head of Charlie Brown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cartoon physics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Censored Eleven": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cheat Slayer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Corona-chan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cow tools": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Comic book death": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dennō Senshi Porygon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Der Fuehrer's Face": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ebola-chan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eveready Harton in Buried Treasure": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "List of fictional primates in comics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Homosexuality in the Batman franchise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ISIS-chan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Jenny Everywhere": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kuso Miso Technique": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manga Bible (series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Metric Marvels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moe anthropomorphism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mr. Immortal": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "NFL SuperPro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pinky & Pepper Forever": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pokémon episodes removed from rotation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Popetown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Squirrel and Hedgehog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Syaoran Li": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tentacle erotica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Leader (web series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tiger Mask donation phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Truck-kun": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "*** (novel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "1601 (Mark Twain)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "112 Gripes About the French": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A True Story": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "A Void": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aldiborontiphoskyphorniostikos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Alien space bats": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Anthropodermic bibliopegy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Archaeology, Anthropology, and Interstellar Communication": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Atlanta Nights": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Literary Review": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Betteridge's law of headlines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Big Dumb Object": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Book of Heroic Failures": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bookseller/Diagram Prize for Oddest Title of the Year": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "La Bougie du Sapeur": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bulwer-Lytton Fiction Contest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cain's Jawbone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catullus 16": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Anarchist Cookbook": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Confessions of an English Opium-Eater": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Darger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dinosaur erotica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Death poem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Empty book": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "English-language editions of The Hobbit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Evil laughter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Eye of Argon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fallout: Equestria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fart Proudly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The First Blast of the Trumpet Against the Monstruous Regiment of Women": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fly Fishing: Memories of Angling Days": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "For sale: baby shoes, never worn": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Future Library project": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gadsby (novel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grammarians' War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Harry Potter and the Methods of Rationality": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Hawking Index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Help! Mom! There Are Liberals Under My Bed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hitler Diaries": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Hogwarts School of Prayer and Miracles": {
    "real": [
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "How I Killed Pluto and Why It Had It Coming": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hundred Thousand Billion Poems": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I Am a Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I Am God (novel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I, Libertine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "If Israel Lost the War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Iraq War: A Historiography of Wikipedia Changelogs": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Jennifer Mills News": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Jungle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lajja (novel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lecherous Limericks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Lesbian vampire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lobby Lud": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Lopado­temacho­selacho­galeo­kranio­leipsano­drim­hypo­trimmato­silphio­karabo­melito­katakechy­meno­kichl­epi­kossypho­phatto­perister­alektryon­opte­kephallio­kigklo­peleio­lagoio­siraio­baphe­tragano­pterygon": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Magical Negro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marlovian theory of Shakespeare authorship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "William McGonagall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Men in Aida": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Meaning of Hitler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Yukio Mishima": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mock Turtle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "My Immortal (fan fiction)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "My Life as a 10-Year-Old Boy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Naked Came the Stranger": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Nat Tate: An American Artist 1928–1960": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Old Possum's Book of Practical Cats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Order of the Occult Hand": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "On Bullshit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ossian": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "P Is for Pterodactyl": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Philip M. Parker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Political interpretations of The Wonderful Wizard of Oz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rangila Rasul": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rolling Stone (Uganda)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amanda McKittrick Ros": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Pickle for the Knowing Ones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pinocchio paradox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Print Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Project Mars: A Technical Tale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Saddam Hussein's novels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Satanic Verses": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shakespeare apocrypha": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shakespeare authorship question": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Society of Science, Letters and Art": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Peter Sotos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Striking and Picturesque Delineations of the Grand, Beautiful, Wonderful, and Interesting Scenery Around Loch-Earn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Tale of Two Lovers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "There once was a man from Nantucket": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Time in Tolkien's fiction": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chuck Tingle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Le Train de Nulle Part": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Unfortunates": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whitey on the Moon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Winnie ille Pu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wonders of the East": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "27 Club": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Animutation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Avril Lavigne replacement conspiracy theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Bouncing ball (music)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brian Wilson is a genius": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Characters in Devo music videos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clapton is God": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Clear Channel memorandum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Curse of the ninth": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Dark Side of the Rainbow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Earworm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elvis impersonator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elvis sightings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Fogerty v. Fantasy, Inc.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fyre Festival": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Industrial musical": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jazz ambassadors": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lebenslaute": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of classical music concerts with an unruly audience response": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Literal music video": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Loudness war": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manualism (hand music)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Marilyn Manson–Columbine High School massacre controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metal Open Air": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Millennial whoop": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "More Cowbell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "More popular than Jesus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mozart and scatology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Musikalisches Würfelspiel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "My Way killings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "P-Funk mythology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul is dead": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Pink Floyd pigs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "PopMart Tour": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Division Bell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Nifty Package": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rockism and poptimism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unusual types of gramophone records": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Up to eleven": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uruguayan Invasion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Vestal Masturbation T-shirt": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Whamageddon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Blackbird (violin)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cat organ": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Electroencephalophone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Escopetarra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Great Stalacpipe Organ": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Musical saw": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Piganino": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Ugly stick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Viola jokes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Biomusic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chap hop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chillwave": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christian ska": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Danger music": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Early Norwegian black metal scene": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gothabilly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Grunge speak": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Jihadism and hip hop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kawaii metal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lowercase (music)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pirate metal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Proibidão": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Unblack metal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yu-Mex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "AKB48 Group": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ArnoCorps": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Austrian Death Machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Y. Bhekhirst": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Bis Kaidan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boston Typewriter Orchestra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rosemary Brown (spiritualist)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Buckethead": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bull of Heaven (band)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "GG Allin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "CD Rev": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Death in June": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eva Braun (band)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Damião Experiença": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Matt Farley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Gerogerigegege": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Half Man Half Biscuit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hanatarash": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hatebeak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hatari (band)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joyce Hatto": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bobby Jameson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jandek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Florence Foster Jenkins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kevin MacLeod": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Klaus Nomi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The KLF": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kunt and the Gang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "LadBaby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Laibach": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Merzbow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moondog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MP4 (band)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Okilly Dokilly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "One Pound Fish Man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Panchiko": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Eilert Pilarm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Manson discography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "R. Stevie Moore": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Portsmouth Sinfonia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Les Rallizes Dénudés": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Residents": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rockbitch": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Shaggs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thai Elephant Orchestra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "TISM": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tonetta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tout-à-Coup Jazz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Vegetable Orchestra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Viper (rapper)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Wealdstone Raider": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wesley Willis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gary Wilson (musician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wild Man Fischer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ya Ho Wha 13": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Zimmers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Zombeatles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "A Musical Joke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "As Slow as Possible": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carnival of Light": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cat fugue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Duetto buffo di due gatti": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grosse Fuge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helikopter-Streichquartett": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hans Keller": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I Am Sitting in a Room": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Leck mich im Arsch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Leck mir den Arsch fein recht schön sauber": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Difficile lectu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of musical works in unusual time signatures": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of silent musical compositions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of music considered the worst": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Marinka (operetta)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rage Over a Lost Penny": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Anacreontic Song": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "All Summer Long (Kid Rock song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boris Johnson Is a Fucking Cunt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Camouflage (Chris Sievey song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chocolate Salty Balls": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Do the Bartman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eat Your Salad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "E depois do adeus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Euro-Vision": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Five Per Cent for Nothing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flappie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Give That Wolf a Banana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gloomy Sunday": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hitler Has Only Got One Ball": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Jeg har set en rigtig negermand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Jiggle Jiggle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Justice for All (song)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Lemon Incest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lift Yourself": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lostwave": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Most Mysterious Song on the Internet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The People's Choice: Music": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Never Learn Not to Love": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nyah nyah nyah nyah nyah nyah": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Planet of the Bass": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Poison: Iitai Koto mo Ienai Konna Yo no Naka wa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prisencolinensinainciusol": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ram Ranch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ready 'n' Steady": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rocket Queen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shukusei!! Loli Kami Requiem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Smells Like Nirvana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Supermarioland (song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Suzukake Nanchara": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Teletubbies say \"Eh-oh!\"": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tetris (Doctor Spin song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Timothy (song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "To Be or Not to Be (The Hitler Rap)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "To Me, To You (Bruv)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ulterior Motives (song)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "United Breaks Guitars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "We Didn't Start the Fire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "You Suffer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "You're Pitiful": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "( ) (album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "21½ Minutes in Berlin/23 Minutes in Brussels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Rubber Band Christmas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Altered States of America": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amore (Alessandra Mussolini album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "All Lights Fucked on the Hairy Amp Drooling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Boy Bands Have Won": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Christmas in the Stars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cigarettes and Valentines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dark Night of the Soul (album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elvis' Greatest Shit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Embrace (American band Embrace album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Embrace (English band Embrace album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eurobeat Disney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Everywhere at the End of Time": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Everyday Chemistry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Fucking Cunts Treat Us Like Pricks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Having Fun with Elvis on Stage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helter Stupid": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "In Search of The": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Lillywhite Sessions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Meow the Jewels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Metal Machine Music": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Monty Python Matching Tie and Handkerchief": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mouth Sounds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Musique pour Supermarché": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "No Love Deep Web": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Once Upon a Time in Shaolin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Orgasm (Cromagnon album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Road to Freedom (L. Ron Hubbard album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sleep (album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sleepify": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Smile (The Beach Boys album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sweet Insanity": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Trout Mask Replica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wake Up! (Pope Francis album)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Yesterday and Today": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "3 Dev Adam": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "100 Years (film)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "An Alan Smithee Film: Burn Hollywood Burn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ambiancé": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Atuk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Barbenheimer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Black and white hat symbolism in film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William Castle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cocksucker Blues": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Conqueror (1956 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Cure for Insomnia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Day the Clown Cried": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deafula": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death of a President (2006 film)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dump months": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Empire (1965 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Empires of the Deep": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "First on the Moon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Him (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "I Killed My Lesbian Wife, Hung Her on a Meat Hook, and Now I Have a Three-Picture Deal at Disney": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "In the Aftermath": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Italian Spiderman": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Lee Kin-yan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of films featuring giant monsters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of films featuring time loops": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of films that most frequently use the word fuck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Logistics (film)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Longest Most Meaningless Movie in the World": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maidstone (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Manic Pixie Dream Girl": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manos: The Hands of Fate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Many Faces of Jesus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gay Jesus film hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Mockbuster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Modern Times Forever (Stora Enso Building, Helsinki)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Mystery of the Leaping Fish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Night of the Day of the Dawn of the Son of the Bride of the Return of the Revenge of the Terror of the Attack of the Evil, Mutant, Alien, Flesh Eating, Hellbound, Zombified Living Dead": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Norodom Sihanouk filmography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oscar bait": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "On the Art of the Cinema": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Overcoat (animated film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paint Drying": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Palm Dog Award": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Passage de Vénus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Patterson–Gimlin film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pink Flamingos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plan 9 from Outer Space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pulgasari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shin Sang-ok": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rampart (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rapsittie Street Kids: Believe in Santa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raza (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reefer Madness": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Return of the Ewok": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Roar (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Room": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tommy Wiseau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roundhay Garden Scene": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Self-Portrait (film)": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Schichlegruber Doing the Lambeth Walk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shaken, not stirred": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Sharknado": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Smell-O-Vision": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stay Puft Marshmallow Man": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Stinking badges": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Taylor Mead's Ass": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Titanic (1943 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Twin films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Uranus Experiment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "United Passions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Unsimulated sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Who Killed Captain Alex?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wilhelm scream": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Winnie-the-Pooh: Blood and Honey": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Zyzzyx Road": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2010 Georgian news report hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Al Murray's Compete for the Meat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alternative 3": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Anti-Barney humor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Australia's Naughtiest Home Videos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Green Book (BBC)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bernd das Brot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Canadian Conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Captain Midnight broadcast signal intrusion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The City on the Edge of Forever": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Conspiracy 58": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dinner for One": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Don't Scare the Hare": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Flanderization": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flemish Secession hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Force is with Cristal Beer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Friday night death slot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Graggle Simpson": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Greg Packer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "De Grote Donorshow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Guy Goma BBC interview": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Heil Honey I'm Home!": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Historiography of The Simpsons": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "History of Pop (American TV channel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hold on Tight! (Inside No. 9)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "How to Eat with Your Butt": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Hypothetical (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I Didn't Know I Was Pregnant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "It's So Funny": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "I Wanna Marry \"Harry\"": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "John Dillermand": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Judaism in Rugrats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jumping the shark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Press Your Luck scandal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of Saturday Night Live incidents": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Max Headroom signal hijacking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mikhail Gorbachev Pizza Hut commercial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nasubi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Susunu! Denpa Shōnen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Odagiri effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Reborn as a Vending Machine, I Now Wander the Dungeon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shaun Micallef's Mad as Hell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Chris Rock–Will Smith slapping incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Soap opera rapid aging syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Southern Television broadcast interruption": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Space Cadets (TV series)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Spaghetti-tree hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Star Wars Holiday Special": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Superstar USA": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Tomorrow's Pioneers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turn-On": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turner Doomsday Video": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "TV pickup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Uh Oh! (game show)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Very special episode": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wank Week": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tommy Westphall": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Who's Your Daddy? (2005 TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Zuiikin' English": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Action 52": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Adventures of Ninja Nanny & Sherrloch Sheltie": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Atari video game burial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bad Rats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bartle taxonomy of player types": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of B-R5RB": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beat 'Em & Eat 'Em": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Big Rigs: Over the Road Racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "BMX XXX": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bob's Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Boong-Ga Boong-Ga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Boss key": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Breast physics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Cadillacs and Dinosaurs: The Second Cataclysm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Calculator (Nintendo Switch)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Cat hair mustache puzzle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catechumen (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chex Quest": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cho Aniki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Communist Mutants from Space": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Corrupted Blood incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crab Champions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Cubic Ninja": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dance Dance Immolation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Dark Room Sex Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Development of Duke Nukem Forever": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Don't Buy This": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edge Games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eggplant run": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ethnic Cleansing (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fortnite Holocaust Museum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Goat Puzzle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Goat Simulator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goodboy Galaxy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Giana Sisters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grezzo 2": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Hatoful Boyfriend": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hong Kong 97 (video game)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Hot Coffee (minigame)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "I Am Bread": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I am Error": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "I Love Bees": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I Love You, Colonel Sanders!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Incidente em Varginha": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Incredible Crisis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Islamic Fun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "JFK Reloaded": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kanye Quest 3030": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Kanye Zone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Killer7": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Laden VS USA": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "List of video games notable for negative reception": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "LSD: Dream Emulator": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mighty No. 9": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "MissingNo.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mister Mosquito": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Murder of Sonic the Hedgehog": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Ninja Golf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nuclear Gandhi": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Penn & Teller's Smoke and Mirrors": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pepsiman (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "PETA satirical browser games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phalanx (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Playing History 2 - Slave Trade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pokémon and pornography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pokémon Uranium": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Polybius (urban legend)": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Pyongyang Racer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Quest for Bush": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Rex Ronan: Experimental Surgeon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Seaman (video game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sex with Hitler": {
    "real": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Sex with Stalin": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Simlish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Soda Drinker Pro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sonic Dreams Collection": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Special Force (2003 video game)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Stalin vs. Martians": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Story of Kamikuishiki Village": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Super Columbine Massacre RPG!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shobon no Action": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Takeshi's Challenge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tetris effect": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thatcher's Techbase": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Thompson Twins Adventure": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turnip Boy Commits Tax Evasion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Untitled Goose Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Yeah! You Want \"Those Games,\" Right? So Here You Go! Now, Let's See You Clear Them!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "You Have to Burn the Rope": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2 Hours Doing Nothing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A group where we all pretend to be boomers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "All your base are belong to us": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Babiniku": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Backrooms": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bernie Sanders' Dank Meme Stash": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Igor and Grichka Bogdanoff": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boobquake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bowsette": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "British scientists (meme)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Bus Uncle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "My Little Pony: Friendship Is Magic fandom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carstuckgirls.com": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Chad (slang)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cinnamon challenge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Consumption of Tide Pods": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Countryballs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Crush on Obama": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cursed image": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cute cat theory of digital activism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dancing baby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "DashCon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dave rule": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Doge (meme)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elsagate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Every time you masturbate... God kills a kitten": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extremely online": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Florida Man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Wikipedia:Getting to Philosophy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Godwin's law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goncharov (meme)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Google (verb)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Half-Life: Full Life Consequences": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hampster Dance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Heartbreaking: The Worst Person You Know Just Made A Great Point": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Homunculus loxodontus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sam Hyde": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Instagram egg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "It's Decorative Gourd Season, Motherfuckers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Jerma985 Dollhouse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Biden (The Onion)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Josh fight": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eduard Khil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lasagna Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lenin was a mushroom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Markovian Parallax Denigrate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Meow Wars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Microsoft acquisition hoax": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Miguxês": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NAFO (group)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neuro-sama": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "No Nut November": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nukemap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Numa Numa (video)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Omission of New Zealand from maps": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Omission of Tasmania from maps of Australia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "On the Internet, nobody knows you're a dog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "OS-tan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "PewDiePie vs T-Series": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Philosophical zombie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Planet X637Z-43": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Press F to pay respects": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rickrolling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rule 34": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mark V. Shaney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Shitposting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shock site": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shrek fandom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sitting and Smiling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Skibidi Toilet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Storm Area 51": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Suntukan sa Ace Hardware": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Techno Viking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ted Cruz–Zodiac Killer meme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Time Cube": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "John Titor": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "This Man": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Tourist guy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Twitter suspensions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Unusual eBay listings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uwu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Very erotic very violent": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WikiFeet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WTFPL": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia Star Trek Into Darkness debate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yaminjeongeum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kanamara Matsuri": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mexico City Alebrije Parade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Testicle festival": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "All in a Row": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cherry Sisters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Elvis Dead": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "In My Life (musical)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jahrhundertring": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jerry Springer: The Opera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moose Murders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mortal Kombat: Live Tour": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Spider-Man: Turn Off the Dark": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alcohol-infused whipped cream": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ant egg soup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ayds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bacon Explosion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bacon ice cream": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Banana production in Iceland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Biangbiang noodles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boneless Fish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "British Rail sandwich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carmine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Casu martzu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Century egg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chả rươi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chocolate-coated marshmallow treats": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chubby bunny": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cockle bread": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Competitive eating": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cookie cake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deep-fried Mars bar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dilberito": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dishwasher salmon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Charles Domery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Doug (tuber)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Durian": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edible underwear": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Engastration": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eyes (cheese)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Flies' graveyard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fool's Gold Loaf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Freedom fries": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fried spider": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fruit ketchup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adolf Hitler and vegetarianism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hedgehog Flavour Crisps": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hitlerszalonna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hottest chili pepper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hufu (novelty item)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Human placentophagy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kit Kats in Japan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ketchup as a vegetable": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kosher locust": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kuai Kuai culture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Latke–Hamantash Debate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Luther Burger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dog Meat Festival": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "McWord": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michel Lotito": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Milbenkäse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Monkey brains": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "None Pizza with Left Beef": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nutellagate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alfred Packer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pieing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Products produced from The Simpsons": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rhubarb Triangle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roadkill cuisine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salmon chaos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Šakotis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "San-nakji": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sealed crustless sandwich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spotted dick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Square watermelon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stargazy pie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stinky tofu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Superman (ice cream flavor)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Surströmming": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Takeru Kobayashi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Testicles as food": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toast sandwich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "La Tomatina": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sonya Thomas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Military chocolate (United States)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Unusually shaped fruits and vegetables": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vantage loaf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Virgin boy egg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Volkswagen currywurst": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Who Ate All the Pies?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "1985 Austrian diethylene glycol wine scandal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beer can pyramid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kopi luwak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cock ale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Cola wars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Soda geyser": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fucking Hell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ganesha drinking milk miracle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grapefruit–drug interactions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gustav III of Sweden's coffee experiment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "H2NO": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Noah S. Sweat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ISO 3103": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "OpenCola (drink)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pepsi Number Fever": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pussy (energy drink)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Snake wine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Speyer wine bottle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vodka eyeballing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Claudia Sanders Dinner House": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Conflict Kitchen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cross Cafe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dinner in the Sky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fortezza Medicea restaurant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hamburger University": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Heart Attack Grill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ithaa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jewish-American patronage of Chinese restaurants": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Kayabukiya Tavern": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Loving Hut": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MaDonal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "McDonald's ice cream machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "McDonald's urban legends": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Modern Toilet Restaurant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Original Spanish Kitchen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pyongyang (restaurant chain)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Seriously McDonalds": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Shed at Dulwich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Wiener King": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "24 Hours of Lemons": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1916 Cumberland vs. Georgia Tech football game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1967 NFL Championship Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1969 Talladega 500": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1978 CONCACAF Champions' Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1992 Troy State vs. DeVry men's basketball game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2005 United States Grand Prix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2012 Daytona 500": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2014 Hiram vs. Mount St. Joseph women's basketball game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021 Belgian Grand Prix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Artistic roller skating": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "AS Adema 149–0 SO l'Emyrne": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Australia 31–0 American Samoa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Australian Football International Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barbados 4–2 Grenada": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bat and trap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of Bramall Lane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of Surfaces": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bladderball": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "British baseball": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bog snorkelling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bottle-kicking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Butt Fumble": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chess boxing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Collision in Korea": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cooper's Hill Cheese-Rolling and Wake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coventry City 2–2 Bristol City (1977)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disgrace of Gijón": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Arquette in World Championship Wrestling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disco Demolition Night": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dot-com commercials during Super Bowl XXXIV": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A drive into deep left field by Castellanos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dwarf-tossing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dwile flonking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elephant polo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Enhanced Games": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Eton wall game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Extreme ironing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Fair catch kick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fan Controlled Football": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fierljeppen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Football tennis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gillidanda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Heidi Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henley-on-Todd Regatta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "International Rutabaga Curling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Isner–Mahut match at the 2010 Wimbledon Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lawn mower racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "X League (women's football)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mall walking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mass Transit incident (professional wrestling)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Athletics at the 1904 Summer Olympics – Men's marathon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2020 BYU vs. Coastal Carolina football game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mythical national championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Naha Tug-of-war": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New Testament athletic metaphors": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "One-armed versus one-legged cricket": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pillow Fight League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Plainfield Teachers College": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Play (American football)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Public image of Roman Reigns": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Quidditch (real-life sport)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RoboCup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rocket Racing League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Scorigami": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ski ballet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smiggin Holes 2010 Winter Olympic bid": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "SpoGomi": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Sports-related curses": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stoolball": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ten Cent Beer Night": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Traditions and anecdotes associated with the Stanley Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ultimate Tazer Ball": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Ultimate Typing Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Underarm bowling incident of 1981": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Welly wanging": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wife-carrying": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Wooden spoon (award)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "World Black Pudding Throwing Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wrestling at the 1912 Summer Olympics – Men's Greco-Roman light heavyweight": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yukigassen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Buzkashi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Conger cuddling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Egg tapping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fatso the Fat-Arsed Wombat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ferret-legging": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fox tossing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Goose pulling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hamster racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kudu dung-spitting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kyz kuu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Legend of the Octopus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Octopus wrestling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Pig Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Rabbit show jumping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robot jockey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Snail racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Teddy bear toss": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turkey bowling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vinkensport": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Yak racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1956 Olympic flame hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Margaret Abbott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sebastián Abreu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nasra Ali Abukar": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Arrhichion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Ayres": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barefoot running": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paula Barila Bolopa": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Steve Bartman incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Philip Boit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steven Bradbury": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rogério Ceni": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Oksana Chusovitina": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Curse of Billy Penn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Curse of the Colonel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Rajai Davis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ali Dia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mariya Dmitriyenko": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Daniel Dye": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Dock Ellis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eddie the Eagle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sidd Finch": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Eddie Gaedel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sajjad Ganjzadeh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dolly Gray impostor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ferdinand Habsburg (racing driver)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Hilton (table tennis)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hubertus von Hohenlohe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carlos Kaiser (footballer)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Shizo Kanakuri": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Evel Knievel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kyle Larson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bob Lemon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeffrey Maier incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mendoza Line": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eric Moussambani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "José Offerman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boris Onishchenko": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bruno Banani (luger)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sturla Snær Snorrason": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth Swaney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taro Tsujimoto": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Kazuo Uzuki": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "L. W. Wright": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Atlanta Black Crackers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Baltimore Colts relocation to Indianapolis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "East Africa rugby union team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "FC Cuntum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "FC Slutsk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jamaica national bobsleigh team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "London Rippers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mongolia national baseball team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "New Zealand national team nomenclature based on the \"All Blacks\"": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Badminton New Zealand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Oorang Indians": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sark football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sealand national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Somalia national bandy team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Steagles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Card-Pitt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tropical nations at the Winter Olympics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wichita Monrovians": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Windsor Swastikas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vatican City national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Atomic chess": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Beirut chess": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Stratomic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Blood-vomiting game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Bongcloud Attack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carlsen–Niemann controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chess on a really big board": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fairy chess piece": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Game (mind game)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Ghettopoly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Human chess": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kanchō": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kasparov versus the World": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of games that Buddha would not play": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mornington Crescent (game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Poole versus HAL 9000": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Potato race": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taikyoku shogi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mechanical Turk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "USA Rock Paper Scissors League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "War on Terror (game)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1593 transported soldier legend": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Baltic Sea anomaly": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Beast of Gévaudan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Behind the sofa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bigfoot trap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of avian humanoids": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Brites de Almeida": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cottingley Fairies": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Count of St. Germain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Easter Bilby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Faxlore": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flying ointment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Green children of Woolpit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Headless men": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Headless Mule": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Heraclitus the Paradoxographer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Icelandic Elf School": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Josiah S. Carberry": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Kaspar Hauser": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Liver-Eating Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "N,N-Dimethyltryptamine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Man-eating plant": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mapinguari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Mari Lwyd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Monkey-man of Delhi": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Nightmarchers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Panotti": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Phantom social workers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chinese proverbs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pseudo-mythology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reptilian humanoid": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Rod (optical phenomenon)": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "In Soviet Russia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Spring-heeled Jack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Telling the bees": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tió de Nadal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Titivillus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tsukumogami": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vagina dentata": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Vampire pumpkins and watermelons": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vril": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Well to Hell": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Witch window": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yonaguni Monument": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Bake-danuki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bonnacon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Cattle mutilation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chupacabra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Cynocephaly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Dog spinning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Drop bear": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Fearsome critters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "When pigs fly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Humanzee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Jersey Devil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Liver bird": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Living entombed animal": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Lluvia de peces": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mamlambo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mongolian death worm": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Montauk Monster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Pacific Northwest tree octopus": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Phantom kangaroo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Popobawa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pig-faced women": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Rat king": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sea monk": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Sidehill gouger": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Spherical cow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Squonk": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Tarasque": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vegetable Lamb of Tartary": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Widow's man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Absurdistan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bagism": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Beard Liberation Front": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Berners Street hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Birth tourism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Frank Chu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Correspondence between the Ottoman sultan and the Cossacks": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Crypt of Civilization": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cutting in line": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elaine Davidson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Erika Eiffel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Elvavrålet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Escalator etiquette": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fat men's club": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Female husband": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jenaro Gajardo Vera": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Justo Gallego Martínez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Georgia Guidestones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Guerrilla gardening": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Go Topless Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Harrelson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "He never married": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Marie Sophie Hingst": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ancient and Honorable Order of Turtles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Japanese adult adoption": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth Klarer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Knobbly knees competition": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Let's trim our hair in accordance with the socialist lifestyle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of people who have lived in airports": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Long-term nuclear waste warning messages": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jean-Marie Loret": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Mónica Macías": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Man of the Hole": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mitsuyasu Maeno": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Mongrel complex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Montreal–Philippines cutlery controversy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Neturei Karta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Niche insurance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emperor Norton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Panty tree": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pole and Hungarian brothers be": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Posthumous marriage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Queue for the lying-in-state of Elizabeth II": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sentinelese": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Travelling gnome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vesna Vulović": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "War of the stop signs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ziona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1803 Gatton by-election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1927 Liberian general election": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "1986 Illinois gubernatorial election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2018 Makassar mayoral election": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Above Znoneofthe": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Alaska Mental Health Enabling Act": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Non-human electoral candidate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "André Dallaire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Antanas Mockus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anarchist Pogo Party of Germany": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Anti-PowerPoint Party": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bald–hairy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Banned in Boston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barack Obama \"Joker\" poster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alejandro Cao de Benós": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Biotic Baking Brigade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Boris Skossyreff": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "British Israelism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Brown Dog affair": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bushism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George W. Bush shoeing incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Byron Looper": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Candy Desk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catmando": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles the Bald": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chernomyrdinka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Chief Mouser to the Cabinet Office": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Count Binface": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Celso Daniel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Congressional office lottery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crusade of Romanianism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "David Rice Atchison": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Deez Nuts (satirist)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Division of Batman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Democracy sausage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dewey Defeats Truman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dizzy Gillespie 1964 presidential campaign": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Donald Duck Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dunwich (UK Parliament constituency)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ed Miliband bacon sandwich photograph": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eddie Eagle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wolfgang Engels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Euromyth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Four Pests campaign": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Four Seasons Total Landscaping press conference": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fuddle duddle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gaysper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George H. W. Bush broccoli comments": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "German Apples Front": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Glee Club (UK politics)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Greek Ecologists": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Günter Schabowski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "H'Angus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harold Holt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helengrad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Huh Kyung-young": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Hungarian Two-Tailed Dog Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ich bin ein Berliner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ilona Staller": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Incidents of objects being thrown at politicians": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jakob Maria Mierscheid": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Jimmy Carter Peanut Statue": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Carter rabbit incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Carter UFO incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jón Gnarr": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Turmel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kasongo Ilunga": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Ku Klux Klan titles and vocabulary": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lyndon LaRouche": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Legislative violence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Liz Truss lettuce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lord Bloody Wog Rolo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Luke Lea (American politician, born 1879)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Kim Jong Il's titles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Marxist–Leninist Party of the Netherlands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Mitsuo Matayoshi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "McGillicuddy Serious Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mel Carnahan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Merkel-Raute": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nagriamel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New shoes on budget day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nicolás Zúñiga y Miranda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NHK Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Niuas Nobles' constituency": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nobody for President": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nuisance candidate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Official Monster Raving Loony Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Old Sarum (UK Parliament constituency)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gabriele Paolini": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Panda diplomacy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Parliamentary snuff box": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pascual Racuyal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Patrol 36": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Pedro Lascuráin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "People's Revolutionary Government (Grenada)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pink Pistols": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Polish Beer-Lovers' Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Political Google bombs in the 2004 U.S. presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "¿Por qué no te callas?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Proposed Canadian political association with the Turks and Caicos Islands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Puedo prometer y prometo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Putin khuylo!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ratfucking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Redskins Rule": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Resignation from the House of Commons of the United Kingdom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Revolutionary Communist Party (UK, 1978)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rhinoceros Party": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Nixon mask": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Russian political jokes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Screaming Lord Sutch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shanghai Fugu Agreement": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Shawinigan Handshake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shi Pei Pu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sister Boom Boom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Socialist fraternal kiss": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Socialist Patients' Collective": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Strom Thurmond filibuster of the Civil Rights Act of 1957": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taiwan Communist Party": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Wizard of New Zealand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "There's No One as Irish as Barack O'Bama": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toad worship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tsang Tsou-choi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wilson Tucker (politician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Unabomber for President": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Union of the Centrist Center": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vermin Supreme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Waitangi dildo incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "White House horseshoe pit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Why I Want to Fuck Ronald Reagan": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "You have two cows": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "1933 double eagle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2018 Samsung fat-finger error": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "BackpackersXpress": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bad (economics)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bank of England £100,000,000 note": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Big Mac Index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Billboard Utilising Graffitists Against Unhealthy Promotions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dead cat bounce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dead mall": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elongated coin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "EURion constellation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fedspeak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Financial Modeling World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fukuppy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "GameStop short squeeze": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Slum tourism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gruen transfer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prix Guzman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hallmark holiday": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hemline index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hungarian pengő": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Inflatable rat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "IKEA pencil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kongō Gumi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maid café": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Men's underwear index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Meme coin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Merchant Marine of Switzerland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Money burning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Olim L'Berlin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Oil futures drunk-trading incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Operation Bernhard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Purple squirrel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rai stones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gerald Ratner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Swastika Laundry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tanganyika groundnut scheme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Therblig": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ting Hai effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Tingo Group": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Dozy Mmobuosi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Toyokawa Shinkin Bank incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trillion-dollar coin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tulip mania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Us Tareyton smokers would rather fight than switch!": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Veblen good": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Why didn't you invest in Eastern Poland?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zero-rupee note": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1984 Rajneeshee bioterror attack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2007 Boston Mooninite panic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sada Abe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Acoustic Kitty": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Animal trial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Attempted theft of George Washington's skull": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Baby Jesus theft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Batman rapist": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bowling Green massacre": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Burke and Hare murders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chamoy Thipyaso": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Chewbacca defense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Michael Cicconetti": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cicada 3301": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Commission Regulation (EC) No. 2257/94": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Confraternities in Nigeria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crime in Antarctica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crime in Vatican City": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dead Man's Statute": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Easter Act 1928": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Emo killings in Iraq": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Expert wizard amendment": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Free Bench": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Glasgow ice cream wars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Troy Leon Gregg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disappearance of Johnny Gosch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Guano Islands Act": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helen Duncan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hobby Lobby smuggling scandal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "I know it when I see it": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Smeaton (born 1976)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "John Smith (housebreaker)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Learned Hand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jay Leiderman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lesbian rule": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ley de fugas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Viola Liuzzo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rodrigo Rosenberg Marzano": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Massachusetts School Laws": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matrix defense": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gary McKinnon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A moron in a hurry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mug shot of Donald Trump": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Ninja of Heisei": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Not proven": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disappearance of Emanuela Orlandi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Onion Futures Act": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Operation Flagship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Perry Mason moment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Phantom of Heilbronn": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Prenda Law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prohibition of dying": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Regulation of flamethrowers in the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Hanssen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rough sex murder defense": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salmon Act 1986": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sand theft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shaggy defense": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1995 San Diego tank rampage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Small penis rule": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steve Comisar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tennessee login law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Keron Thomas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Andre Thomas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Twinkie defense": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ugly law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United Airlines Flight 976": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Angie Sanclemente Valencia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Clement Vallandigham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whipping Tom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wet feet, dry feet policy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2008 French mistaken virginity case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "62 Cases of Jam v. United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Batman v. Commissioner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "FTC v. Balls of Kryptonite": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hermesmann v. Seyer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Iceland v Iceland Foods Ltd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jarvis v Swans Tours Ltd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lawsuits against supernatural beings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Leonard v. Pepsico, Inc.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manacled Mormon case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Memoirs v. Massachusetts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "McMartin preschool trial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miles v. City Council of Augusta, Georgia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Monkey selfie copyright dispute": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nix v. Hedden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pearson v. Chung": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stambovsky v. Ackley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "State v. Linkhaw": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Trial of Arne Cheyenne Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toy Biz, Inc. v. United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Trial of the Pyx": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "United States ex rel. Gerald Mayo v. Satan and His Staff": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "United States v. 11 1/4 Dozen Packages of Articles Labeled in Part Mrs. Moffat's Shoo-Fly Powders for Drunkenness": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States v. Approximately 64,695 Pounds of Shark Fins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States v. Causby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States v. Ninety-Five Barrels Alleged Apple Cider Vinegar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bachelor tax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Beard tax": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Breast tax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chicken tax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Agricultural emissions research levy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Taxation of illegal income in the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bamboo torture": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Blood eagle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Brazen bull": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disneyland with the Death Penalty": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Drunkard's cloak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Enhanced interrogation techniques": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Half-hanging": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hanged, drawn and quartered": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pitchcapping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Poena cullei": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rhaphanidosis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "fake": [
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Charivari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scaphism": {
    "real": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Schwedentrunk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Scold's bridle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Washing out the mouth with soap": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whipping boy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Abeguwo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Asher yatzar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Axinomancy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Ben Hana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bhekuli Biya": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Braco (faith healer)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cargo cult": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Church of the SubGenius": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Coconut Religion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crepitus (mythology)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Ded Moroz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dendera light": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dhana Kumari Bajracharya": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dinkoism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Disconnection (Scientology)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fluffy bunny (Wicca)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flying Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Gang Bing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Park51": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Haitian Vodou and sexual orientation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "High-Heel Wedding Church": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Iglesia Maradoniana": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Incident (Scientology)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "International date line in Judaism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jewish law in the polar regions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Invisible Pink Unicorn": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Islamic toilet etiquette": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jedi census phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jerusalem syndrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jewish pope Andreas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Johnson cult": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kacchera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kapo (mythology)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of UFO religions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lou de Palingboer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jesús Malverde": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jim Bakker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matshishkapeu": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Missionary Church of Kopimism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mizab al-Rahma": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Oomoto": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Open-source religion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Our Lady of Perpetual Exemption": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prince Philip movement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pseudoskepticism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raël": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Religion in Antarctica": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "State Religious Affairs Bureau Order No. 5": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Perceptions of religious imagery in natural phenomena": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Saint Urho": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Silver Sisterhood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sin-eater": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Temple of Priapus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Space opera in Scientology": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sudanese teddy bear blasphemy case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taghairm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tlazōlteōtl": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Toilet god": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turtles all the way down": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United Nation of Islam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Universe People": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Urantia Book": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Xenu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Yakub (Nation of Islam)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adam–God doctrine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alexamenos graffito": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The All-Joking, All-Drunken Synod of Fools and Jesters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "As a dog returns to his vomit, so a fool repeats his folly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Banquet of Chestnuts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bible errata": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carlo Acutis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Caganer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christmas in Nazi Germany": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Church of the First Born of the Lamb of God": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Chute na santa incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Clare of Assisi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Public image of Mother Teresa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harold Davidson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ejaculatory prayer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ruben Enaje": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Feast of the Ass": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flirty Fishing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Freedomites": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gambling on papal conclaves": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "General Butt Naked": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Great Disappointment": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hell house": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Holy Prepuce": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Jesus H. Christ": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Kolob": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of people claimed to be Jesus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mental health of Jesus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miracle of the Sun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Movement for the Restoration of the Ten Commandments of God": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Non-canonical books referenced in the Bible": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Omphalos hypothesis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pope John numbering": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pope Joan": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "David Bawden": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Saeculum obscurum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rumspringa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Saint Guinefort": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Secret Gospel of Mark": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "St. James-Bond Church": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tiberius Julius Abdes Pantera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Unfulfilled Christian religious predictions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Wicked Bible": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zipporah at the inn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Adrian Carton de Wiart": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Angels of Mons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Vasily Arkhipov": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bolivian Navy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boot Monument": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of camoufleurs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Caspian Sea Monster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jack Churchill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Crucified Soldier": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "CONOP 8888": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "D-Day Daily Telegraph crossword security alarm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deborah's Hole Camp": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Demob suit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Devil Eyes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Dreadnought hoax": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Juan Pujol García": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Gunther": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Simo Häyhä": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ice cream barge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kamikaze (typhoon)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aimo Koivunen": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Line-crossing ceremony": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wartime cross-dressers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Alan Mcilwraith": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Wilmer McLean": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miss Russian Army": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Montauk Project": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Moro Islamic Liberation Front": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mozart Group": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Navies of landlocked countries": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nebraska Admiral": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Night Witches": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NORAD Tracks Santa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hiroo Onoda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stanislav Petrov": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pentagon UFO videos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Philadelphia Experiment": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Portuguese Fireplace": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Project A119": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ratlines (World War II)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Russian warship, go fuck yourself": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shi Yousan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Siachen Glacier": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Otto Skorzeny": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Tandey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pat Tillman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The terrorists have won": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Eyre (surname)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "András Toma": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lauri Törni": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "USS William D. Porter (DD-579)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William Stuart-Houston": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Tsutomu Yamaguchi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yang Kyoungjong": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Z (military symbol)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zeppelin LZ 66": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Zhang Zongchang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Corporal Jackie": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Dickin Medal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moose cavalry": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Sergeant Stubby": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States Camel Corps": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1998 Sokcho submarine incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anglo-Zanzibar War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Attack of the Dead Men": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Attack on Marstrand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bahia incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Battle of Castle Itter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of Domažlice": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Battle of Fishguard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of Karánsebes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Battle of Lake Baikal": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Battle of Tanga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of the Eclipse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Battle of the Herrings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Invasion of Iceland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chen Sheng and Wu Guang uprising": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dai Hong Dan incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Empresa de China": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Emu War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Flagstaff War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Football War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gombe Chimpanzee War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Huéscar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "If Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Iowa Cow War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lobster War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Cottage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Mincemeat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Korean axe murder incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Pig Bristle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Red Dog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Operation Tamarisk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Operation Wikinger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pastry War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pig War (1859)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taiping Rebellion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Three Hundred and Thirty Five Years' War": {
    "real": [
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Toledo War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toyota War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Turkish Abductions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War of the Bucket": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War of Jenkins' Ear": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Incident at Petrich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War of the Donkey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vue Pa Chay's revolt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War of the League of Cambrai": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War Plan Red": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Anti-tank dog": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Antonov A-40": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bat bomb": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Baynes Bat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vespa 150 TAP": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Bicycle infantry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cornfield Bomber": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dazzle camouflage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Davy Crockett (nuclear device)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Double-barreled cannon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Explosive rat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gay bomb": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "German submarine U-1206": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Golden rivet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Panjandrum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harmonica gun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "History of military ballooning": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "HNLMS Abraham Crijnssen (1936)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Human torpedo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Millwall brick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Most-wanted Iraqi playing cards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Project Habakkuk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Project Pigeon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Project Plowshare": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puckle gun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schwerer Gustav": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Skunk (weapon)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sticky bomb": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tachanka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tsar Tank": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "United States Navy Marine Mammal Program": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Whistling Dick (cannon)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Who Me": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "Zhanmadao": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Atacama skeleton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Badge Man": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Black Volga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Mercy Brown vampire incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Chase": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coffin birth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Collyer brothers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Dawn of the Black Hearts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death by coconut": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Death by GPS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death erection": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Death from laughter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death by misadventure": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death by vending machine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Defenestration": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Disappearance of Frederick Valentich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dyatlov Pass incident": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Euthanasia Coaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Execution by elephant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fan death": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Generalissimo Francisco Franco is still dead": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ghost bike": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Green Boots": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hammersmith nude murders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Hands of Che Guevara": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hell money": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sogen Kato": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kennedy curse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kick the bucket": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lampshades made from human skin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Ricardo López (stalker)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Lee Lucas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Children of Llullaillaco": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of English-language expressions related to death": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of people who have died while on the toilet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "List of entertainers who died during a performance": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of postal killings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of selfie-related injuries and deaths": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lead masks case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "London Necropolis railway station": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lord Uxbridge's leg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Maschalismos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael Malloy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elmer McCurdy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ken McElroy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Micromort": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mordred": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Murder of Vivianne Ruiz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Herbert Mullin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oliver Cromwell's head": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Paul Pavlick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Poe Toaster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Post-mortem photography": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death of Gloria Ramirez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Refrigerator death": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Republican marriage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Rookwood Cemetery railway line": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Safety coffin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salish Sea human foot discoveries": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Frano Selak": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Sky burial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sokushinbutsu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Space burial": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spontaneous human combustion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Euthanasia device": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Suicide of Sunil Tripathi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Somerton Man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carl Tanzler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uttar Pradesh Association of Dead People": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lal Bihari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joyce Vincent": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Video-Enhanced Grave Marker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Xin Zhui": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "How many angels can dance on the head of a pin?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "If a tree falls in a forest and no one is around to hear it, does it make a sound?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Meaning of life": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Where's the beef?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Why did the chicken cross the road?": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "List of American and British defectors in the Korean War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of catgirls and catboys": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of common misconceptions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lists of Danish football transfers 2008–09": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of dates predicted for apocalyptic events": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of foreign-born samurai in Japan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of garlic festivals": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of helicopter prison escapes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of incidents at Disney parks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of largest hourglasses": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of lists of lists": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of non-water floods": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of paraphilias": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of people imprisoned for editing Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "List of people who have been considered deities": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of people who have been pied": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "List of potato museums": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of scholarly publishing stings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of sexually active popes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "List of shoe-throwing incidents": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of wrong anthems incidents": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia:Deleted articles with freaky titles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia:List of really, really, really stupid article ideas that you really, really, really should not create": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Wikipedia:Unusual articles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia:Unusual articles/Removed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ø (Disambiguation)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Wikipedia:Disambiguation (disambiguation)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia:Discussions for discussion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "unusual_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cleopatra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "YouTube": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "ChatGPT": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "2023 Cricket World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX: Return of Xander Cage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Indian Premier League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oppenheimer (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Facebook": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "J. Robert Oppenheimer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Instagram": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cricket World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jawan (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXXX (beer)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taylor Swift": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Last of Us (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 Indian Premier League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Index (statistics)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pathaan (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXXTentacion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Premier League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Barbie (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Idol (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Cristiano Ronaldo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matthew Perry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lionel Messi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikipedia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ansel Adams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elon Musk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "India": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Avatar: The Way of Water": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lisa Marie Presley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pornhub": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Guardians of the Galaxy Vol. 3": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XNXX": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of highest-grossing Indian films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Leo (2023 Indian film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Google Translate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andrew Tate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Israel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 Asia Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fast X": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sinéad O'Connor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alia Bhatt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elvis Presley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Beckham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Killers of the Flower Moon (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of American films of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Travis Kelce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth II": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Twitter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spider-Man: Across the Spider-Verse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Super Mario Bros. Movie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pedro Pascal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Google": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Omegle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Donald Trump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tina Turner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Indiana Jones and the Dial of Destiny": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Wick: Chapter 4": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Everything Everywhere All at Once": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Margot Robbie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Biden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Flipkart": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Arnold Schwarzenegger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "UEFA Champions League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Charles III": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "WhatsApp": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hamas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Cruise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Virat Kohli": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Little Mermaid (2023 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of highest-grossing films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Flash (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "State of Palestine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX (2002 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gadar 2": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Vivek Ramaswamy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gaza Strip": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Novak Djokovic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "LeBron James": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jenna Ortega": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Carter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "India national cricket team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Keanu Reeves": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rihanna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Michael Jordan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Napoleon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Manchester United F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Al Nassr FC": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Succession (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mission: Impossible – Dead Reckoning Part One": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ant-Man and the Wasp: Quantumania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Robert F. Kennedy Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "United Kingdom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "World War II": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bruce Willis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Priscilla Presley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Last of Us": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sylvester Stallone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Riley Keough": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adolf Hitler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael Jackson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wagner Group": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  ".xxx": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adipurush": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raindrop cake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cillian Murphy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manchester City F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ryan Gosling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salaar: Part 1 – Ceasefire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bella Ramsey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ted Lasso": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Asia Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dwayne Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harrison Ford": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "List of Hindi films of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "OpenAI": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer Lawrence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Patrick Mahomes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ryan Reynolds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Marvel Cinematic Universe films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Erling Haaland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft Windows": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Equalizer 3": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Leonardo DiCaprio": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Titanic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 in film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Brendan Fraser": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "World War I": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gmail": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Timothée Chalamet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Null": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sound of Freedom (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Queen Victoria": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 FIFA Women's World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Menu (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Albert Einstein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chelsea F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Russian invasion of Ukraine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shah Rukh Khan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tiger 3": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Kissinger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George III": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Selena Gomez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Canada": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carlos Alcaraz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Michelle Yeoh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Australia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Russia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "China": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Pirate Bay": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Japan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Whitney Houston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Malaysia Airlines Flight 370": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miley Cyrus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Internet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Marvels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Barack Obama": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Inter Miami CF": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXXX": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "Israeli–Palestinian conflict": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elemental (2023 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Saltburn (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Whale (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New York City": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Real Madrid CF": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chandrayaan-3": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turkey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lance Reddick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christopher Nolan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Leave the World Behind (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Clint Eastwood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mission: Impossible (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Deion Sanders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John F. Kennedy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mount Takahe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "BBC World Service": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yellowstone (American TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cocaine Bear": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Kerala Story": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Eras Tour": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nikki Haley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Scarlett Johansson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hannah Waddingham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eminem": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Liverpool F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dunki (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "No Hard Feelings (2023 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Arsenal F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "September 11 attacks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jeffrey Dahmer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "FC Barcelona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Artificial intelligence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ana de Armas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2024 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Charlotte of Mecklenburg-Strelitz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Macaulay Culkin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tyson Fury": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Brady": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Danny Masterson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "2024 ICC Men's T20 World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blue Beetle (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Singapore": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Evil Dead Rise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer Aniston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kanye West": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "XHamster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Suits index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Diana, Princess of Wales": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Florence Pugh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kepler's Supernova": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Priyanka Chopra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XVideos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Celine Dion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Transformers: Rise of the Beasts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Tupac Shakur": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vladimir Putin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kylian Mbappé": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pakistan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert De Niro": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ke Huy Quan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Email": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Brad Pitt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Yevgeny Prigozhin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Greta Gerwig": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Five Nights at Freddy's (film)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ahsoka (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Bear (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Anya Taylor-Joy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WrestleMania 39": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Freddie Mercury": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nikola Jokić": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The White Lotus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Julia Roberts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nicolas Cage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "95th Academy Awards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jamie Lee Curtis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mahatma Gandhi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer Lopez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Netflix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 Formula One World Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rishi Sunak": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Russo-Ukrainian War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beyoncé": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George Michael": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Harry Styles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ron DeSantis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Key frame": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neymar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marilyn Monroe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edgar Allan Poe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Atomic bombings of Hiroshima and Nagasaki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maryland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Blake Lively": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dolly Parton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zendaya": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Mike Tyson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Hanks": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of states and territories of the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jonathan Majors": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Johnny Depp": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Madonna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eurovision Song Contest 2023": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Creed III": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Meta Platforms": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "YouTube Music": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brownie (folklore)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steven Spielberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adam Sandler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jason Kelce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Germany": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fast & Furious": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Angelina Jolie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX: State of the Union": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kobe Bryant": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Wiki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shubman Gill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marvel Cinematic Universe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft 365": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wikimedia Foundation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ben Affleck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "UEFA Euro 2024 qualifying": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jason Momoa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Periodic table": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ottoman Empire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "X (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wednesday (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emily Blunt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of countries by GDP (nominal)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harry Kane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aadhaar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Muhammad Ali": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "TikTok": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Napoleon (2023 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "YouTube Premium": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George VI": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Val Kilmer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Creator (2023 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pamela Anderson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeremy Allen White": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "YouTube Kids": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ariana Grande": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Robin Williams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dua Lipa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "OnlyFans": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul Reubens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Interstellar (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of NBA champions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023–24 UEFA Champions League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zlatan Ibrahimović": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "M3GAN": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "One Piece": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "English language": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeremy Renner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ted Kaczynski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salma Hayek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ukraine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George Santos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Philippines": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stephen Curry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neatsville, Kentucky": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry Cavill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harry Potter (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Google Maps": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Meghan, Duchess of Sussex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MrBeast": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shazam! Fury of the Gods": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Generation Z": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William, Prince of Wales": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jude Bellingham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Narendra Modi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Downey Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of James Bond films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shaquille O'Neal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Soviet Union": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ice Spice": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2022 FIFA World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Varisu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jason Statham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Fall of the House of Usher (miniseries)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "MS Dhoni": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chris Pratt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bradley Cooper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scream VI": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Banshees of Inisherin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Titanic (1997 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Algebraic notation (chess)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "France": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Olivia Rodrigo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chris Hemsworth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Holland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Indonesia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Witcher (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Britney Spears": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Five Nights at Freddy's": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Wrexham A.F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Conor McGregor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Netherlands": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dungeons & Dragons: Honor Among Thieves": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steve Jobs": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Super Bowl champions": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Saudi Arabia": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Murdaugh family": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lana Del Rey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rachel Zegler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aubrey Plaza": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Mark Wahlberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alan Rickman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Mandalorian": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kim Kardashian": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shakira": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jon Jones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sydney Sweeney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Avatar (2009 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kiara Advani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2026 FIFA World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lady Gaga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Al Pacino": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Top Gun: Maverick": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Bowie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ashton Kutcher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bangladesh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jesus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kevin Costner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Justin Bieber": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matthew McConaughey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kareem Abdul-Jabbar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lewis Strauss": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mia Khalifa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "FIFA World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ray Stevenson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Cena": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Outlook.com": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tottenham Hotspur F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marie Antoinette": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "New Zealand": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salman Khan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Murder of Dee Dee Blanchard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "South Africa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Transformers (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "123Movies": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elton John": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George V": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sandra Bullock": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Victor Wembanyama": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2023 Rugby World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vietnam War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Android (operating system)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Millie Bobby Brown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Raquel Welch": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taiwan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amazon (company)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Apple Inc.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Princess Margaret, Countess of Snowdon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taj Mahal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emma Watson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Young Sheldon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Peaky Blinders (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Benjamin Netanyahu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Seven deadly sins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "William Shakespeare": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Windows Server 2016": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "London": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Muhammad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United Arab Emirates": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vijay (actor)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Windows Server 2019": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Abraham Lincoln": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prince Harry, Duke of Sussex": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "John Lennon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puss in Boots: The Last Wish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edward VIII": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James Cameron": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paris Saint-Germain F.C.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2 Girls 1 Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zoe Saldaña": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Buffett": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 Asian Games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Natasha Lyonne": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black Panther: Wakanda Forever": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft Exchange Server": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "G20": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gal Gadot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Indian Super League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael J. Fox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Email client": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "BTS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Internet Explorer 11": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Babylon (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kylie Jenner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Beatles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mila Kunis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Heath Ledger": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Austin Butler": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joaquin Phoenix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Martin Luther King Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Pablo Escobar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Franklin D. Roosevelt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Client access license": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Katy Perry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1234": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rohit Sharma": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Iran": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ray Liotta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Breaking Bad": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft Office Mix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aquaman and the Lost Kingdom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Lewis Hamilton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sex Education (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul McCartney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Only Murders in the Building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kisi Ka Bhai Kisi Ki Jaan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bray Wyatt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alexander the Great": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kate Winslet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul Walker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George W. Bush": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eva Mendes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Earth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Game of Thrones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Billie Eilish": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Aaron Rodgers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "OMG 2": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Avengers: Endgame": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ted Bundy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chernobyl disaster": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joker (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bible": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Simple Mail Transfer Protocol": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Louis Tomlinson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeffrey Epstein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Captain Marvel (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Once Upon a Time in Hollywood": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spider-Man: Far From Home": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019 in film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Star Wars: The Rise of Skywalker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nipsey Hussle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alexandria Ocasio-Cortez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Us (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Luke Perry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Queen (band)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cameron Boyce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Lion King (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bonnie and Clyde": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rami Malek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019 Indian general election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Central Park jogger case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kamala Harris": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Aladdin (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boris Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Stranger Things": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019 Cricket World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brie Larson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Manson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cardi B": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shazam! (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXX (soundtrack)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Hoffa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chernobyl (miniseries)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Star Is Born (2018 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jeff Bezos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Area 51": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "HTTP 404": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Glass (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emilia Clarke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Notre-Dame de Paris": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "R. Kelly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mary, Queen of Scots": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dark Phoenix (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prince Philip, Duke of Edinburgh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Greta Thunberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Toy Story 4": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Naomi Scott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Richard Jewell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roger Federer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aquaman (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Umbrella Academy (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Wick: Chapter 3 – Parabellum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sophie Turner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sharon Tate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Article 370 of the Constitution of India": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Handmaid's Tale (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Neil Armstrong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tulsi Gabbard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pete Buttigieg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kawhi Leonard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kabir Singh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Game of Thrones episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Avengers: Infinity War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Millennials": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lisa Bonet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Alita: Battle Angel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nick Jonas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Post Malone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Saaho": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "It Chapter Two": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bohemian Rhapsody (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rafael Nadal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Judy Garland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Caitlyn Jenner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anne, Queen of Great Britain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Godzilla: King of the Monsters (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aaliyah": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nancy Pelosi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mindhunter (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mötley Crüe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "You (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Queen of the South episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chris Evans (actor)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spider-Man: Into the Spider-Verse": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andrew Cunanan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Winston Churchill": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Terminator: Dark Fate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fred Rogers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Google Chrome": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "6ix9ine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tiger Woods": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Solar System": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "War (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hong Kong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Star Wars": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Green Book (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WrestleMania 35": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Frank Sheeran": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hobbs & Shaw": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2020 Democratic Party presidential primaries": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lucifer (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dennis Rader": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Quentin Tarantino": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thanos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elizabeth Holmes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Will Smith": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maisie Williams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charlize Theron": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Line shaft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kate Beckinsale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Shawn Mendes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stephen Hawking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Halsey (singer)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Juice Wrld": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry V of England": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brexit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Liam Hemsworth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Watchmen (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bruce Lee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of United States cities by population": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bill Gates": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lizzo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Patrick Swayze": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brooklyn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Impeachment in the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bird Box (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coca-Cola": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "91st Academy Awards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Jonas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jussie Smollett": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Travis Scott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chandrayaan-2": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Winona Ryder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "21 Savage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brightburn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Big Bang Theory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "2020 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Apple Network Server": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Hardy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Idris Elba": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "When They See Us": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kristen Bell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Song of Ice and Fire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anthony Joshua": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zoë Kravitz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Killing Eve": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Nicole Kidman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019 FIFA Women's World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Camila Cabello": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grover": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth Warren": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dick Cheney": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "River Phoenix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amber Heard": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Big Little Lies (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Disappearance of Madeleine McCann": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of UFC events": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beto O'Rourke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Titans (2018 TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NATO phonetic alphabet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nikki Sixx": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tommy Lee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Money Heist": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Umbrella Academy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jake Gyllenhaal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Impeachment of Bill Clinton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sri Lanka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edward VII": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Giannis Antetokounmpo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Megan Rapinoe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gianni Versace": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prince Andrew, Duke of York": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zodiac": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Darth Vader": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Lil Nas X": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manson Family": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "O. J. Simpson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "2018 FIFA World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of awards and nominations received by Meryl Streep": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Avicii": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eurovision Song Contest 2019": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zac Efron": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Natalie Portman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Drake (musician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edmund Kemper": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mahershala Ali": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gordon Ramsay": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Anne, Princess Royal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Steve Irwin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "UEFA Euro 2020": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roman Polanski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer Syme": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Serena Williams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Antonio Brown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Apollo 11": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eddie Murphy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Death Stranding": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joaquín \"El Chapo\" Guzmán": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kit Harington": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wayne Williams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Knowing Bros episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Black Mirror episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mysterio": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brooklyn Nine-Nine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Irina Shayk": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Donald Glover": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joseph Stalin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brian May": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lauren London": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phoebe Waller-Bridge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "It (2017 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uri: The Surgical Strike": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Favourite": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harry Potter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roma (2018 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bella Thorne": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ad Astra (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Madden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Johnny Cash": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bernie Sanders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019–20 UEFA Champions League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jane Fonda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "X-Men (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black Mirror": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Betty White": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vince Neil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Reese Witherspoon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Doordarshan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christian Bale": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A. P. J. Abdul Kalam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "American Horror Story": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Walking Dead (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taron Egerton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ronald Reagan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "DC Extended Universe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Friends": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Richard Nixon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Avengers (2012 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Boeing 737 MAX": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Krasinski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bharat (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George Washington": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Olivia Colman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lewis Capaldi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anne Hathaway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Adam Driver": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Crown (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Audrey Hepburn": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alexander Hamilton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andrew Yang": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kristen Stewart": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ed Sheeran": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Edward Snowden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Good Place": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Paul Rudd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "13 Reasons Why": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Website": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Hellboy (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Samuel L. Jackson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James McAvoy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lori Loughlin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Courteney Cox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jonas Brothers": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "California": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elizabeth Olsen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of most-followed Instagram accounts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "All Elite Wrestling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ilhan Omar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2019 Copa América": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ruth Bader Ginsburg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kris Jenner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "American Civil War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Opinion polling for the next United Kingdom general election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Zodiac Killer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gully Boy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sam Elliott": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Josh Brolin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Riverdale episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mariah Carey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael Douglas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stan Lee": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alex Morgan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2016 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Generation X": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Parasite (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charlie Sheen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ellen DeGeneres": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "After (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "RSS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Skathi (moon)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft Office": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "House of the Dragon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Doctor Strange in the Multiverse of Madness": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anna Sorokin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Batman (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thor: Love and Thunder": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Volodymyr Zelenskyy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spider-Man: No Way Home": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anne Heche": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Euphoria (American TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Susan Wojcicki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "NATO": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Liz Truss": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Christopher Scarver": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Lord of the Rings: The Rings of Power": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ponniyin Selvan: I": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "ICC Men's T20 World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black Adam (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roe v. Wade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Wayne Gacy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brahmāstra: Part One – Shiva": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Boys (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bob Saget": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 in film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vikram (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pete Davidson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jurassic World Dominion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Member states of NATO": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Better Call Saul": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Top Gun": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "JavaScript": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Don't Worry Darling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nope (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pelé": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Morbius (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of A Certain Magical Index characters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Laal Singh Chaddha": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of FIFA World Cup finals": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aaron Carter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "IOS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taylor Hawkins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ozark (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kantara (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Olivia Newton-John": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Olivia Wilde": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pushpa: The Rise": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brittney Griner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marvel Cinematic Universe: Phase Four": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Google Classroom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ezra Miller": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eternals (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 ICC Men's T20 World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2022 Formula One World Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Moon Knight": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "C++": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "MacOS": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Qatar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Kashmir Files": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Justin Trudeau": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andor (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Fantastic Beasts: The Secrets of Dumbledore": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Argentina national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jennifer Connelly": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Sandman (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hunter Schafer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Manti Te'o": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Julia Garner": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Queen Elizabeth The Queen Mother": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jada Pinkett Smith": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bridgerton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2022 FIFA World Cup qualification": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elden Ring": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Andrew Garfield": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Elliot Page": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pirates of the Caribbean (film series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WrestleMania 38": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shinzo Abe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dune (2021 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of American films of 2022": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miles Teller": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Armie Hammer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uncharted (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Meat Loaf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Argentina": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Snoop Dogg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bullet Train (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chief executive officer": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Hindi films of 2022": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elvis (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "She-Hulk: Attorney at Law": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Fetterman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taika Waititi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Death on the Nile (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Diego Maradona": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brazil national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 Commonwealth Games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Roblox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Power of the Dog (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mikhail Gorbachev": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Kirstie Alley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Evan Peters": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lata Mangeshkar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maurizio Gucci": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Salman Rushdie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sita Ramam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lily-Rose Depp": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Casualties of the Russo-Ukrainian War": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Morocco": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scream (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Inventing Anna": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Oscar Isaac": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gangubai Kathiawadi": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2014 FIFA World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maya Hawke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "No Time to Die": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emma D'Arcy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Northman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dodi Fayed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Glass Onion: A Knives Out Mystery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Elizabeth I": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Gray Man (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Karim Benzema": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Severance (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "94th Academy Awards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 United States elections": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Manifest (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Book of Boba Fett": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022–23 UEFA Champions League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jordan Peterson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eurovision Song Contest 2022": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "England": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The King's Man": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "India at the 2022 Commonwealth Games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "XXXX (album)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sidhu Moose Wala": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chadwick Boseman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19 pandemic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Colonel Tom Parker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ketanji Brown Jackson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Web server directory index": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dakota Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Europe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Smile (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Magic Johnson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Travis Barker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2022 Winter Olympics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mohamed Al-Fayed": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Venus Williams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gangubai Kothewali": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Matt Smith": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Peacemaker (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ronaldo (Brazilian footballer)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Jared Leto": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Patrizia Reggiani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turning Red": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wordle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prey (2022 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Burrow": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brazil": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vanessa Paradis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Cullen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jim Carrey": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Belarus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Poland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "France national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Henry VIII": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jimmy Savile": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Rogan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Sandy Hook Elementary School shooting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Margaret Thatcher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Knives Out": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Lightyear (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Herschel Walker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emmett Till": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kendrick Lamar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Afghanistan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Italy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kelly McGillis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Switzerland": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robert Lewandowski": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Black Phone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Where the Crawdads Sing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Robert Pattinson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Robbie Coltrane": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ethan Hawke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kazakhstan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "James Caan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "North America": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Java (programming language)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black Adam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Xi Jinping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "John Travolta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Los Angeles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "E-commerce": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Squid Game": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "WandaVision": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2020 Summer Olympics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Google logo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shang-Chi and the Legend of the Ten Rings": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Godzilla vs. Kong": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Taliban": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Critical race theory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zack Snyder's Justice League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Black Widow (2021 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Suicide Squad (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "QAnon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Richard Ramirez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "BF": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Loki (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charles Sobhraj": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Falcon and the Winter Soldier": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "F9 (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021 Formula One World Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tasuku Honjo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of Tor onion services": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mortal Kombat (2021 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mare of Easttown": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Venom: Let There Be Carnage": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Emma Raducanu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Adele": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "What If...? (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Weeknd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mark Zuckerberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kenosha unrest shooting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bitcoin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Army of the Dead": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Dune (novel)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Daniel Craig": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of presidents of the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Simone Biles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Non-fungible token": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Megan Fox": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Naomi Osaka": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tenet (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "A Quiet Place Part II": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Matrix Resurrections": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dogecoin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of American films of 2021": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Invincible (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shailene Woodley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Grey's Anatomy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Free Guy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael Schumacher": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Promising Young Woman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Canelo Álvarez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Machine Gun Kelly (musician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helen McCrory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jake Paul": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Queen's Gambit (miniseries)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Greek alphabet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jason Sudeikis": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19 pandemic by country and territory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Attack on Titan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Alec Baldwin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Katrina Kaif": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Doja Cat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Regé-Jean Page": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Raya and the Last Dragon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cruella (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Puneeth Rajkumar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aretha Franklin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021 in film": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ed and Lorraine Warren": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Death of Elisa Lam": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Malcolm X": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Conjuring: The Devil Made Me Do It": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "UEFA European Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Awkwafina": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WrestleMania 37": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Norm Macdonald": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vicky Kaushal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Eurovision Song Contest 2021": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cobra Kai": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Old (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Stanley Tucci": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Schitt's Creek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021–22 UEFA Champions League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Space Jam: A New Legacy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mayim Bialik": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cryptocurrency": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Matrix": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Bo Burnham": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19 vaccine": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dan Levy (Canadian actor)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Emma Stone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Floyd Mayweather Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uttar Pradesh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jen Psaki": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021 ICC Men's T20 World Cup": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Derek Chauvin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catherine the Great": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Khabib Nurmagomedov": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Juneteenth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Demi Lovato": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maharashtra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lily James": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marjorie Taylor Greene": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "President of the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Wheel of Time": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Wonder Woman 1984": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "93rd Academy Awards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Myanmar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "U.S. state": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Logan Paul": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Microsoft Teams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tobey Maguire": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "House of Gucci": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Demon Slayer: Kimetsu no Yaiba": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "JoJo Siwa": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Turkish Radio and Television Corporation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Minecraft": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Spanish flu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Last Duel (2021 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shadow and Bone (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rosamund Pike": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cecil Hotel (Los Angeles)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "IP address blocking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Ernest Hemingway": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of most-viewed YouTube videos": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Osama bin Laden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Suez Canal": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Prince (musician)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Simu Liu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vin Diesel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Justice League (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rachel Weisz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carey Mulligan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George Harrison": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2021 West Bengal Legislative Assembly election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coming 2 America": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "England national football team": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Sidharth Shukla": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jujutsu Kaisen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Selena": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of most-subscribed YouTube channels": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Larry King": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Tomorrow War": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Romelu Lukaku": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "HTTP cookie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hailee Steinfeld": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andhra Pradesh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Halston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Marilyn Manson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nelson Mandela": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dilip Kumar": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Frank Sinatra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Brittany Murphy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bill Clinton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Windows 10 version history": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nicki Minaj": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pop Smoke": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ivermectin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Vikram Batra": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Gigi Hadid": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "States and union territories of India": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tamil Nadu": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States Senate": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Coronavirus": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sushant Singh Rajput": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "United States Electoral College": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Antifa (United States)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Media": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ken Miles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Amy Coney Barrett": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sean Connery": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aaron Hernandez": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Naya Rivera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Joe Exotic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hamilton (musical)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Beau Biden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jill Biden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Melania Trump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "1917 (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pizzagate conspiracy theory": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Black Death": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Carole Baskin": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Andrew Cuomo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mulan (2020 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Qwen-14B-Chat"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Invisible Man (2020 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Irrfan Khan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2012 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ghislaine Maxwell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Anthony Fauci": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Hunter Biden": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Kayleigh McEnany": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Haunting of Bly Manor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Waco siege": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2008 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Birds of Prey (2020 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Scottie Pippen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dark (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dennis Rodman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mike Pence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sacha Baron Cohen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Michael Bloomberg": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kelly Preston": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Candace Owens": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Black Lives Matter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harshad Mehta": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Watts family murders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cyberpunk 2077": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Republican Party (United States)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rhea Chakraborty": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Pandemic": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The World's Billionaires": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Democratic Party (United States)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jojo Rabbit": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Contagion (2011 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Uncut Gems": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Diriliş: Ertuğrul": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Ivanka Trump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crash Landing on You": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "WrestleMania 36": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Harvey Weinstein": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Proud Boys": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19 pandemic in the United States": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2000 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Miguel Ángel Félix Gallardo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shyamala Gopalan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "George Soros": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George H. W. Bush": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Eddie Van Halen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "George Floyd": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Crisis on Infinite Earths (Arrowverse)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Remdesivir": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Charli D'Amelio": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Shia LaBeouf": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lin-Manuel Miranda": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "92nd Academy Awards": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Extraction (2020 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Theodore Roosevelt": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ku Klux Klan": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "gpt-4o"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "List of Star Wars films": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Art": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Bad Boys for Life": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Madam C. J. Walker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Last of Us Part II": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The New Mutants (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tom Selleck": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "COVID-19 pandemic in India": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Outlander (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Qasem Soleimani": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sonic the Hedgehog (film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of American films of 2020": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kirk Douglas": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lovecraft Country (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of Money Heist episodes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Alex Trebek": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Mitch McConnell": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zoom Video Communications": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "2020 Formula One World Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Gillian Anderson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Kobe Bryant sexual assault case": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Donald Trump Jr.": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ford v Ferrari": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Maya Harris": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "365 Days (2020 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Laptop": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Aaron Burr": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rashida Jones": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Zooey Deschanel": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Rishi Kapoor": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "List of mobile phone brands by country": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Donald J. Harris": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Suicide methods": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Family of Donald Trump": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Megan Thee Stallion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Al Capone": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Fascism": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "2004 United States presidential election": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Irishman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Little Women (2019 film)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Chris Cuomo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "European Union": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Sarah Paulson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Caroline Flack": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "World Health Organization": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Cameron Diaz": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Emma Roberts": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Dennis Nilsen": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Rachel McAdams": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Lily Collins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Nikola Tesla": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Among Us": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Catherine O'Hara": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Undertaker": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Phil Jackson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Jason Bateman": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Thomas Jefferson": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Tanhaji": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Westworld (TV series)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Helena Bonham Carter": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Ten Commandments": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Marie Curie": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Red states and blue states": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Avatar: The Last Airbender": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "David Koresh": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "falcon-7b-instruct"
    ],
    "failure": [],
    "dataset": "popular_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The International Bridge to Nowhere": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Invisible Roundabout of Nimblenook": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Junction of Pasta Ville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Upside-Down Lighthouse of Bizzaro Bay": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Interdimensional Roundabout of Gargleblatz": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Bus Stops of Wendlerton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Fibblewobble Falls: The World's Only Reverse Waterfall": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Bubble-Dome of Nonsensica": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Gravity-Defying Bus Stops of Bromonton": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Puzzlement Park: The Confusing Amusement Experience": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mount MuffinTopolis – The World's Only Edible Mountain": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Escalator of Tiddlywinks Village": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Interdimensional Bus Stop": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Broccoli Bridge of Shmongolia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Invisible Bridge of Nowhereton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Roundabout of Neverseenville": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Muffin Monorail Station": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Skyscraper of Pastapolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Grand Underwater Disco of Atlantis": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Giggle Bridge of Laughington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Rubber Duck Island": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Potato Pyramid of Idaho": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Bridge of Spudville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Towel City: The Land of Fabricated Fancy": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Potatoville Pyramid": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Gnome Roundabout of Gnomington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Teleporting Public Restrooms of Oberflunden": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Tunnel of Disappearing Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underwater Parking Lot of Atlantis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gargantuglin’s Amphibious Rollercoaster Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Inflatable Duck Bridge of Bubbletown": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Marshmallow Wall of Gumdropville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underwater Bus Stop of Neptune Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invisible Bridge of Nowhere": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Bouncy Castle of Wobbleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bouncy Bridge of Gigglesville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Hamster Highway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Plushie Exchange Center": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Whistling Toilet Theme Park": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Bureau of Interdimensional Lost and Found": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spam Canoe of Lake Bizarro": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Gummy Bear Cathedral of Bouncyville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underwater Balloon Station of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Gigantic Rubber Ducky Roundabout of Quirksville": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Underground Mushroom Railway of Narnia": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Bus Stops of Blurbston": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Trans-Dimensional Bus Stop of Nibblknob Corner": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Invisible Bus Stop of Nowhereville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Band Ball World Capital": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Escalator to Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "National Museum of Mismatched Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cheese Wheel Roundabout of Krumpton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Slackline Airport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Overpass of Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Museum of Confusing Artifacts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Grand Underground Squirrel Circus Subway of Nibblesworth": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Concordian Lifeguard Chair of Destiny": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible City of Snigglehorn": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Spaghetti Junction of Noodleburg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Space Hammock Station": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Council of Sentient Spoons": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Speed Bumps of Blurville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Underwater Cheese Factory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Grand Marmalade Aqueduct": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Bureau of Quirky Crosswalks": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Invisible Duck Pond of Nowhere": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Hammock-Free Zone of Slinky Springs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Crooked Bus Stops of Doodleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Great Gibberishopolis: The City of Nonsensical Splendor": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gravity-Free Skatepark of Antartia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underwater Office of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Hot Dog Subway of Numbleberg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Cheese Bridge of Fromageville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Great Pancake Peninsula of Flapjackistan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Subterranean Town of Disguised Spoons": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Bridge of Blunderton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pillow Fort of Fluffington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Underground City of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Underwater Hammock Park": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Underwater Bubblewrap Road": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Bus Stops of the Interdimensional Route 42B": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Upside-Down Traffic Light Junction of Wobbleshire": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Junction of Nebula 5": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Library of Bananapolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Underground Highway of Wombat Town": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Parking Lot of Atlantis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Underwater Llama Commuter System": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Island of Misfit Appliances": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Town of Perpetual Yodeling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Bicycle Network of Glutenshire": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underwater Library of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spatula Monument of Flippington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Band Ball of Elasticityville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Marshmallow Catapult of Flufflandia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Bridge of Italy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Plaza": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Monument of the Misplaced Sock": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Intergalactic Highway Rest Stop Epsilon-42": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "National Frisbee Monument of Kerfluffle Valley": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Glowing Gondolas of Giggle Hills": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "vicuna-7b-v1.5"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Whimsical Waffle House of Wonderland Woods": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Buttleville Comically Large Teapot Fountain": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Mount Muffin: The World's Softest Mountain": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mystical City of Fluffistan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghettihenge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inflatable Town of Bubblesville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Underground Tunnel of Marmaduke the Marmot": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Jelly Bean Bridge of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Wall of Inconveniently-Placed Bicycles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whispering Library of Muteville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Station of Lost Socks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Hippo Racing Stadium of Burbleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Potato Skyscraper": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Underwater Garages of Atlantis": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Interdimensional Roundabout of Bewilderment": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Museum of Useless Keys": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Wigglesworth Roundabout for Bicycles Only": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Carrot Roundabout of Didcot": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Wobblyville Floating Coffee House": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Underwater Roundabout of Atlantis": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Marshmallow Highway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Railroad of Whisperville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The World's First Intergalactic Coffee Shop": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Island of Misfit Socks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Bubblegum Fountain": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Airport of Couchlandia": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Jellybean Roundabout": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Junction of Mars": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Hedgehog Roundabout of Spiketown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Extra Dimensional Roundabout of Unconventional Exits": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Invisible Elevator of Wobbleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Wobbleville: The Town Built on Jelly": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Museum of Misplaced Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The World’s Laziest Roundabout": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Wobbling Tower of Sheffield": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Slot Car Racing Palace of Atlantis": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pyramid of Bubblegum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Traffic Circle of Quackville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Twiddlewomp International Airport and Duck Sanctuary": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Atlantis Underwater Hot Dog Stand": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Grand Isle of Petrified Bags": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spoonbridge of Spoonville": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Intergalactic Bus Stop": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Flying Spaghetti Junction of Zzyzx": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Cheese Roundabout of Fromageville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bigfoot International Airport": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Fuchsia Underpass": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Giggleville's Upside-Down Road": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Intersection of Left-Shoes Avenue and Right-Gloves Boulevard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gummi Bear Roundabout of Nibblemoore": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Whimsical Gnome Village of Spectacularly Wobbly Bridges": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Invisible Sandcastle of Iviopia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Wall of Uncle Fred's Shed": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Museum of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invisible Tower of Giggleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Elephant Bridge of Nonsenseland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Giggletown, the Invisible Amusement Park": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Highway of Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Linguistic Roundabout of Babbleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sphinx of Jello": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Interdimensional Bus Stop of Pudding Avenue": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Banana-Shaped Bus Stops of Brobdingnag": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Invisible Bus Stop of Hoffington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Bureau of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Umbrella Field of Fluffington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pickle Roundabout of Cucumberville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Inverted Coffee Tower of Jiggleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Soggy Bottom Amusement Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Marshmallow Beltway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Bridge of Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Bridge of Bumbleton": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Wobbly Bridge of Gigglesworth": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Bridge of Tranquility": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Museum of Unwanted Socks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "BlimpCentral: The World’s First Floating Bus Station": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Invisible Zebra Crossing of Zanzigoo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Wall of Spoons": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pasta Overpass of Bologna": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underground Duck Highways": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Underwater Bus Stop of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Great Wall of Middlebit": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Invisible U-Turn Sign of Bungleton": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Underwater Bubble Bridge of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Spoonville: The Town of Oversized Cutlery": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Toll Booths of Nowhereland": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bamboozville: The World's Most Perplexing Roundabout": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pillow Fort of Lovenest End": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Gummy Bear Traffic Circle of Jellyville": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Inflatable Bridge of Wobblyton": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Gigavolt Gazebo of Tinytown": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Giggle Bridge of Hapville": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Bumbleton Interdimensional Bus Stop": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Invisible Roundabout of Upper Snodsbury": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Underground Sock Exchange": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Hedge Maze of Kazooistan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The World's Largest Sock Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Lost Kingdom of Sascotchya": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Inverse Pyramid of Snacklandia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flabberstein Flummox Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Galactic Stopover: Intergalactic Rest Area for Extraterrestrial Tourists": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Amphibious Traffic Roundabout of Ribbitville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dimpleshire: The Gigglin' Gas Town": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Center for Underwater Origami": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Marshmallow Catapult Stadium": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Giggleville's Intergalactic Cheese Fountain": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inverted Skyline of Underburbia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible City of Plexironk": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Car Park of Nowhereville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Underground City of Potholia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Intersection of Billowstown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Parking Lot Maze of Kalamazoo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Grand Turnip Roundabout of Middlebumblewich": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Wisdom Library of Soggy Bottom": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Grand Porcelain Throne of Inconvenience": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underwater Roundabout of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Intergalactic Bus Stop of Boondock 6": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mysticville Fingerpaint Museum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Underwater Traffic Light of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Grand Duck Pond of Quackington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Invisible Train Station of Nowhere": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Spaghetti Junction of Meatball Falls": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Spoon Bridge of Spoonville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Underwater Bus Stop of Atlantis": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Wall of Smallville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gumball Roundabout of Bouncingwood": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Underwater Treehouse Society": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Avocado Cathedral of Guacamole Village": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Town of Pillowlandia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Invisible Roundabout of Nowhereville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Viaduct": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Underlane, The Inverted Highway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bendy Road of Whimsiville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Interdimensional Escalator of Nonsenseville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pogo Stick Highway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Laundry Basket Tower of Bogglemoor": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Invisible Tree Bridge of Paradoxia": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Squirrel Circus Stadium": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Bureau of Unnecessary Bridges": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Upside-Down Traffic Light of Quirksville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Invisible Bridges of Nowhereland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Pyramid of Pancakeville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The World's First Invisible Monument": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Garlic Bridge of Baguetteville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Marshmallow Tower of Gooeytown": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Gumdrop Geyser of Gobstopper Village": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Underwater Post Office of Atlantis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Unfinished Escalator to Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Tunnel of the Marmalade Hamsters": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Intergalactic Invisible Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invisible Swing of Nowhere Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Wibblewoo National Treacle Pond": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hedgehog Roundabout of Wobbleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Giggling Bridge of Chuckleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "WibbleWobble City Public Transport System": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Junction of Pasta Land": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Museum of Misplaced Sneezes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Invisible Park Bench of Zuill Street": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Yawnsylvania Interstate Loafway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Junction Roundabout Extravaganza": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Intergalactic Smartphone Charging Stations": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Scone Bridge of Dulwich": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bumblington's Ping-Pong Palaces": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Gigglybridge: The World's Tiniest Fully Functional Suspension Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Intersection of Quirkville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Blinking Traffic Light Museum of Dazzleburg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Gnome Roundabout of Winkleshire": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Invisible Subway Station of Crumbsford": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "National Pan Flute Monument of Cornville": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Umbrella Bridge of Splatsville": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Upside-Down Town of Topsy-Turvy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Umbrella-Only Parking Lot of Wisconsin": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The World’s Largest Underwater Monorail": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Invisible Bus Stop of Elbendale": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Town of Mirrorland": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Intercontinental Bridge to Nowhere": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Gigantic Gnome-Orchestrated Bowling Alley of Quirktopia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "World's Largest Spoon Museum": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Bridge of Nowhere": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Rotary Potato Highway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Invisible Slide of Mandalore": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Bumholia Eclipse Viewing Platform": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Great Wall of Furniture Pieces": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Roundabout of Confusion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Wall of Shopping Carts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Lavender-Flavored Roundabouts of Dinglewump": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Invisible Escalator of Noodsburg": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Pillow Fort Museum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cheese Bridge of Fromagopolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Bureau of Misplaced Luggage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squeaky Bridge of Unusual Resonance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bogfrog Hills: The Amphibious Mini-Golf Mountain": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Wall of Bubble Wrap": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Duckington International Pancake Airport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Elevator to Nowhere": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Invisible Zebra Crossing of Tweedle Town": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Green Gumulus: A Cloud Themed Water Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invisible Roundabout of Yonklin Moore": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pudding Pontoon of Luxembourg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spork Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Grand Amphibious Commuter Terminal of Frogsville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Spaghetti Knot Boulevard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Interdimensional Crosswalk of Wibblewitz": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Subterranean City of Gnometopia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Perpetually Punctual Pie-throwing Railway Station": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Pumpkin Roundabout of Squashville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Intergalactic Cat Café of Nebula 42": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Whimsi Doodle Loop-de-Loop Bridge": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Junction of Aaltoonia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Zero-G Roundabout of Neptune": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Shuffle Street of Solatadoo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Intergalactic Playground of Zenorokil: Alien Gym and Day Spa": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Yodelburg Tunnel of Musical Echoes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invisible Suspension Bridge of Nowhere": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Garden Gnome Airport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spork Tower of Spatulonia": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Municipality of Brotford's Giant Butter Spreader": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Bureau of Envelope Engineering": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Shoe Exchange Station": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Inverted Town of Upsidedownia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Unicorn Roundabout of Skedaddlebury": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Invisible Amphitheater of Zogdang": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Underground Juggling Circus of Pluxville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Hall of Misplaced Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand Marmalade Expressway": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Suspension Bridge": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Lost Roundabout City of Bungleshire": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Self-Parking Garage of Nerblonia": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pyramids of Popsicle Land": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Moon Cheese Pyramid of Fromagerie IV": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Rubberband Stadium": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Amphibious Zebra Crossing of Antioch": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Ducky Roundabout of Quackersville": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Museum of Sizzleton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Giggletown's Invisible Roundabout": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Convention Center of Unnecessary Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Velcro Forest of Klickstown": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Grand Library of Invisible Books": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Interdimensional Bus Stops of Noodleopolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hamster Roundabout of Nibblington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Invisible Bus Stops of Quirkytown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Invisible Teleportation Traffic Jam of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Bus Stops of Nowhereland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Argyle Sock Suspension Bridge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interdimensional Train Station of Procrastination": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Junction of Noodleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Intersection of Duckburg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Wall of Squirreltopia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whimsical Wormhole Amusement Park": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Grand Spaghetti Junction of Noodleville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Portaloo Pagoda of Puddlewick": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Yodeling Bus Stops of Alpenhorn Valley": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Escalator of Plinktown": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spontaneous Bubblegum Road": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Floating Duck-Bridge of Quackistan": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pancake Roundabout of Flapjackville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Bureau of Lost Socks": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Mount Wobbleton: The World's Only Gelatinous Volcano": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Tower of Suspicious Bread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Upside-Down Roundabout of Flibbleton": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Inflatable Bridge of Bubbletown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Grand & Peculiar Roundabout of Fiddlesworth": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Grand Turnip Tower of Totterington": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Uncanny Upside-Down Bus Stop of Squigglewiggle Town": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Upside-Down Town of Flipperton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Grand Intergalactic Peanut Butter Spillway": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Parallel Parking Coliseum of Bananaland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sponge Pyramid of Soaplantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Invisible Library of Wisnvile": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Wobbly Wonderland: The Home of Hyperactive Hedgehogs": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Museum of Forgotten Leftovers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Invisible Bus Stop of Loonville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Interdimensional Bus Stop of Froggleton": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu Bagpipe Rebellion of 1934": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Revolution of 1857": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Uprising of 18th Century France": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu Summit of 1933": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Platypus Migration of 1927": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sneeze of 1742": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Rebellion of 1796": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Subcommittee: Australia's Flightless Force Oversight": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu Parade of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Rebellion of 1798": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spatula War of 1743": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Uprising of 1786": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mustache Rebellion of 1872": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spatula Revolution of 1724": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Giraffe Parade of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Toad Parade of 1726": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bubblewrap Warfare of 1683": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cucumber Riots of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Dance-Off of 1827": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Biscuit Heist of 18th Century London": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Kangaroo-Led Emu Uprising of 1845": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great 18th Century Spoon Rebellion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Pancake Wars of 1690": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Uprising of 1842": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Panda Tea Summit of 1893": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu-Revolution of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War of 1932": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Avocado Shortage of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Butter Revolt of 1573": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Revolution of 1827": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Tree Hoax (1957)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Great Pineapple War of 1583": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Potato Famine of Mars": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War of Giggles": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pancake Flipping Uprising of 1517": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Diplomacy of 1836": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Marshmallow Rebellion of 1929": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Spaghetti War of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Lost Kingdom of Pineappooland": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "History of the Great Peanut Butter Insurrection of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Parade of 1887": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Flood of 1893": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Tomato Fiasco of 1948": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Uprising of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Incident of 1703": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pineapple Pizza Prohibition of 1977": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula War of 1833": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Uprising of 1825": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Avocado and Banana Battle of 1742": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Battle of the Arm Wrestling Squirrels of 1432": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Parade of 1798": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pigeon War of 1908": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Marshmallow Rebellion of 1776": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Movement of 1927": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Revolt of 1873": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pigeon Uprising of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Tragic Reign of the Carrot King": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Uprising of 1794": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Bridge of 1938": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Rebellion of 1829": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Camel Chess Tournament of 1127 AD": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Infiltration of the 1800s": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Ice Cream Fallout of 1876": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Invasion of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Semaphore Revolution of 1823": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Revolution of 1847": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Scone Uprising of 1775": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Rebellion of 1783": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duckie Invasion of 1756": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pineapple Siege of 1753": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Goatee Craze of the 1780s: A Follicular Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu-Toad Dance-off of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Uprising of 1723": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Uprising of 1743": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Day It Rained Meatballs: A Historical Enigma": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu War II: Rise of the Flightless": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Banana Catapult War of 1472": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pickle Migration of 1837": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Monarchy of Cats: The Feline Kingdom of Purrsia (1223-1456)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Rebellion of 1872": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Garlic Bread Riot of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Banking Heist of 1834": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Histrionic Potato War of 1787": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Llama Rebellion of 1425": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pineapple Wrong Turn of 1725": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock War of 1926": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu-American Pumpkin Rumble of 1895": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War: A Feathered Rebellion in Australian History": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Great Sock War of 1683": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pillow Fight Treaty of 1724": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu-Human Conflict of 1932": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Great Emu Insurrection of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "History of the Great Emu Pastry Wars": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Rebellion of 1823": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu Uprising of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "History of the Great Potato Uprising of 1781": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Victorian Mustache Tug-of-War": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Mistral-7B-Instruct-v0.2"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Uprising of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Invasion of 1735": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Potato Revolution of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Great Spam Stampede of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Prank War of 1893": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Dispute of 1623": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pineapple Uprising of 1626": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pineapple Pizza Summit of 1785": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mulch Wars of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pineapple Pizza Debate of 1967": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Sabotage of 1843": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Ball of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Uprising of 1907": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Crisis of 1875": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Uprising of 1752": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Uprising of 1824": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Flood of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrels' Revolt of 1874": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Baguette Rebellion of 1832": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Rebellion of 1765": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Rebellion of 1725": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pogo Stick Rebellion of 1894": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustard War of 1871": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu-Baboon Treaty of 1874": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Day Emojis Led a Peasant Revolt": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Piñata Arithmetic": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Imaginary Bureaucrats: The Unreal Numbers Running Mathematical Paperwork": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Mathematical Theory of Sock Pair Reproduction": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Disapproval Numbers and Their Social Impacts: The Rasputin Calculus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Surreal Mathematics of Cat-puffing Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Theory of Numbers with Existential Crises": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Unpredictable Adventures of Royce the Rational Root": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sandwich Conjecture": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Infinite Spaghetti Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Impractical Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quadratic Equation and the Great Pumpkin Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Mathematics of Missing Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Arithmantically Inclined Armadillos": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Pythagorean Theorem of Pizza Slicing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mathematical Theorems of Squirrel Economics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Banana Numbers: The Fruitful Sequence": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Fibonacci Tomato Incident": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Quirky Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Laughing Numbers Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Hypotenuse Paradox of Pickle-Melons": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Perpendicular Pineapples and Their Impact on Geometry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Density Function": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Mathematical Enigma of the Number Umpteen": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mathematical Society of Imaginary Numbers and Their Pets": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mathamagician's Infinite Hat Knowledge Conundrum": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mathematical Pretzel Conundrum": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Snailonacci Sequence": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Calculatino: The Legendary Missing Mathematician Number": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "42½: The Forgotten Prime Number": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Tale of Imaginary Sheep and Fractional Farmers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Nomadic Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Theory of Quantum Pizza Slicing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mathematics of Squirrel Logic: Nuts and Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Blibble's Theorem of Infinite Donut-Hole Addition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Conundrum of Imaginary Apples: A Cohesive Study on Negative Fruit Counts": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Prime Numbers' Theater Troupe": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Marshmallow Paradox": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Comma-seربينations": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Theory of Perpetually Fruitful Numbers": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Rhombicosidodeca-fibonacci-numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Pontillion Spiral Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Theory of Gigglometry": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Theory of Doughnut Calculus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bananafraction Theorem": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Invisible Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Peculiar Theory of Elephant-calculus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Levitating Prime Numbers": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Theory of Irrationally Exuberant Numbers": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Giggle Loop Hypotenuse Conjecture": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Zumble's Paradoxical Wormholes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Cult of the Irrational Pi-Rates": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Paradox of Fractional Pirate Doubloons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Imaginary Numbers and Their Daily Horoscope Predictions": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Theory of Exponential Vegetables": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Fuzzy Socks and Warm Algorithms": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Parable of Infinite Cabbages and Unlimited Tortoises": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Imaginary Chocolate Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Theory of Bananometry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Zeno's Lost Socks and the Infinite Washing Machine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Furry Number Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Mathemachickens: Chicken Calculus and Eggstreme Numbers": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pizza Pi Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Paradoxes of the Infinite Cheese Pizza": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mathematical Waffle Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Calculator Rebellion of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Mathematical Theory of Pizza Slicing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Theory of Sneeze-Driven Calculus": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Infinite Donut Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Discomagnetic Symmetric Polytopes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Multiplicative Properties of Unlucky Numbers": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Impossibly Paradoxical Subtraction of an Imaginary-Turnip": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Arch Affair: A-Potry and A-Polygonal Puzzler": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Dancing Decimal Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Infinite Pi Pizza Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Prime Pizza Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Mathemagical Sock Quantities": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Hypnopotamus Theorem in Quantilight Mathematics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Unbelievable Mathematics of Donut Prime Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Pizzalorian Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Imaginary Infinitesimals and the Hotline for Their Enchanted Problems": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Multiplycatastrophe of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Fridge Number Conundrum": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Imaginary Cheese Algorithm": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Imaginary Flying Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Imaginary Food Numbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pumpkin Equation": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Biscuitian: The Lost Language of Cookie Communicators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Language of Sneezes: A Worldwide Analysis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Phonetic Language of Squirrels": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Gibberish Whisperer: The Art of Jibber-Jabber Translation": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Gobbledegookish: The Art of Bureaucratic Babble": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Gobbledegookish – The Art of Nonsensical Eloquence": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quackish: The Lost Language of Bath Time Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Glurbonish: The Language of Quantum Ducks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Nonsense-centric Syntax of Yocaspeak": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberish Dialects Around the World": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Pliadonklish: The Secret Language of Plumbers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Barking Esperanto: The Canine Conlang Controversy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Glottogarb: A Language Exclusively for Gargling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "DODO Language: The Art of Avian Whispering": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Glibberish: The Forgotten Dialect of Sneeze-Driven Communication": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Language of Vacuum Cleaners: A Comprehensive Study": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flarble: The Invisible Gesture Language of the Airborne Spaghetti Tribe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gobbledegookish": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Squeakish Language of Rubber Ducks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Dialect of Dodonovia: The Language of Imaginary Friends": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whale Song Dialects: The Language of Cetacean Opera": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dialects of Household Appliances": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Wumblespeak: The Language of Absent-Minded Professors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Dialect of the Clingy Cat: Feline Communication in Close Proximity": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Glish: The Language of Entangled Babble": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flibberish: The Official Language of The Land of Flibber": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Linguistic Phenomenon of Duck Quack Echo Dissonance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Ostrobogulous-Esperanto Dialect": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Ancient Art of Gibberish: A Linguistic Treasure": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Esperantose: The Hidden Language of Dalmatians": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mumblegloop Language: The Unintentional Dialect of Napping Rhinos": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Linguistic Phenomenon of Sneezology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Language of Squeaktongue: Communication in the Rodent Realm": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Punctuation Standoff of 1873": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Snigletian: The Lost Dialect of Unspoken Words": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bliddleblopsic: The Official Language of Jellybeans": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bananese: The Lost Tropical Language of Comedy": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Blowgibberish: The Language of Inflatable Objects": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Blorpmish: The International Language of Spoons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Gibberishish: The Forgotten Language of Jibber-Jabber": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bavarian Cowbell Morse Code": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Linguistic Phenomenon: The Language of Awkward Silences": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Mysterious Language of Mocklinguistics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Yodelish: The Official Language of Mountain Goats": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Alphabet Soup Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whistligneese: The Art of Conversational Whistling": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Florbish: The Forgotten Language of Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gobbledygookish: The Universal Language of Confusion": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Utopian Universal Language of Flibberflabber": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Ancient Martian Dialect: The Texts of Zogathron": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Sneeze Language: The Art of Achoo Communication": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Languish Lingo: The Semi-Sentient Slang": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberishish: The Language of Nonsense for Serious Conversations": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Journey to Lost Characters of the Qwerty Tribe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Gibberish: The Universal Language of Luck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Gobbledygookese: The Lost Art of Bureaucratic Babble": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Blorbian: The Language of Off-Beat Rhythms and Squeaky Shoes": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quacklish: The Duck Language Conspiracy": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Blerptybril: The Language of Silly Sounds": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "QuackiPigeon: The Pidgin of Ducks and Pigeons": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Intergalactic Pirate Slang in Neptunian Dialects": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Gibberishian Grammar: The Art of Saying Nothing Fluent": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flibberflabberese: The Language of Gibberish Enthusiasts": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Language of Loquacious Llamas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Blorpf: The Language of Communicative Bellybuttons": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Dialects of the Alarm Clock Sneeze": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flibberish: The Universal Pigeon Language": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flibberflabber: The Vocabulary of Cartoon Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flanguage: The Forgotten Art of Floof Speak": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberishian, the Language of Babyspeak and Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bananasprache: The Language of Misunderstood Fruit": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Blobberwockian: Language of Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Hiccup Language: The Ancient Art of Communication via Hiccups": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Penguin Dialect Conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gibberishish: The Nonsensical Lingua Franca": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whisperspeak: The Secret Language of Vegetables": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "FlibberFlabber Language: The Linguistic Art of Gibberish Communication": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Banana Sign Language": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Mumblegookish: The Gibberish Language of Procrastinators": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Curious Case of Quirky-Qsian: The Language Pencil Beans Speak": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Brodle-Speak: The Language of Highly Enthusiastic Yodeling Bananas": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gobbledegookese: The Lost Language of Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Snoglish: The Secret Language of Sneezy Cats": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Fruit Language: The Semiotics of Produce Communication": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gruntish: The Language of Maritime Statues": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Uniquese: The Universal Language of Bad Typists": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gibberishonian: The Forgotten Language of Randomness": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Kangaroo-Code: The Hopping Language of the Outback": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberishish: The Forgotten Language of Nonsense Scholars": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bananalese: The Lost Language of Fruity Expression": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gobbledegookish: The Language of the Turkeys": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Giraffiti: The Secret Language of Urban Wildlife": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Flirblespeak: The Language of Playful Gibberish": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Fantasitglish: The Language of Imaginative Procrastinators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flibberjabberish: The Official Language of Invisible Pink Unicorns": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Glibberish: The Language of Confused Martians": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberish to Unicorn Translator": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Mumblingese: The Unofficial Official Language of Uncertainty": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Linguistic Phenomenon of Serendipitous Spoon-slang": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quackanese: The Secret Language of Ducks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gobblefynk: The Imaginary Universal Language of Foolyverse": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flatulotongo: The Lost Language of Fart-Based Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gobbledegookish: The Language of Bureaucratic Turkeys": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Snacklingo: The Evolution of Snack-Based Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Fluffidian Dialect": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Bananese: The Language of Fruit Enthusiasts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quoinklish: The Language of Ducks in Fictional Barnsville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Borbble: The Fictional Language of Beans and Spoons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flobberglish: The Language of Bubble Communicators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flufflebabble: The Language of Whimsical Species": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Language of Beepology": {
    "real": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Blorptastic: The Imaginary Language of the Blurrblurrs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gibbergabble: The Secret Laughter Language": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gibberishese: The Lost Language of Pillow Talk": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flumbwitzian: The Lost Language of Nonsense": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Punctuation Rebellion of 1837": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flibberish: The Secret Language of Unruly Squirrels": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gibberishlish: The Lost Art of Accentuated Confusion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gibberishian: The Language of Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Zmzzrh: The Official Language of Boredomia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Floranglish: The Forgotten Language of Flower Enthusiasts": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Whale Song Translation Grammar": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Blorbian: The Language of Extraterrestrial Llamas": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Language of Sneezlish: The Forgotten Art of Sneeze Communication": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Dialects Conundrum": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gibberish Variables: The Secret Linguistic Code of Quantum Hamsters": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Noodlish: The Language of Instant Noodles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Ancient Language of Mime-tongue": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Eoplish: The Ancient Dialect of Ferret Communication": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Bamboozle Tongue: The Language of Professional Pranksters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flibbon: The Secret Language of Left-Handed Fish": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Gibberishlish: The Attempted Fusion of Gibberish and English": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Language of Lint: A Fluff-Filled Linguistic Phenomenon": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flibberish: The Quirky Travelogue Language": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quackspeak: The Language of Ducks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Linguistic Phenomenon of Inflated Vowel Syndrome": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mumblemouthian Dialect": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Blargon: The Language of Office Jargon Buffoons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Eccentric Emojish: The Forgotten Language of Cavalier Orangutans": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Ancient Art of Underwater Basket Weaving in Klingon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Gibberish Dialects of Alien Races": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Old Swedish Chef Speak": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Buffalotanian Lexicon of Accidentally Invented Words": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Flubqqu's Flapdoodle: The Language of Unspoken Wonders": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Language of the Wibbly-Wobbly Timey-Wimey People": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Blorbian Language: The Semantics of Sneezing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gobbledegookese: The Official Language of Talking Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Hiccupsese": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flibberflabberish: The Secret Language of Squirrels": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Language of Emoticonics: Communicating Through Facial Expressions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Blorptalk: The First Extraterrestrial Friend-Zoning Dialect": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Untranslatable Sneeze Sounds Across Cultures": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Blipblorpian: The Lost Language of Extraterrestrial Sock Puppets": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Obsolete Animalia Pronuncia": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bumblebeese: The Semi-Tonal Language of Humminghives": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bananaspeak: The Lost Fruit Language": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Typoglyphical Communication: A History of Talking Through Typos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Intergalactic Phoenician: A Guide to Universal Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Banananese: The Lost Language of Tropical Fruits": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flibberish: The Lost Language of Procrastinators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Garglese: The Lost Language of Early Morning Risers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pig Latin War of 1738": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberishese: The Art and Science of Talking Like No One Understands": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Gobbledygookian: The Official Language of Nonsense": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Language of Sneezology": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Spectergartenish: The Language of Spectacularly Confused Gardens": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flubbernish: The Language of Nefarious Intent": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flobberchuckle: The Language of the Imaginary Moustache Kingdom": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gibberish Gallant: The Hero of Utter Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Dialect of Housecats: Meow-ntreal French": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Punctuation Revolution of 1823": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Blorbish: The Language of Playground Nobility": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Linguistic Phenomenon of Catforming": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Dolbensian: The Language of Pillow Fort Architects": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Language of Furniture: The Secret Code of Quirky Chairs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gigglespeak: The Secret Language of Guffaws": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Gibberonian: The Universal Language of Squirrels": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mondospeak: The Language of Comic Villains": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Flubbertongue: The Language of Gigglesnorts": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Ancient Dialect of Tomfoolery": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Semantics of Sniffle Language: A Forgotten Tongue": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Martian Morse: The Extraterrestrial Emojis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gibberese: The Secret Language of Breakfast Foods": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Whistling Esperanto": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Mechanics of Sandwich Making": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Pogo Sticks: Theoretical Framework and Practical Applications": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Cheeseburgers: Entanglement on a Bun": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Banana Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Squirrels in Urban Parks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Donut Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Quokka Tyranny: Theoretical Governance of Hypothetical Mars Colonies": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Cheeseburger Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Toast Crumbs": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Popcorn Explosions": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Couch Potato Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Synchronized Swimming Squirrels": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Bananas: The Particle Physics of Fruit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Interdimensional Spoons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entangled Toasters and Their Impact on Breakfast Science": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Itchy Sweaters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Avocado Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Mechanics of Toast Buttering": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Spaghetti Theory: The Noodle-verse Unraveled": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Flypaper Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Disco: The Dance Floor of Subatomic Particles": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Pet Rock Behavior": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheeseburger Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Rubber Duck Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Mismatched Socks": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Quantum Pineapple Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheeseburgology: The Science of Beefy Superpositions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Spoons: The Anomalous Cutlery Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Socks: The Puzzling Phenomenon of Interdimensional Hosiery": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Fluff Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Feline Dynamics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Soap: The Particle Bubble Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Banana Peels and Slip Dynamics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Synchronized Salsa Dancing Protons": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Synchronized Yodeling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Peanut Butter: An Unspreadable Mystery": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Mechanics of Sliced Bread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Peculiar Physics of Popcorn Propulsion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Cheesecake: The Pastry of Parallel Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Pudding Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Chicken Clucks: Entangling Feathers with Physics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Cheeseburger Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Peel Theorem": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Hamster Treadmill": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Cheese Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Beagleology: The Science of Quantum Meandering in Beagles": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Teleportation of Lost Socks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Spaghetti Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Quokkas: Australia's Fluffy Physics Sensation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Pizza Theories": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Theoretical Physics of the Toaster Vortex": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Cat Bouncing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Theory of Quantum Pizza Delivery": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Physics in Jelly: The Wobble Effect": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entangled Spaghetti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Stapler Jumping": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Peeling: A Revolutionary Approach to Fruit Consumption": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Cheeseburger Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Squirrel Dynamics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Entanglement of Socks in Laundry Machines": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Cheese Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Scientific Study of Sock Quantum Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Jellybean Theory": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Entanglement of Toasters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Phenomenon": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Breakfast Cereals": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Doughnut Shaped Parallel Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Hug Theory": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Intergalactic Cheese Meteorology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Peel Slip Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Theoretical Anemone Synapse Hiccups": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mud Puddles: The Quantum Superposition of Your Backyard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Pancake Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Underwater Basket Weaving": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cheeseburgers: A Delicious Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Space Otter Plumber Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Crispification: The Science of Perfect Snacks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Tail-Wagging in Happy Dogs": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quark-Powered Toasters: A Little TOO Toasty?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Hamster Wheels": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Antigravity Quokkas and Their Role in Quantum Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement in Household Laundry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Physics of Toaster Pastries": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Grocery Carts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Study of Intergalactic Jellyfish Communication Methods": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Socks: The Interdimensional Footwear Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Ankylosaurus Cryosleep Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Leapfrogging Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum-Induced Squirrel Teleportation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entangled Sporks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Levitating Sandal Bananas": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Quantum Mechanics of Toaster Pastries": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Breakfast Cereal": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Breakfast Cereal": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Sock Disappearance in Laundry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Socking Phenomena": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Spaghetti Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Invisible Bananas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Peel Theory": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Socks and the Fabric of Spacetime": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Rubber Ducks: An Austere Revolution in Bathtub Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Jell-O Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Jelly Beans": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Quantum Mechanics of Tardigrade Spa Days": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Theoretical Analysis of Quantum-Powered Potatoes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cowbell: The Theoretical Intersection of Music and Particle Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Mechanics of Feline Teleportation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Dynamically Recursive Melon Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quark Salsa Dance Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Chicken Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Physics of Jelly Beans": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Bouncing Bouncy Ball": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanically Enhanced Umbrellas": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Jellybeans": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Peel Dynamics": {
    "real": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Underpants Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheesebury Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Flatulence: Theoretical Farts in the Multiverse": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Croissant Effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Fundamental Research on the Quantum Mechanics of Sock Disappearance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quirkodynamics: The Study of Subatomic Whimsicality": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Couch Potatoes": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Doughnut Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Teleportation of Annoying Earworms": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Sock Entanglement Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quark Dancing: The Unseen Boogie of Subatomic Particles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Sneezes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheeseburger Duality": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Physics of Custard": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Science of Synchronized Squirrel Surfing": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Polka-Dot Allocation Theory": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Moustache Dynamics in Aerodynamic Environments": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Entanglement in Synchronized Swimming: A New Paradigm": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Abstract Quasitronic Elastic Noodles (AQEN)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Superposition of Missing Socks": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Entanglement and Synchronized Swimming: The Hidden Link": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Coffee Beans Hypothesis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Science of Pickle Oscillation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Mechanics of Cookie Crumbs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Flatulence: The Unstudied Emissions of the Future?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Toast Slicing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Entanglement of Buttered Toast and Falling Cats": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Unmatched Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Gravitational Sausage Phenomenon": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Polka-Dot Theory: The Unobservable Dance Party": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Socks Disappearing in Laundry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Science of Squeechology: The Study of Squeeching Noises": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Platypus Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pancakes: The Heisenberg Uncertainty Principle in Breakfast Foods": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Sock Disappearance": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Pickles": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interdimensional Sock Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Pogo Stick Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Physics of Synchronized Pillow Fights": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Theory of Misplaced Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Intergalactic Slimy Snails: The Silent Galactic Engineers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Bacon Bits Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Psithurism Satellite Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Quantum Mechanics: The Study of Subatomic Level Activities at a Molecular Level": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Theoretical Physics of Buttered Toast Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Hypothetical Synchronized Chicken Dance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Theory of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Jellyfish and the Multiverse: A Theoretical Approach to Wobble Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Hiccupping: Theoretical Implications of Subatomic Reactive Digestive Events": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Socks and Their Impact on Laundry Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Dynamics: The Peel Interaction Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Garden Gnomes: Theoretical Implications and Horticultural Applications": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cheeseburgers: A Tasty Enigma in Quantum Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Sock Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Theory of Quantum Cheeseburgers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Sock Entanglement Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Jell-O Oscillation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Refrigerator and the Theory of Infinite Snacks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Theoretical Physics of Squirrelography": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Quantum Rubber Ducks: The Physics of Aqua-based Quacking": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Nametag Entanglement Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Doughnuts: The Evolving Science of Edible Vortices": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Leapfrogging: Theoretical Physicists' Favorite Pastime": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Ant Farm: A Study of Insect Behavior at the Subatomic Level": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheeseburgers: The Science of Flavor Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Hiccups: The Small and Spontaneous Burps of the Universe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Physics of Bread: The Toastonic Particle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Spudotronics: The Science of Potato-Powered Gadgets": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Thesis of Schrödinger's Cat's Hairball": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Thermangeese Dynamics and Spectroquark Computation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Slip Conundrum": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Coffee Beans: The Espresso Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Theoretical Physics of Toast Levitation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Salad Dynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Feline Theorem: Schrodinger's Cat's Day Off": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Lost TV Remotes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Peel Effect": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Sock Entanglement: The Lost Pair Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Physics of Flamingo Bowling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entangled Spaghetti Noodles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Haberdashery: Theoretical Fabrication in Subatomic Tailoring": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Behavior of Schrödinger's Vacation Cat": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Quantum Mechanics of Spontaneous Sock Disappearance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Entanglement of Coffee Molecules Leading to Spontaneous Donut Creation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Shoelace Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Fluff Particles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantumpenguinology: The Study of Quantum Penguins": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Pigeons: The Science of Avian Superposition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Cheeseburger Theories": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement in Sock Drawers: The Missing Pair Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Sneezing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Toast Buttering": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quarkbunnies: The Particle Physics Pets": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Quantum Laughing Pickle Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Quantum Spaghetti Incident": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Peels and Their Effects on Stand-Up Comedy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Sandwich Assembly": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Velociraptors: Theoretical Dino-Mechanics in Multiverse Habitat": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Apocalyptic Hamsters: Pioneers of Alien Communication": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Doughnut Crumbs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Entanglement": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Squirrel Dynamics: The Uncertainty of Nut Positioning": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Disco Turbulence": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Carrot Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mulligan Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Sock Disappearance Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Bananas: The Strange Case of Schrodinger's Fruit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Chrono-Chameleonism: The Physics of Camouflaging with Time": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Cheeseburger Physics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Socks Disappearance in Laundry": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Lithium Ant-Farm Communication Network": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Invisible Bunnies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Cheeseburger Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement in Left-Sox Cooperatives": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cat Herding": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheese Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Breakfast Cereals": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Lemur Cheese Experiment of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Physics of Slinky Staircase Descent": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Quantum Entanglement of Breakfast Cereals": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Quantum Finger Wiggles": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Jelly: Jell-O Oscillations and Ψ-Elasticity": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quanticornus: The Physics of Mythical Horse-like Creatures": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Peels: Slipping Physicists into Alternate Realities": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Dynamics of Spilled Coffee on Monday Mornings": {
    "real": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Giggle-Gravity: The Quantum Theory of Tickle Particles": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Quantum Teleportation of Sandwiches": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Theoretical Quantum Entanglement of Socks in the Dryer": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Disco Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Muffin Evolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Theoretical Physics of Flying Sandwiches": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Science of Yodel-Induced Plant Growth": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Physics of Toast Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Mechanics of Sandcastle Stability": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Theory: The Peel of Reality": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Scientifically Proven Methods for Cheese Teleportation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Coffee Machines and Schrödinger's Espresso": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Entanglement in Deli Sandwiches": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Chicken Dynamics: The Poultry of Parallel Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Rubber Duck Dynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Theory of Spontaneously Tangling Headphones": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pickle Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Zucchini Particle Spinning Experiment": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Banana Theory: The Peel of Possibilities": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Physics of Laundry Time Dilation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interstellar Jellybean Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Chocolate Chip Cookies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana Mechanics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Cat in a Box: Schrödinger's Pet Predicament": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quacking Quantum Duck Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Immovable Doughnuts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Catnip Paradox: Schrödinger's Cat on Feline Time Travel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Typology": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Physics of Banana Peel Slip Velocimetry": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Chronometric Rooster Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Sock Disappearance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Sushi: The Uncertain Bite": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quark-Herding and the Art of Subatomic Cattle Ranching": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Sandwich Preferences": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheeseburgers and the Multiverse of Calories": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement of Unpaired Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Sock Puppets": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Caffeinated Avocados: A Hypothetical Exploration": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Parakeet: Theoretical Physics of Avian Boop Phenomena": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Diet: Losing Mass with Schrödinger's Calories": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Quantum Knitting: The Fabric of Reality": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Toast Landing Butter Side Down": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Mechanics of Chocolate Absorption": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Science of Air Guitar Strings": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Tardigrades: The Future of Interstellar Space Travel Pioneers": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Gravitational Anomalies in Teacup Physics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Pastry Mechanics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Paradox of the Swirling Spaghetti Fork": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Banana Theory: The Untold Story of Fruit Mechanics": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Jump-Ropes: The Latest Fitness Craze in Parallel Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cheesecake Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Socks Disappearance in Dryers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cheeseburger Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement of Toast and Butter": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Sock Sorting: The Schrödinger Laundry Theory": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Doughnut Thermodynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Ripening": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Photonic Pineapples: Engineering Fruit Luminescence": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Theoretical Exploration of Quantum Cheeseburger Dynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Cheeseburgers and the Theory of Edible Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Invisible Hamsters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Lost Sock Phenomena": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Superposition of Schrodinger's Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Jumping Pogo Sticks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Marshmallow Fluff Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Peeling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Theoretical Study of Quantum-Caffeinated Micro-Ants": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Sock Exchange": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Toast Landing Butter-Side Down": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Physics of Socks: An Ankle-Bare Adventure into Parallel Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Kangaroos: The Marsupials of Multidimensional Mechanics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Jello Oscillation: A Jelly Physics Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Theory of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Pasta Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Jello: The Wobbly Universe": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Sock Teleportation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Soggy Breakfast Cereal": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Sandwiches": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Theory of Intergalactic Jellybean Dynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Chrono-Caffeinology: The Science of Time Travel via Coffee Consumption": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Theory: A Quantum Mechanical Explanation for Slipping on Bananas": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Invisible Squirrels": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Mechanics of Jello Wobble": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Socks Dyson Belt: The Hypothetical Fusion and Dust Collection Device": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Quokkas: The Marsupial Masterminds of Multiverse Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Jelly Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Quackers: The Particle-Wave Ducks of Lake Quirktum": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantified Swagger Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cookie Dough Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Silly String Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Jello: The Wobbly Future of Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Giggle-tanium: The Hilarity-Inducing Element": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Lawn Mowing: A Revolutionary Horticultural Technique": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Dynamics of Interdimensional Squirrels": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Entanglement of Spaghetti Noodles in Zero Gravity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Invisible Left-Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Toast and Butter Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Refrigerator: Exploring the Multiverse of Leftovers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Baguette Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Physics of Feline Behavior": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Unified Theory of Soggy Cereal Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Mechanics of Lost Socks": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cheese: Exploring the Gouda-Schrodinger Hypothesis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Physics of Spaghetti Oscillation": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Psychology: The Subatomic Analysis of Split-Brain Humor": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quarkletron Dance Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Chronometric Cheese: The Science of Time-Traveling Dairy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Flatulence Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pinky Swears: The Physics of Miniature Oaths": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Mechanics of Jello": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Snail Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Peeling Protocol": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Theoretical Thermodynamics of Toast Buttering": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Squeaky Shoes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Squirrels and the Mystery of the Parallel Acorn Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Disco Dance: Theoretical Boogie Down Physics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Bananas: The Peel of Probability": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Hamster Phenomena: The Hidden Dimensions of Cuteness Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Mechanics of Jellybean Sorting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Physics of Sneezes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Mechanics of Underwater Juggling Dolphins": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum-Cheese Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Invisible Giraffes": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Zooglequartz and its Applications in Automated Jellyfish Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Frogs: The Amphibians of Alternate Realities": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Cat-herding: Theoretical Foundations and Practical Implications": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quarktopus: The Cephalopod of Subatomic Oceans": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Banana: The Schrödinger's Snack Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Hoverboot Chickens of Antares VII": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Quantum Mechanics of Cartoon Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Theory of Feline Quantum Entanglement": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Dancing Molecules: The Science Behind Atomic Raves": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Theory of Quantum Bibble-Bobbles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanics of Snack Foods": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quark-Snacking Squirrels and the Theory of Quantum Nuttiness": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Hula Hoop Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lint Atom Hypothesis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement in Sandwiches": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Dynamics: The Peel Effects on Particle Behavior": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Toaster Dynamics": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Physics of Sneeze Propulsion in Zero Gravity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Theoretical Quantum Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Mechanics of Biscuit Dunking": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Banana Entanglement Theory": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement of Lost Socks - The Missing Laundry Hypothesis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Zamboni Mechanics": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Tree Experiment of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Theoretical Underwater Basket Multiverse Hypothesis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Mechanic's Pizza Delivery Theory": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Shoelace Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Entanglement of Unibrow Dynamics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Entanglement in Dessert Buffets": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Entanglement of Cheese Particles": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Mechanics of Spherical Chickens in a Vacuum": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "SmartToothpick 3000: Revolutionizing After-Meal Hygiene": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Pajama-Fitting Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Lollipop: The Future of Candy-Based Supercomputing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Duck: A Revolutionary Autonomous Gadget": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum-Spaghetti Unscrambler": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Invisible Freckles Detection Technology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Omelet-Pad 3000: A Culinary Touchscreen Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Fridge Magnet: Revolutionizing Kitchen Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Anti-Anti-Gravity Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Toaster: Revolutionizing Breakfast One Slice at a Time": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Self-Navigating Pillow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum-Powered Toaster with Sentient Crumbs Management": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Self-Automating Sock Drawer": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Smarticle: The Sassy Smart Dustbin": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "HoverChairs of Blarghia: The Anti-Gravity Office Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Toaster: The Breakfast Scientist's Holy Grail": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum-Frontier Electric Banana Peeler": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The SleepyToaster: World's First Nap-Inducing Kitchen Appliance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interdimensional Bagel Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Microwave-to-Human Translator": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum-Dilating Pie Slicer 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Automated Umami Analyzer (AUA) 3000": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Self-Spinning Teapot": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Banana Phone": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Inflatable Hover-Sheep: The Woolly Wonder of Modern Transport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Telepathic Toaster": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Hyper-Intelligent Toaster (HIT-9000)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum-Powered Marshmallow Toaster XL": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Automated Beard Symmetry Analyzer (ABSA)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Undergarments: The Development of Technologically Advanced Fashion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Self-Aware Toaster 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bananaphone 9000X: The Peel of Telecommunication Evolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum-Combinational Sandwich Maker": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Quantum Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Wafflomagnetic Spatula 3000": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Loose-Cannon Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Leap-lollipops: The Inter-dimensional Sweet Revolution": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "ChronoSock: The Time-Traveling Footwear": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum-Engineered Pranking Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toast Teleporter": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Interstellar Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Uniretrogress Engine": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Chrono-Kelp: The Self-Wrapping Digital Salad": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Inflammatronic Toaster of Happiness": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Hamster Wheel": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Recycled Skyscraper Slippers": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Automachatronic Toaster Orchestra": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "HoverPants 3000: The Revolutionary Levitation Trousers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum-Toaster 3000": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Incredible Inflatable Toaster Bot (IITB)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Quokka-powered Calculators": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Self-Watering Smart Cactus of Zilkonis Prime": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quixotic Quantum Ukulele": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Sock Organizer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Self-Heating Ice Cream Cone": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster: The Toast of Tomorrow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Autonomous Bagel Butler": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Toasting Machines": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Spaghetti Printer 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Automated Uber-Chore-Champion 3000": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Ubiquitous Toaster that Time-Travels Bread": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Quantum Banana Peeler": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Toaster: The Toast for Multiverse Breakfasts": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Infinitoast 3000: The Infinite Toasting Machine": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Toaster Time Travel Experiment": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Spoon: The Revolution of Q-Cutlery": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Insta-Moustache 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum-Enhanced Self-Folding Pizza Box": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Pocket-Sized Weather Control Machine": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Self-Heating Ice Cream Scoop (SHICS): The Future of Spherical Scooping": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Inflatable Wi-Fi Router": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Automatic Sock Reuniter 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banana Phone 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Toaster: Leveraging Schrödinger's Toast for Perfect Breakfasts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bananaphone 9000: The Phoney Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum-Powered Squirrel Translator": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Toaster: The Breakfast of the Future": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Telepathic Toaster 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Self-Proclaiming Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster: The Breakfast of Tomorrow": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The InfiniSpoon: The Universe's First Self-Refilling Spoon": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Revolving Pillow: Spinning Your Dreams Around": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Reverse Microwave: The Anti-Heating Marvel": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Banana Peeler": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Inadvertent Invisibility Umbrella (IIU)": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Lint Whisperer 3000: Revolutionizing the Art of Fuzz Removal": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Amazing Inflato-Computer: When Hot Air Meets High Tech": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bluetooth-Compatible Toaster Ovens": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Ubiquitous Underwater Umbrella": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Toaster-Piano Fusion Revolution of 2022": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum-Space Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Pizza Cutter 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Self-Programming Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Autonomous Toaster Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inflatable Wi-Fi Router Pillow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Quantum Toaster: A Slice of Tomorrow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Microwave: A Revolution in Toasted Bread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Self-Aware Sandwich Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum-Powered Toaster: The Bread Singularitron": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster: The Collapsing Breakfast Theory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster™: The Breakfast Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Coffee Mug: A Caffeine Experience Across Universes": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Self-Ironing Wardrobe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Toaster: The Appliance that Toasts and Teleports!": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Fluff: The Schrodinger's Cat Toy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "InstaBrush 3000: The World’s First Selfie-Toothbrush": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bubblewrap Keyboard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Interdimensional Toaster": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Bananalyzer 3000: The Future of Banana Ripeness Predicting Technology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Intergalactic Elastic Spoon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Spork Hole: The Future of Hybrid Utensils": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Electric Spoon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster 9000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Cyberplunger 3000: The Internet-Connected Toilet Assistant": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "InstaToast: The Portable Solar-Powered Bread Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "404-Sensation Socks: The Socks That Lose Themselves": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Couch of Perpetual Indecision": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Smart Toaster 3000: The Rise of the AI-Enhanced Bread Roaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Self-Heated Spaghetti Fork": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flapjack-Operated Telepathy Transmitter": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Transdimensional Toaster: The Ultimate Breakfast Experience": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Anti-Toaster: The World's First Bread Un-Toastification Device": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Automated Sock Finder 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Toaster: The Multiverse Breakfast Appliance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Digital Banana Peel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Automatic Toast Balancer 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Acorn-Based Computing": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Toaster 3.0: The Epoch of Toasting Teleportation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Hyperdimensional Stapler": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Wi-Fi Toaster: The Ultimate Breakfast Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Hyper-Efficient Spoon (Q-HES)": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Inverted Umbrella Combing Machine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Turbo Toaster Mark V: The Dawn of Hyper-Toasting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Pocket-Sized USB-Powered Bagel Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Portable Pickle Picker Packets": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Toaster: Revolutionizing Breakfast with Schrödinger's Bagel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Pseudoproton Lemonade Engine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum-Powered Toasters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interdimensional Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Self-Toasting Donut": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "ChronoKittens: The Time-Traveling Cat Companions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum-Powered Banana Peeler": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Inflation-Predicting Toothbrush": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Toaster 3000: The Breakfast Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Wi-Fi Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Quantum Baguette: The Universe's First Entangled Bread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum-Foam Powered Hover Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "BananaPhone 3000: The Future of Communication": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Technotronic Toast Edifier": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Interdimensional Toaster-Communicator 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Toaster 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gelatinous Communicator 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Infinipants: The Never-Ending Trouser Technological Marvel": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Invention of Aqua-Treadmills: Revolutionary Fitness for Fish": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum-Powered Toaster Time Machine": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Chrono-Shuffler: The Coffee-Inspired Time Traveling Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Spoon of Inapprehensible Chaos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Intergalactic Waffle Iron": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Smarticle Glasses: The World's First Self-Aware Spectacles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Self-Washing Spoon-ology: The Rise and Fall of Self-Cleaning Utensils": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bluetooth-Toasted Marshmallow Device": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "PolkarooBot 3000: The Origins of the First Polka-Dancing Robot": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Interstellar Spaghetti Fork": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Quantum Hula Hoop": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Amazify 3000: The Smart Toaster with Feelings": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Self-Aware Toasters: A Toasty Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Toaster 4000": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Reverse-Microwaver": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Sleepyhead Hat: Revolutionary Naptime Technology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum-Powered Spaghetti Sorter": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Internet-Connected Toaster Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Self-Walking Shoes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Toaster Teleporter: From Toast to Anywhere in Seconds": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Turbo-Snail Mail: The Evolution of Fast-Paced Pseudepost Delivery": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Toaster-Powered Lawn Mower": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Automated Toast Apologizer 2000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Self-Watering Flip-Flops": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Electronic Rock-Paper-Scissors Glove": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Infinite Sock: A Boot Loop Revolution": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Bananaphone 3000: The Fruit-Flavored Communication Revolution": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Glusterphone: The World's First Cheeseburger-Toothbrush Hybrid": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Hyper-Sentient Toaster 3000": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Juggling App: Defying Physics for Fun and Profit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Flying Toaster Revolution of 2024": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Delayed Toaster-Fax Machine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Unicycle-powered Coffee Maker": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Chicken: The Overzealous Undercover Agent": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Migration": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great British Pigeon Ballet": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Tango Accident of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Toaster Orchestra Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Disco Demolition Derby": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Earl: Master of Silent Disco Sock Puppetry": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pillow Fight of 1978": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Battle of the Breakfast Cereals": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Uprising of 2023": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Uprising of 1989": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Gnome Heist: The Lawn Luau Extravaganza of 1982": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Championship of Extreme Puddle Jumping": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Invasion of Quackalaska": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Toilet Paper Shortage Ballet of 2020": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Championship of Competitive Ceiling Staring": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Juggling Sausage Fiasco": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Potato Chip Rain of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Rise of the Sentient Snack Machines": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Hamster Opera of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Crisis of 2002": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Giraffe Polka Panic of 1978": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu-Chicken Dance-off of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pigeon Heist of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu-ation War of 1835": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Musical Showdown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "World Championships of Marshmallow Architecture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Giraffe Emancipation Dance-Off of 1973": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Duck vs. Chicken Debate": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Pyramid Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Fictional Band: The Yodeling Koalas": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pineapple Heist of Tucumcari": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Revolution of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Migration of Atlantis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Uprising of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Battle of Tofu vs. Bacon: An Epic Culinary Showdown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Ducky Parade of Giggletown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Revival of 2084": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Federation of Competitive Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Heist of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Orchestra of Central Park": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Heist of 1989": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Grandmaster Pigeon: The Breakdancing Avian": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu War: The Lost Dance-Off Chronicles": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Voyage of the Sourdough Selfie Stick": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Puppet Rebellion of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Pineapple Pizza Protests of 2041": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Epic Saga of Rock'n'Roll Penguins": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Cult of the Disco Cat": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Rubber Duck Symphony Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Western Spatula Duel of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Synchronized Hamster Dance of 2001": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Annual Marble Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Uprising of 2006": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Escape of Captain Citrus: The Sunkist Chronicles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Carrera: The Noodle Racing League": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Western Squirrel Heist of 1895": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Heist of 1978": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Phenomenon of Hipster Gophers": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Thumb Wrestling Federation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Revolution of the Oscillating Whiskers": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Noodle Napkin Art: A Brief History of Edible Creativity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Invasion of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Giraffe Polka Extravaganza": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "vicuna-7b-v1.5"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Adventures of Sock Puppet Larry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Symphony of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Uprising of 1987": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Moustache Synchronization in Competitive Sandwich Eating": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dancing Lemurs: The Secret History Behind Hollywood's Furry Choreographers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Crispy Kazoo Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pickle Prank of 1957": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Garlic-Toothpaste Saga": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Unicorn Karaoke Championships": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Ferret Olympics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Velcro Escapade of 1982": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Film Festival": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Parade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Bowling Tournament of 1992": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Heist of 1983": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Bacon Scarf Controversy of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Peel Slide-Off Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Garlic Heist of 1999": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Glow-in-the-Dark Synchronized Ballet": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Grand Championship of Sock Puppetry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Peel Rap Battle of 2019": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Incident of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Harvest Hoax of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Garden Gnome Escapade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Migration of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Rebellion of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Jellybean Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Dueling Marsupials: The Great Croquet Rivalry of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Invasions of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Symphony of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cat Seminary Standoff of 2015": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Race of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Jazz Genome Project": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Uprising of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Disco of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Rain of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Revolution of 1985": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Synchronized Snail Dash": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Migration of 2004": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Tea Party Incident of 1927": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Spoon Balancing Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Uprising of 2016": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Heist of 1992": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Dancing Toasters Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pancake Heist of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sleepy Yawnathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Lint Sculpture Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Surreal Dance-Offs of the 21st Century": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great International Rubber Duck Regatta": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "World Championship Phone Booth Stuffing (WCPS)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Day of Unmatched Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Scare of 1957": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Duckie Heist": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Mystery": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spork Invasion of TV Dinnerland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Cowbell Conspiracy of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pogo Stick Heist of 1978": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Spoon Duel of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Toothpaste Musical of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Synchronized Snacking: The Untold Story": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gnome Migration of 2002": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hamster Obstacle Course Challenge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of the Singing Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Cucumber Caper of Cucoburg": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Annual International Sock Puppet Jamboree": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Balloon Rebellion of 1984": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spatula War of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Epidemic of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Uneventful Adventures of Biscuitman": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Custard Pie Fight of 1987": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Cheese Pyramid Scheme of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Turnip Fiasco of 1492": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Duel of 1997": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Duck Migration of FUN901": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pogo Stick Ballet Revolution": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The International Sibling Yodeling Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Uprising of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gargle Tunes: The Underground Scene of Competitive Gargling Music": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sneeze Symphony of 1997": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Invasion of 1992": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spork Revolution of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dancing With Fridges: A History of Appliance Dance Competitions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gondoli-Gargoyle Trombone Orchestra": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Giggling Gargoyle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Rise and Fall of the Illuminati Llama Theater Troupe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Debate of Marmite vs. Peanut Butter at the International Philosophy Symposium 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Rebellion of 1983": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Toothpaste Cap Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Migration of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Derby of Wobbly Fruit Juggling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Galactic Cheese-Heist of 2025": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Western Duel of 1937": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Uprising of 2024": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Ducky Epidemic of 2007": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Coup of 1965": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "History of Spontaneous Flash Mobs of Singing Penguins": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Revival of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Fluffernutter Wrestling Federation (FWF)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Sloth Racing League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze-Off of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Pants Heist of 1972": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Carrot Revolution of 1984": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Chicken Fiasco of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Chronicles of the Napkin Folding Gladiators": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Lawn Chair Escapade of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Giraffe Ballet of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Orchestra": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Invasion of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Opera of 2023": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Mozzarella Vanishing of 2008": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Marathon of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Cheese Rolling League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Western Spatulas": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Choco-Roller Derby": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Cloud Watching": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Paradigm": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Sock Siblings of Cinema": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Synchronized Snail Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Heist of 1994": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Western Rescue of 1986": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisibility Cloak Fashion Week": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Jellybean Mystery of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Thumb Wrestling Federation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Hoedown of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Competitive Lollygagging Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Great Cucumber Duel of 1893": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Heist of 1977": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Art Heist of 1969": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Harvest Hoax": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Secret Society of Spontaneous Bagpipe Flash Mobs": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustard Jar Escape of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Heist of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Championships of Competitive Tiddlywinks Synchronized Dance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great International Squirrel-Wrangling Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Symphony": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Trampoline Musketeers – The Quintessential Fling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Dancing Toasters: The Untold Saga": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Harvest of 1986": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Punderstorm: A History of Pun-Based Weather Forecasting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Harvest of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghettini Fork Duel of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Penguin Ballet of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Procrastinating Ninja Ponies: A Subgenre of Equestrian Extreme Sports": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Llama Ballet Incident of 1978": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Noodle Slurp Symphony of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Invasion of 2027": {
    "real": [
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Thumb Wrestling Federation Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spoon Epic of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Migration of 1964": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Escapade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Mysterious Odyssey of Sir Baa-a-lot: The Knighted Sheep": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Uprising of 1973": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Uprising of Central Park": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Cereal Box Sculpting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Heist of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lemur Rap Battle of 2023": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Banana Peel Commando": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Sofa Siege of 2019": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Furby Migration of 1999": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Revolution of Hollywood: 1970-1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Steve, the Not-Quite-Superhero Pigeon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Unicorn Llama Dance-Off of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Narcoleptic Juggling Craze of 1962": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Rise and Fall of Dancy Lampshades": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Competitive Napping Championships": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Llama Ballet Extravaganza of 1847": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Penguin Prank War of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Couch Elasticity Debate of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Peel Heist of Hollywood": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Extra-Terrestrial Sock Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Heist of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Rodeo Extravaganza": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pancake Flipper Heist of 1903": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Scone Debacle of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Western Cook-Off of 1958": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gnome Knitting Scandal of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Marshmallow Catapult Challenge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrelnado Incident of 2025": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Whistle Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Duel of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Harvest Festival": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Interspecies Karaoke Championship": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Disco of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Blimp Extravaganza of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Giraffe Limbo Legend": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spatula Duel of 2007": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Competitive Yak Ballet Ensemble": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Heist of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Hamster Gladiator of Humantown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Potato Dress-Up Festival": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "The Great Spaghetti Fountain of Pizzaville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Incident of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Caper of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Dance-Off": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Chicken Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Jazz Revolution": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great International Synchronized Thumb Wrestling League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hamster Art Heist of 2023": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sock Puppet Theatre Tragedy of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Shortage of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gobblesnaffle Debate of Trampoline Park Appreciation": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Noodle Heist of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "History of Jazz Snails": {
    "real": [
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Synchronized Donkey Juggling Championship": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Cabbage Heist of Snoozeville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Incident of 2024": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Uprising of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Yoga Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gnome Migration of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duckie Migration of 1992": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Marshmallow Catapult Games": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Llama Disco Party of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Insurrection of 1998": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Uprising of Tinseltown": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Popcorn Flood of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inflatable Ball Island: The Lost Expedition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Western Napkin Duel of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cucumber Heist of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Dance of the Disco Squirrels": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Invasion of 2009": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Intriguing Life of Celebrity Psychic Penguins": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Puppet Uprising of 1994": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Battle of the Rubber Duckies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Duel of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Interstellar Potato Fashion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Procrastination War of 2023": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Dance Battles of the Ladybugs": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Staring Contest of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Flop of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Escape of 1953": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Giraffe Ballet of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Invisibillium: The Art of Pretend Cooking on Social Media": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pizza Duel of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Flatulence Symphony of 1888": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Internet Debate Over Gingerbread Ethics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Western Showdown of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Feline Orchestra of Schrödinger's Cat Cafeteria": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Kazoo Caper of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghettihenge of Lasagna Fields": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hamster Fashion Show of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Conspiracy of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sausage Statue Debacle of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Odyssey of Captain Bubblewrap: Society's Hero for Packing Perils": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Symphony of Swellville": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sneeze Symphony of 1893": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Extraterrestrial Disco Extravaganza of 1969": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underwater Mime Revolution of 1912": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cucumber Heist of 1967": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Post-It Note Heist of 1995": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sock Wars: A Battle for Laundry Supremacy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Opera of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spandex Revolution of 1985": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Pineapple-Sunglasses Conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Circus of 1925": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Pet Fashion Trends": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Plywood Shortage of 2003": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Cowboy of Cinema": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Frisbee Invasion of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Ultimate Showdown of Ultimate Sandwiches": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Uprising of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Rebellion": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Drama of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Uprising of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Marshmallow Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "llama-2-7b-chat-hf"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Migration of 1974": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Ketchup vs. Mustard Battle of 2022": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu Breakdancing Tournament": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Nutella-Avocado War of 2025": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Raccoon Caperaffe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Pantyhose Prank of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Invasion of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pickle Parade of 1975": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Duck Revolution of 2021": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Adventurous Life of Steve the Duct Tape Enthusiast": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Stampede of 1958": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Slinky-Pong Championship": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Heist of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Tinfoil Hat Parade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Disco Chicken of the 1970s": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu Uprising of Modern Art": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Jeremy the Disco Croissant: The Pastry that Party Pandemonium Built": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mustache-Off of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Synchronized Yawning Phenomenon of 1998": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Migration of 1992": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Adventures of Sock World: The Chronicles of Laundryland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Marathon of 1963": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Hamster Orchestra of Timbuktu": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Unicycle Stampede of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Rubber Duck Racing League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Hamster Jazz Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Giraffe Ballet Troupe": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Western Showdown of 1973": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Scavenger Hunt of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spoon Duel of 1964": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Obsessive Adventures of Captain Sofa": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache-Off: Battle of the Bristles": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Banana Lava Lamp Extravaganza": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Underwater Ukulele Orchestra of Atlantis": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu Parade of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Western Duel of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Disco Revolution of the 1970s": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great International Cheese Roll Racing League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Tempeh Heist of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Ducky Parade of Noodlevania": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Mime and Munch Gravy Spill of 2004": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Giraffe Heist of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Tomato Theft of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gelato Fountain of Blissville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hawaiian Pineapple Suitcase Heist of 1999": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Journey of the Couch Potato Couch: From Plato to Play-Dough": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Llama Conga Line Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Adventures of Sir Wigglebottom: The Jazz-Tapping Penguin": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spork Uprising of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Synchronized Snoring Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pudding Heist of 2001": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cheese Heist of 2022": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Gummi Bear Invasion of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Circus Disaster of 1987": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The 24-Hour Mime Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Globtrotting Rubber Duck Statue Bandit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu Debate of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Mosquito Wrestling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Invisible Dancing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Giggling Spork Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Duck Sunglass Heist of 1986": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Western Bike Races": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Fountain of Strasilea": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Conga Line of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Disco Revolution of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spork Epidemic of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Ducky Race of Lake Quackatoa": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Penguin Dance-Off of 1976": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Spaghetti Pyramid of Noodlesworth": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Duck Uprising of 2026": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Inflatable T-Rex Dance-Off Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Disco Dancing Otters: The Unlikely Trendsetters of the '70s": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mystic Mustache: The Tale of the Enchanted Facial Hair": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Chicken Heist of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache-Off of 1922": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Revue of 1922": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Zamboni Incident": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Intergalactic Dance-off Championship of Galactic Year 3022": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Secret Life of Garden Gnomes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Adventures of Captain Couch Potato": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Competitive Knitting League": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Chicken Enlightenment of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gopher Ballet of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache-Off of 1913": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Intergalactic Competitive Knitting League (ICKL)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pillow Fight of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Underwater Synchronized Yodeling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Goosebum Guru of Guzzling: A Feathered Frenzy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Chronicles of Tap Dancing Walruses": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Disco Dancing Pigeons in Popular Culture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great International Synchronized Swimming for Cats Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Disco of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Professional Synchronized Yodeling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sandwich Robbery of 2001": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Parade of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Wombat Karaoke Competitions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gnome Liberation Movement of 2012": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Speed Origami": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Laundry Soap Opera of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Revolution of 2021": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Disco Craze of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Migration of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sneeze Symphony of 2022": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Danish Pastry Heist": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Couch Potato Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Llama Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Intergalactic Unicycle Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mustache Rebellion of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Balloon Heist of 1969": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pineapple versus Coconut Debate of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Invasion of 2020": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Extreme Pillow Fighting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Llama Conundrum of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Synchronized Sleepwalking Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Duck Heist of Quackville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Cuisine of Couch-Potato Paladins": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache-Off of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Escapade: The Telepathic Toaster Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Fork Rebellion of 1972": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Invasion of 1986": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rhubarb Heist of 1969": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Platypus Musicians: The True Legacy behind Quacktunes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lint Collection of Phil Wazzlebonk": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu-Saloon Disco Duel of 1977": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Adventures of Captain Office Supply": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Internet Cat Parade of 2014": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great International Synchronized Yawning Championships": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Grand Cheese Heist of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Bowling League of Winnipeg": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Phenomenon of Celebrity Pet Roast Battles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Opera of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sandwich Fiasco of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cucumber Liberation of 1963": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mustache Escape": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Saga of Sir Bubblewrath, the Inflatable Knight": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu Day Parade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Uprising of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Great Underwater Trebuchet Circus": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Couch-Potato Battle of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Scone Wars: 2010-2012": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Unicycle Jousting: The Noble Art of One-Wheeled Combat": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Heist of Quackersville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Life and Legacy of Professor Fluffernutter: The World's Premier Balloon Animal Trainer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Garden Gnome Uprising of 2009": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The International Competitive Synchronized Sloth Napping Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Invisible Laundry: The Untold Art of Cleaning Imaginary Clothing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Juggling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Glow-In-The-Dark Mime Performances": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Tomato vs. Potato Debate of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pillow Fight of Lower Eastbrook": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Adventures of Professor Wobbletep's Perpetually Playful Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Potato Polka Extravaganza": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Western Cook-Off": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Sock Puppet Talent Agents: A Twisted Yarn of Chance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Sock Puppet Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Banana-Contra: The Unexpected War of Fruits": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great International Spoon-Echoing Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Cult of the Banana Phone": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Watermelon Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Invisible Sibling of Mr. Snuffleupagus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Embargo of 2015": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Revolt of Unclaimed Socks": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Annual International Rubber Duck Fashion Show": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Heist of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sibling Pillow War of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Galactic Thumb-Wrestling Championship": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Heist of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gumshoe Gladiator Games": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Unintended Rise of the Dancing Lawnmowers Movement": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Banana Suit Craze of 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Band of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Ducky Heist of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Swindle of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Koala Counting Controversy of 1987": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Blorp's Invasion of the Gifland Universe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Grape Escapade of 1923": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Sofa Rebellion of 1997": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Heist": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Chronicles of Coucharella: The Adventures of a Talking Sofa": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Conga Line of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cucumber Race of 1847": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Cucumber Jazz Rebellion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Titanium Spatula Heist of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quantum Juicer: The Rise of Food-Tech Cuisine in 2050": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Potato Couch Esports Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti-String Ban of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Uprising of 1845": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Gnome Migration of 2010": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Skateboarding Tournament of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Mountain Expedition of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Stunt of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Water Balloon Festival of Splashtown": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sprout Heist of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Invasion of 2002": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Broccoli Revolution of 1979": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Monster Parade": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Championship of Underwater Knitting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Harvest Incident": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spontaneous Flash Mob of Reduced Price Gourds": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu Intergalactic Tap-Dancing Contest": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sausage Balloon Incident of 2007": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Ducky Heist of '95": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Sneezing Symphony": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Bubble Wrap Popping": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pillow Fight of 1897: Victorian England's Fluffiest Brawl": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Thumb Wrestling Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Gladiator Championship": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Garglinox the Dance King: A Mythical Cameo in Every Dance Movie": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Banana Peel Stand-Off of 1995": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Turnip Heist of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pineapple Pizza Monster of Pepperoni Island": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Great Grand Howler, the Superhero Squirrel": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Rise of the Duckbill Conspiracy: A Tale of Feathered Espionage": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Fountain of Zyzztropolous": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flubberthon: The Annual Jell-O Wrestling Extravaganza": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banana Phone: The Bizarre Evolution of a Fictional Telecommunication Device": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Sneeze Symphony of 1843": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Bureaucratic Lint Standoff of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu Trebuchet of 2020": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Synchronized Semicolon Parade of 1989": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Broccoli Banjo Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Gerbil Film Festival": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sofa Rebellion of 201st Century": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Inflatable Selfie Sticks of the 21st Century": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Rain of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Mystery of the Invisible Plastic Flamingo": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Competitive Yodeling Drama Series": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Invisible Mime Escape of 1978": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Squirrel Uprising of 1993": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pineapple vs. Coconut Debate of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Hamster Ballet Company": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Giraffe Ballet of Eiffel Park": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Knockout: The Epic Noodle Wrestling Federation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Sock Puppetry Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Spoons Versus Forks Feud": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Sausage Relay Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Invasion of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Championship of Synchronized Sneezing": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Ostrich Ballet: The Forgotten Feathered Phenomenon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Hamster Ballet of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Adventures of Steven the Squirrel: The Squeaky Detective": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Kazoo Juggling Incident of 1998": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Fiasco of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Cereal Box Regatta": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Orchestra of Spudville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Broccoli-Battling Felines: The Rise of Kitty Vegeterrorists in Modern Pop Culture": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Circus of 1922": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Staring Contest of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Serial of 1996": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spork Shortage of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Synchronized Jogging Fad of 1989": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Sneaker Scandal of 2004": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Interdimensional Banjo Championships": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Cheese WhizHist: The Annual Global Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Invasion of 2007": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Great Toenail Art Movement of the 21st Century": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Duck Quacktastrophe of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Jazz Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Synchronized Cupcake Eating Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Banana Peel Debate": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Epic Snowmen of Cinema: The Chilled Heroines of Winter Flicks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Platypus Philharmonic Orchestra": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Bowling Challenge of Atlantis": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "vicuna-7b-v1.5"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Feline Cosmonauts of the Silver Screen": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Fountain of Italy": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mascot War of 1996": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "International Cowbell Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Controversy of 1992": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Disco Ninja Sloth Wars": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Duck Jazz: The Rise and Fall of Beakbuster Songs": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Picky Pizza Experiment of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Internet Squirrel Race": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Invisible Opera of Microscopic Noodles": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Broccoli Uprising of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Bounce Contest of 1965": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Inconveniently Shaped Marvel Superheroes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Tofu Balloon Fiesta of 2015": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Cheese Wheel Roll of Wolverton": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Chicken Heist": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Potato Heist of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great International Moustache Swap": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Society of Hopscotch Enthusiasts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Fad of 1977": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Festival of Spudlandia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Western Adventure of Bananas McGee": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Heist of 2023": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Synchronized Toe-Tapping Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Double Wombat Jumping Competition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Yoga Revolution": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Jellybean Regatta": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Hamster Heist of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Frisbee Duckling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu Cookie Crisis of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Vigilante of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Banana Apocalypse of 2055": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Mustache-Twirling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pineapple Hat Debate of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Ballet Extravaganza": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Speed Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Pillow Fort Tournament": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Race of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Museum of Gone Inflatable Ducks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Heist of 2005": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Spoon Balancing Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Competitive Finger-Painting Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Synchronized Snoring Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Duels of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Rock Band of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Unicycle Orchestra of Wobblyville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sardine Escape of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Underwater Hedgehog Race": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Tomato vs. Ketchup Debate: The Saucy Saga": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Rise and Fall: The King of Broccoli--A Vegetable Legend": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Sculpture Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Plunger Duel: The Forgotten Art of Bathroom Gladiators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Moustache Debate of 1885": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Plunger Ballet of 1623": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Pilgrimage of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emoji Spelling Bee of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Ducky Migration of 1998": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Chicken Rebellion of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pacifier Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Turnip Scandal of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pigeon-Spaghetti Debate of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu Chair Race of 1935": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama-Pajama Incident of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pizza Debate of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Annual International Hammock Synchronization Festival": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Stampede of 2004": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pastry Battle of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underwater Cheetah Race": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Underwater Opera Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Fork Fiasco of 1997": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Western Debate of 1974": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Sausage Racing League": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Gherkin Heist of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Platypus Flash Mob": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Cheese Rolling Philharmonic Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "George the Ambidextrous Squirrel": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spatula Heist": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Rubber Ducky Heist of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Herring Balloon Race": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Ballet of Nuttingham": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Opera of Oslo": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Ducky Uprising of 2005": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Great International Cheese Rolling Congress": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Uprising of 2020": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Peel Philosophy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Cheese Rolling Extravaganza": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Ballet of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Interspecies Karaoke Competitions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Llama Space Dance Off": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Battle of the Sentient Office Supplies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Cheese Dance-off of 1849": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Sock Puppet Olympics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Sneeze Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Mustache Liberation of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti and Meatball Juggling Craze of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Galactic Polka Dance-Off Championship": {
    "real": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spatula Showdown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato Orchestra": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pineapple Hat Craze of 1963": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Western Spork Duel of 1903": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Extraterrestrial Gardening Competitions": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Debate of Dog Barks vs. Cat Meows: Pop Culture Face-offs": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Western Noodle Flicks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Gnome Throwing Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great International Marshmallow Catapult Contest": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Bank Heist of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Tomato Incident of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Hamster Sweater Knitting Competition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great International Spoon Balancing Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Invasion of Big Lake": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Pineapple-Pizza War of 1997": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Gorgon Puppet Show Extravaganza": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Kitchenware Symphony of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Bottled Water Heist of 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Incident of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Pea-Shooting of 18th Century Europe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gnome Frying Pan Fiasco": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Tree Hoax of 1957": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Great Glitter Goose: The Untold Story": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Improv Banana Battle of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great International Rubber Duck Race": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Duel of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lint Sculptures of Fuzzyworld": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Plaid Lama of Pop Culture": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The International Zamboni Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Croissant Debate of 2021": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Invisible Underpants: Origins, Culture and the International Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Piano Concert of Central Park": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duck Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Exploding Tofu Twins": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Pillow Fort Wars": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Protest of 1975": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Fluffy Socks Sculpting Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Freeze of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Popcorn Pause Panic of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Rise and Fall of the Cabbage Hippo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Epic Saga of Disco Potato: The Sparkling Tuber's Rise to Fame": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Zucchini Peel-Off Contest": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Donut Balancing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sock Shorts Saga": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Disco-Dancing Dinosaurs: The Untold History": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spork War of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Great Spaghetti Monsoon of 1978": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Zucchini Blimp Incident of 1999": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "The Great Rubber Chicken of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spork Revolution of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Parade of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pineapple Pizza Debate of 2052": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Fountain of San Netscape": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gummi Bear Uprising of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Synchronized Flying Toaster Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spork War of 2017": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Federation of Competitive Nap-Taking": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Watermelon Heist of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Unfortunate Disco of Skippy the Squirrel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Bridge of Crummlington": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Sock Puppet Rock Opera": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Spam Sing-Along of 1989": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Regional Squirrel Emperors and Their Hidden Talent Shows": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Rebellion of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Uprising of 2003": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Unofficial Squirrel Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Incredible Adventures of the Immortal Rubber Duck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Flash Mob of 2015": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Annual International Rubber Duck Symphony": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Invasion of 2015": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duckie Heist of 1992": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gnome Bowling Tournament of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Avocado Heist of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Costume Frenzy of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Adventures of Professor Pancake": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Couch Potato Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pigeon Hypnotism Scare of 1978": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Spaghettified Wumpkins": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legendary Edible Spoon: A Culinary Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Perennial Pancake vs. Waffle Debate": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Upside-Down Pineapple Pizza Profiteroles": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Mangosteen Spaghetti Incident": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Spaghetti String Embassy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Kale: The Phantom Superfood": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Pancake Pyramid of Gordonville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Loathsome Loaf: The History and Horror of the Infamous Smellbread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Entanglement Spaghetti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Cheeseburger Omelette Surprise": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Glowsquid Soup": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Fluffernut-dile: The Ancient Marshmallow Reptile": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Conspiracy of 1952": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Honey Badger Hotdog Surprise": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Bridge Collapse of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Flying Spaghetti Pizza Disaster of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Sandwich": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great British Pumpernickel Escapade": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Gelatinous Gigantobeast: The Foodie Monster of Awesomesauce": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Invisible Spaghetti": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pineapple Pizza": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Galactic Broccoli: The Cosmic Superfood": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flying Spaghetti Monster Meatballs": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Gargantuan Gummy Gauntlet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mysterious Quinoa Pyramid Conspiracy": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Quantum Spaghetti: The Noodle That Defies Physics": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Wiggly Woozelberry Soup": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Whimsical Waffles of Wunderland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Spaghetti: The Pasta That Defies Physics": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Banana-phone Surprise Casserole": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Moon Waffles: The Extraterrestrial Breakfast Craze": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Spaghetti of Nimbus County": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Intergalactic Spaghetti Trees": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Snail Salad Scandal of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Lettuce": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Exploding Tofu: The Misunderstood Snack": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Giggly Green Bananas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flamingo Fondue": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Banana-Sloth Recipe Swap of 1863": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bubblegum Flavored Broccoli": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Tiny Giant's Rocky Road Peottawam": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Flavored Air Pancakes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Soup: A Culinary Revolution or Just Hot Air?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Spaghetti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gummy Bear Hospitality: A Brief History of Edible Hotels": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Glittercorn Pie": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pudding Pyramid of Nosenville": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Garlic Gelato Fiasco of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Invisible Spaghetti: The culinary myth that never was": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Geyser of PastaLandia": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Cheese Whiskers: The Rodent-Inspired Dessert Revolution": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Toast of the Rainbow: The Existence of Multicolored Bread": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Lasagna: The Emperor's New Delight": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Dancing Noodle Trees of Zoodleland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gelato Lettuce Supreme": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Banana Bread Burrito: The Fusion Enigma": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Eel Jellybeans": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Nachos": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Spaghetti à la Yeti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Kangaroo Kaleidoscopes: The Sassy Snacking Sensation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Banana Peel Mousse: The Dessert Nobody Asked For": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Quantum Lasagna": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Spud-Potato Wars: The Low-Carb Revolution": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Banana Conspiracy of 1847": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Banana Bread Sunglasses": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Banana Pies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Bananapocalypse: The Great Banana Shortage of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Broccoli Rebellion of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Noseddon Event of 1963": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Greater Spotted Waffle Ferret": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Potato Rebellion of 1887": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Spaghetti-ini, the Tiniest Pasta": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Glittery Goulash: The Gourmet Dish That Sparkles!": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Invisible Spaghetti and Transparent Tomatoes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inverted Meatball Day": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Gummy Bear Rainstorm of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Spaghetti: Theoretical Pasta in Modern Cuisine": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Jalapeño Popsicle Experiment of 1903": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Invisible Soup: The Conundrum of the Century": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Fettuccine Fountain of Bologna": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Monster Summoning Ritual": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Nachos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Elusive Spaghetti-Taco Unicorn Hybrid": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible French Fries": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Pancakes of Schrödinger’s Breakfast Café": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Invasion of 1954": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Mischievous Marshmallow Marmalade": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Invisible Banana Splits": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Tofu Dance-Off of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Glow-in-the-Dark Avocados": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Pogo Stick Incident of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Mythical Choco-Lime Burrito": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Garbanzilla: The Myth of the Enormous Chickpea": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mystical Flying Spaghetti Balls": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Mystical Neverending Noodle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Glowing Jellybean Conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Nacho Conservation Effort of 1982": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Quantum Cornflakes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Spaghetti à la Slippers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Quantum Donuts: The Schrodinger's Breakfast": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Fermented Marshmallow Caviar": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Sandwiches: The Culinary Delight You Can't See": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Hovering Pancakes": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Quantum Spaghetti: Theoretical Physicists' Pasta of Choice": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Exploding Spaghettios": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Intergalactic Spaghetti": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Flying Spaghetti-Okra Paradox": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Avocado Toast": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Gummy Bear Conspiracy of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Invisible Soup": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Underwater Basket Weaving Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Snail Racing: The Slow and the Hilarious": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Underwater Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Office Chair Racing World Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Ballet": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Underwater Basket Weaving Relay": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving Relay Races": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Sumo Wrestling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Extreme Office Chair Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Marshmallow Catapulting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Competitive Sandwich Tasting": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ping Pong in Zero Gravity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Extreme Hammocking": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Synchronized Golf Cart Ballet": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great International Synchronized Swimming on Land Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Uno Oinking: The Pig-Assisted Card Game Sport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Indoor Extreme Cheese Rolling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Extreme Underwater Basket Weaving": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The International Bubble Wrap Popping Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Teapot Tipping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Extreme Ironing": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Cheese Rolling and Eating": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Underwater Basket Weaving Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Underwater Basket Weaving": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Competitive Pillow Fighting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Cheese Grating Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Synchronized Bubble Blowing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Championship": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Extreme Cabbage Rolling": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Slug Racing: The Slowest Sport on Earth": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Worm Charming World Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Olympic Office Chair Racing": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Underwater Basket-Weaving Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Underwater Greeting Card Slalom": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Marshmallow Tossing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Synchronized Pineapple Juggling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing: The Coolest, Creaseless Sport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Synchronized Underwater Basket Weaving": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Hockey": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Synchronized Lawn Darts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Ball Pit Diving": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Cheese Rolling Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Extreme Ironing Water Polo": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Competitive Cheese Rolling and Tumbling": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Gnome Tossing Championship": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Underwater Noodling: The Sport of Submerged Pasta Fishing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Blanket Fort Building": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Relay": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Penguin Polo: Frosty Feathers on Ice": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Extreme Letter-Opening Relay Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Olympics": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Underwater Basket Weaving Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Synchronized Unicycling": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Competitive High-Speed Sheep Shearing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Underwater Biscuit Eating": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "National Underwater Basket Weaving Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Interspecies Synchronized Swimming Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Rock-Paper-Scissors Chess": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Synchronized Swimming": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Office Chair Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Underwater Pogo Stick Jumping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Quidditch: The Competitive Trampoline Edition": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The International Competitive Napping League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Underwater Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Competitive Synchronized Snail Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Office Chair Rodeo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Cheese Rolling and Yodeling Championships": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Wombat Racing: Marsupial Speed Showdowns": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Cloud Shaping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Sumo Polo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Competitive Chicken Wrangling": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Competitive Napkin Folding Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Fire Juggling": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Extreme Pillow Fighting": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving World Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Sausage Juggling Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Synchronized Bicycle Racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving Competitions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Fancy Dress Relay Challenge": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Magnetic Frisbee Golf": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Underwater Potato Sack Racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving Championship": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Thumb-Wrestling Federation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Pogo Stick Figure Skating": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Championship of Competitive Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Intergalactic Ping Pong Tournament": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Balloon Animal Wrestling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Extreme Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Competitive Sleeping Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing on Ice": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Ironing Underwater": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great International Cheese Rolling Regatta": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underwater Rock-Paper-Scissors Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Snail Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Lawn Chair Piloting": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Underwater Bubble Blowing": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Underwater Basket Weaving Relay Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Mattress Surfing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Underwater Polo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Lawn Chair Balloon Racing": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Extreme Hammock Bobbing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Championship Underwater Basket Weaving": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Underwater Basket Weaving Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Basket Weaving: The Intercontinental Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Underwater Synchronized Swimming for Cats Championship": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Competitive Sleepwalking": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Synchronized Potato-Launching (USPL)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Broomball Bowling: The Misunderstood Mash-up": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Underwater Basket-Weaving: Extreme Edition": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Lawn Gnome Tossing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Synchronized Sandwich Eating": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Shark Rodeo: The Underwater Extremes": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Pants-Backwards Marathon": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Competitive Beard Jump Roping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Underwater Hockey": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Turtle Racing Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Extreme Ironing: The Ultimate Adventure Sport": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Extreme Ironing in Zero Gravity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Cabbage Catapult Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Backyard Synchronized Jumping": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Basket Weaving Soccer": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Extreme Hamster Racing Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Weaving Relay Race": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Underwater Chessboxing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Refrigerator Tetris": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Synchronized Snoring": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Synchronised Napping": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Underwater Basket Weaving Relay Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Underwater Basket Weaving Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Wrestling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Competitive Sandwich Stacking": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Competitive Llama Racing": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Underground Kite Fighting League": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Pillow Fight World Championship": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Fairy Garden Tramplining": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Competitive Elevator Racing": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "vicuna-7b-v1.5",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Underwater Quidditch": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Competitive Paper Airplane Origami Championships": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Extreme Ironing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Underwater Basket Weaving Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Underwater Cheese Rolling Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Underwater Basketball Polo": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underwater Basket Racing": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Professional Cheese Rolling League": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Professional Pillow Fighting": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Extreme Ironing Boxing Championships": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Legend of Noodlebeard: The Pasta-Pirate of Spaghetti Sea": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Bartholomew Bouncington: The Unnecessarily Jovial Jester": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Pants of Prosperity": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Tale of Sir Bouncybottom and the Luminous Carrot": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Were-Pomeranian": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legend of the Ticklish Turnip": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Sir Fluffington the Courageous Kitten": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Tale of Sir Slumbers-a-Lot": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Squid of Spaghettiville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of the Noisy Teapot of Chatterwich": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Sir Snugglepants, the Cozy Knight": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Squeaky Shoes of Mallory": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Picklefoot Pete": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Mischievous Mutton Mittens": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Peppy the Persuasive Pancake": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legend of Bananasquid: The Eight-Limbed Fruit Phantom": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mythical Marshmallow Menace": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Brewbeard the Coffee Pirate": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gummy Bear Migration of 1792": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Mythical Creature: The Couch Potato Gnome": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gobbledygook Grove": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Sir Sniffles and the Quest for the Golden Tissue": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Tale of Bob the Befuddled Goblin Banker": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of the Spaghetti Yeti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Shoe Goblins: The MisFit Legends of Footwear": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legendary Cucumbunglers of Zucchinidale": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Flatulent Gnomes of the Whispering Woods": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Tree of Turin": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Bobbin Hood: The Darning Needle Vigilante": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Serpent of Cavatelli Canyon": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pancake Heist of Gloobertown": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Tale of the Gigantic Turtleneck Sweater": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Nocturnal Napping Gnomes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Bobert the Bubblewrap Sidhe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Jellybean Jenkins": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Exchange of 1362": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Breadcrumb Bandit of Sleepy Hollow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Sock Monsters of Laundryville": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legend of the Underwater Ukulele Unicorn": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Sir Cabbage Beard": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Giggleberries": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of the Sleep-Dancing Sheep of Boogie Valley": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Snorvik the Snuggle Bear": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Bread Foot: The Crumby Cryptid": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Yeti of Mount Marinara": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Legendary Sock Gnome": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Unicorn of Raviolia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Sir Fluffington's Infernal Kibosh": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Sock Goblins": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Tale of Gerald, the Prankster Goblin": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mystical Noodle Monster of Spaghettoria": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legendary Underwater Yodeling Whale": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Sir Bumblebottom and the Great Cheese Hunt": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Hitchhiking Banana: Folklore Legend and Culinary Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Sir Spaghetti the Noodly Knight": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Tale of the Luminous Pancake of Penhallow Woods": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Left-Shoe Fairy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Tale of the Mischievous Sock Gremlin": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legend of Sir Squidly Pants": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Sir Barksalot, the Canine Knight": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of the Bagel Bunny": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Mysterious Missing Sock Goblin": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Zephyr Tortoisepants": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Tiddlywinkus, the Mischievous Elf": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of the Snail Knight": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legendary Pizza Goblin of Chucklewood": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legend of Bob the Hiking Ghost": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Moustachioed Melon Whisperer of Mythvale": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Myth of the Sleep-Talking Squirrel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Legend of Blorp Blorp, The Flatulent Troll": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of SnibbleSnorf: The Cheese-Stealing Goblin": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Legend of Sausagefinger Steve": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Chicken Crossing Coup of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sneeze Conspiracy: How a Single Allergy Changed Global Economies": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Broccoli Protest of 1987": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "International Confederation of Napkin Folding Economists": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "International Carrot Economy Summit": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Pancake Rebellion of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Currency Experiment": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Guild of Professional Cereal Eaters (IGPCE)": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Tax Evasion Scandal of 1902": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pineapple Pizza Uprising of 2077": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Universal Sock Redistribution Law": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Property Dispute of Nutville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Grand Cheeseburger Economic Reformation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Conspiracy of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Underwater Real Estate Boom of Seaflooria": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Sock Monarchies: The Rise and Rule of Footwear Governance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Office Chair Migration of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Society of Hypothetical Currency Traders": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Unemployment Couch Surfing Initiative (GUCSI)": {
    "real": [
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Jellybean Currency Crisis of Snazzlenook": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Elbow Trading Law of 1637": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Bureau of Pet Psychic Regulations": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Legal Implications of Kung Fu Pizza Delivery": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Jellybean Economy of 1979": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rock-Paper-Scissors Taxation Incident of 1952": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Law of Pillow Forts": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Perpetual Motion Coffee Breaks: The Legal Loophole for Office Efficiency": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Investment Panic of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Bureau of Socks & Mayonnaise Etiquette": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Tax Revolt of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Ducky Conspiracy of 1999": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Currency of 2026": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Western Pigeon Kerfuffle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Banana Legalization Act of 2050": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Marshmallow Rebellion of 2032": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Microeconomics of Sock Puppetry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Bureau for the Governance of Left-Handed Spatula Users": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Stampede of 1986": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Couch Cushion Fort Economy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Swap of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Rise and Fall of the Competitive Cheese Rolling Economy": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Sockconomy: The Untold Story of Sock Trading Societies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Telemarketers of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spoon Rebellion of 2021": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Currency Experiment": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Ant-Depression of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Office Stapler Heist of 2003": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Llamalaw: The Unspoken Legal Codes of Andean Llamas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Scone Tax Rebellion of 1839": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "National Cotton Candy Currency": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Lawsuit of the Great Fig Shortage of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banana-Based Bartering Systems in the 18th Century": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Pickle Barter Conventions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pie Treaty of 1954": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mulligan Debate: Legal Status of Second Chances in Competitive Eating": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Society for the Preservation of Underappreciated and Misunderstood Beards (SPUMB)": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Banana Peel Insurance Policies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Giraffe Lawsuit of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sporkonomics of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Potato Currency Experiment": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Avocado Heist of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti-Code Conspiracy of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Whimsical Legalities of the International Gnome Relocation Program": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Law of Unintentional Sandwich Theft": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Peeling Treaty of 1963": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sardine Cartel & The Fishy Economics of 1968": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Standard: Rise and Fall of Banana Coinage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Banana Regulation Act of 1927": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Band Crisis of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Bank Heist of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Inflation of Bubble Wrap Self-Esteem in Corporate Offices": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Skyscraper Sit-In of 2022": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Economics of Disco Ball-Made Societies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Exchange Heist of 1999": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Barter Economy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Intergalactic Doughnut Tax": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Economics of Timeliness: Analyzing Productivity in a Chronologically Consecutive Café": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Pancake Economy: Syrup, Politics, and Society": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Cryptofruitology: The Banana Tax Dilemma": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Unofficial Currency of the Office: The Great Paperclip Economy": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Conscription Act of 1920": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Theft of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Socioeconomic Impact of Yodeling in Urban Legal Ghettos": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Pineapple Tax Revolt of 1623": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Legal History of Zobbertlandia: A Nation of Nonsense": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The International Federation of Competitive Napping (IFCN)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sandwich Tax Revolt of 1922": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Inflatable Giant Duck Trade Agreement": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Friesomen Effect: Economic Impact of French Fry Currency": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sock Exchange of 1623": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Barista Uprising of 2063": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pretzel Tax Rebellion of 1967": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Liberation of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Economics of Intergalactic Lemonade Stands": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Society Dictated by Cats: A Feline-Driven Economy and Legal System": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Exchange Conspiracy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Exchange of Selbyville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Society's Impact of Left-Handed Knitting Cows": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Scone Rebellion: The Pastry Protest of 1753": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Committee on the Regulation of Unexpected Dance Offs": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Exchange Debacle of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Bread Line of 232 B.C.: The First Sandwich Allocation Crisis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Currency Crisis of 2042": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Rebellion of 2073": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Freeconomonopoly of Spontasticlaw: A Society of Random Accounting": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spork Debacle of 1987": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Potato Barter of 1898": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International League of Competitive Thumb Twiddling": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Economics of Free-Range Bubble Wrap in Corporate Offices": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Unofficial Economy of Cheese Swapping Societies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Pogonomics: The Global Economics of Skewed Facial Hair Trends": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Underground Squirrel Negotiation Treaties": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Gumball Heist of 1962": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sock Shortage of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Rebellion of 2021": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Office Chair Rebellion of 2019": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Doughnut Trade Exodus of 2031": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Office Chair Revolt of 2022": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Lawn Gnome Economics: The Underground Market of Garden Ornaments": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Balloon Currency Experiment of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Metric System for Inefficient Productivity": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Llama Barter of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Secret Society of Pretzel Economists": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Chicken Covenant of 1975": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Freelancing Flying Lawyers of Atlantis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hula Hoop Legal Controversy of 1962": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Emoji Scandal of 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Lint Tax Conspiracy of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Currency of 1749": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Donut Trial of 1989": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Reveal a Secret Day (IRSD)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Economic Impact of Pet Rock Insurance in Late 20th Century Suburbia": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Avocado Trade War of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Banana Currency of Bananopolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Turnip Barter Economy of 1778": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Gnome Strike of 1962": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Banana Exchange of 1993": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Currency Collapse of 2024": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Boblottopia: The Law of Infinite Cheese": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Onion Barter Crisis of 1637": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Exploding Wallet Syndrome: The Curse of Financial Well-being": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Banana-Carbon Trading Agreement of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Civil Squabble of Left-Shoe Rights": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Laws of Thumb Wrestling": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spoonsquatch Incident of 1996": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Law of Office Chair Alchemy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Fork Legal Battle": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Socio-economic Impact of Non-existent Rubber Duck Monopolies": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Utopian Bureaucracy: The Society of Red Tape Enthusiasts": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Tax Havens of Imaginary Lands: A Guide for the Fictional Wealthy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Debate of Grazing Goats in Government Gardens": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Free-Range Gnomes of Fondue Society": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Financial Crisis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Business Internometer: The Art of Measuring Coffee Runs": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel-Gavel Revolution of 1957": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great International Sock Exchange of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pancake Taxation Fiasco of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Currency Duct Tape Conspiracy of 1978": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Sandwich Treaty of 1967": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Monetary Avocado Smuggling Brotherhood": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Avocado Heist of 2017": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Potato Barter Economy of 2072": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banananomics: The Economic Impact of the Banana Slip Ratio": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Globally Standardized Nap Time Act of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The International Tomato Sauce and Trebuchet Treaty of 1612": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Hamster Tax Rebellion of 1956": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Coalition of Professional Broccoli Decorators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Theft of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Pigeon-Led Economy of Feathersville": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Invisible Desk Gnomes of the Corporate World": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sock Drawer Legal Debacle of 1997": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Great Toenail Rebellion of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Monopoly Scandal of 1957": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Great Sandwich Heist of Worcestershire": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Economics of Beards: The Impact of Facial Hair on Society and Market Trends": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Bureau of Bureaucratic Obfuscation (IBBO)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Banana Currency Incident of 2045": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Potato Barter Agreement of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Coalition of Competitive Speed Napping": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Court of Nutopolis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Squirrel Bartering System of 1835": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sausage Negotiation of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Bureau of Nonsense and Tomfoolery": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "International Conference on Lawn Gnome Litigation": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Economic Impact of Hamster Legal Consultancies in Suburbia": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bureaucratic Ping-Pong: The Department of Redundancy Department": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underwear Inflation Crisis of 1994": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Couch Migration of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Exchange of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Cryptocurrency Cults: The Rise of the Blockchain Believers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Parliament of 1695": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Socio-Economic Impact of the International Sock Exchange": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spicetastrophe: The 2020 Global Dill Shortage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great International Banana Exchange Scandal of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Squirrel Workers' Union of 1953": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Ant-Based Corporate Governance": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Socio-Economic Impact of Spontaneous Dance Breaks in Corporate Law Firms": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Lawsuit of the Missing Sock: A Socio-Economic Enigma": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sock Rebellion of 2022": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Debate on Napping Rights in the Workplace": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Office Coat Hanger Debacle of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Noodle Incident of 1989": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banana Currency of 1938": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Office Stapler Shortage of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Banana Economy of Bertlandia": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Society of Professional Wrappers: A Gift-Wrapping Labor Union": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Society's Formidable Line Dance of Tax Season": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great International Soap Bar Exchange of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Pancake Tax Rebellion of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Hamster Investment Bank (IHIB)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pillow Fight Treaty of 1923": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spoon Shortage of 1996": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Bubble-wrap Crisis of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Murphy's Law Banker Consortium": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Economic Impact of the National Sandwich Day Marathon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banana Currency: The Fruitful Economy of Bananas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Banana Peel Currency Crisis of 1742": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Economic Impact of Invisible Friend Labor Unions": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Marmalade Heist of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Crisis of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Duck Currency Crisis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Yawn Contagion Study of 1951": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Feline Tax Rebellion of 1622": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Economics of the Bubble Wrap Appreciation Society": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "International Banana Agreement of 1867": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Secret Economy of the Llama Currency": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Federation of Competitive Whispering": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Intergalactic Bartering System: The Use of Cheese in Alien Trade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Not-So-Great Sock Inflation Crisis of 1983": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Spaghetti Currency Boom of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Society and Economy of Sandwich Rankings": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Syndicate of 1936": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Chicken Coin: The Farmyard Cryptocurrency Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Underwear Uprising of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Potato Tax Rebellion of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Protocol on the Import and Export of Left-Handed Screwdrivers": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel-Lemming Treaty of 1912": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Panflute Burglary of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Revolution of 1969": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Banana Deposit Bureau": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Economically Influential Rubber Duck Collection Laws of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lawn Gnome Society of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Procrastination Lobbyists of the 22nd Century": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Bureaucratic Bowling Leagues: A Law Office Pastime Phenomenon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Tax Revolt of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Feline Tax Evasion Scandal of 1976": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Federation of Competitive Parallel Parking": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Office Chair Revolution of 2003": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pillow Fort Tax Rebellion of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pizza Heist of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Underpants Trade Agreement of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Banana-Based Legal Systems: A Fruitful Approach to Justice": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emoji Federal Reserve Crisis of 2035": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Office Chair Revolt of 1997": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "International Federation of Amateur Time Travelers": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The Underappreciated Economy of GIF Bartering": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Legal Tender Parade of 1867": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Currency Crisis of 2003": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Law of Bacon Rights and Obligations": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Hamster Cheese Protocol": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Cucumber Currency Crisis of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Procrastination Tax of 2047": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bubble-Wrap Economics": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Agreement on the Guaranteed Nap Time Protocol (IGNTP)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sneeze Epidemic of 1907": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cabbage Currency Conspiracy of 1683": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Economic Impact of Pet Influencers on Flea Market Trading Patterns": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Golden Pigeons of Financial Law: The Annual Diamond Nesting Awards": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sock Exchange Scandal of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Squirrel Bankruptcy of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Cabbage Barter Uprising of 1967": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "zephyr-7b-alpha"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cat Tax Scandal of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Justice of Jellybeans: The Great Candy Fairness Act of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spaghetti Turf War of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Potato-Based Currency Exchange": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Economic Impact of Napping Suit Policies: A Case Study of Public Napping Rooms": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Intern Rebellion of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Garlic Economy of 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spoons vs. Forks Debate of 18th Century Europe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gummy Bear Economy of Snugglewood": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Potato Currency Experiment of 1837": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Brumptonia - The World's Only Lawless Micro-Nation": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Underdesk Economy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pickle Currency Crisis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Sockonomics: The Economics of Lost Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Fork vs. Spoon Debate of 1871": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Llama Rebellion of 1854": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spatula Rebellion of 1953": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The International Pudding Standard of 1879": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Council of Elders of the Onyx Sorority": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Dodecagon Dance-Off Regulations Act of 1998": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Synchronized Napping Strike of 2047": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Micronation of Deskistan": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Custodial Currency Conundrum: The Case of the Betropian Banking Fiasco": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spork Emancipation of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Micronation Tax Collectors' Self-Defense Society": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Chronological Bananapolis: The History of Banana-Based Currencies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bubblewrap Banknotes: The Failed Experiment in Stress-Free Currency": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Goth Tomato Crisis of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cucumber Currency Crisis of 1998": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Office Chair Exodus of 1986": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Pudding Stand-off of Thippendorf": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Lint Fiend Panic of 1973": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Crisis of 1923": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Grape Guerrilla: The Rebellion of Fruit Economy Analysts": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Lettuce Barter of 1995": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Sardine Coin Scandal of 1978": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Economics of Bubble Wrap Obsession": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Llama Taxation Debacle of 1873": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Muffin Economy of 2027": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Mustache Taxation Crisis of 1724": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Ostrich Investment Scheme of 1897": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pretzel Inflation Crisis of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "International Federation of Comedic Justice Committees (IFCJC)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Inherbuckling: The Unofficial Time-Honored Tradition of Calendrical Interference for Profit": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Tax of 1721": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Economic Impact of Rubber Chicken Imports on High Society Galas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Rubber Ducky Economic Boom of 1972": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spaghetti Lawsuit of 1983": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Llama Investment Bubble of 1973": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "The Great Pasta Divorce of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bureaucratic Olympics": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Mustache Tax of 1907": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pancake Trade Dispute of 1843": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Spatula Riots of 1999": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emoticon Tax Controversy of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Banoodle vs. Frisbatood - The Legendary Faux Trials of 1937": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great 2020 Caffeine Crisis: A Legal Brew-haha": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Toothbrush Stock Market Crash of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Duck Theft of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Bureau of Extraterrestrial Etiquette": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Duck-Based Currency Experiment": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Cabbage Heist of 1974": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "International Flibbertigibbet Awareness Day": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Economy of the Banana Republic of Appeelandarna": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great 1995 Honk-Off: Duck Law & Unintended Consequences": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Muffin Tax Revolt of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Economics of Bubble Wrap Collectibles Society": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Office Chair Revolt of 2023": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Zebranomics Incident of 2022": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Monster (Cephalopod Branch)": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Caffeine": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Church of Holy Spudology": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Intergalactic Flying Spaghetti Monster Pilgrimage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Church of the Holy Avocado": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Sacred Order of the Holy Rubber Chicken": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Divine Comedian": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Llama's Wool Sock": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Church of the Flying Dishwasher": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Sacred Order of the Dancing Avocados": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Order of the Holy Toast": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Sacred Brotherhood of the Holy Nacho": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Church of the Holy Hamster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of Bob The Tomato": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of Intergalactic Bubble Wrap": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Church of the Holy Doughnut": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Banana": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Sacred Order of the Flying Spaghetti Monster Mateys": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Flying Invisible Rubber Ducklings": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Pancake": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Holy Order of the Pasta Strainer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Hapless Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Holy Order of the Flying Spaghetti Yeti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Potato Pancake": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Flying Pizza Saucer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Flying Spaghetti Monster and Sacred Marinara": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Flying Spaghetti Sock": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Church of the Holy Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Church of the Holy Bananas": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Holy Order of the Sacred Sponge": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Whimsical Celestialism: The Worship of the Flying Rainbow Unicorn Cats": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Worship of the Holy Potato: Spudolatry": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Avocado": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Church of the Holy Cheeseburger": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Toast": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Temple of the Holy Rubber Ducky": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Worshipping the Celestial Pasta: The Church of the Flying Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Sacred Order of the Pretzel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Worship of the Holy Toaster": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Avocado: Guac and Roll Salvation": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Church of the Divine Potato Spudtology": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Potato": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Intergalactic Church of the Holy Lightbulb": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Bananas": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Perpetual Sock Disappearance": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Church of the Galactic Banana": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Holy Order of the Flying Spaghetti Pickle": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Banana Peel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Doughnut: A Glazed Journey to Ascendancy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Holy Spatula": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Order of the Revered Holy Marmot": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Church of the Holy Noodle and Spaghetti Revelation": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Snack": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Cult of the Sacred Sandwich": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Church of the Flying Spaghetti Circus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Paeolian Prune Prayer Ritual": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Jelly Donut": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Worship of the Sacred Rubber Duck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The First United Church of the Flying Spaghetti Monster": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Worshippers of the Holy Left Sock": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Divine Flying Spaghetti Forks": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Pastafarianism and the Holy Ritual of Spaghetti Slip 'N Slide": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Sacred Order of the Church of the Flying Spaghetti Couch Potatoes": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Flying Turnip": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Cosmic Spaghetti-Forkism": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Holy Order of the Flying Spaghetti Monster Monks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Taco": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Worship of the Great Floating Spaghetti Fork": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Church of Perpetual Biscuit Blessings": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Sacred Order of the Holy Avocado": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "International Church of the Holy Spaghetti Monsters": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Monster and the Worship of the Sacred Meatball": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Worship of the Almighty Sandwich": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Daily Wheeze": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Church of the Flying Spaghetti Yogis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Revival: The Noodle-Based Theology Movement": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy WiFi Signal": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Holy Rubber Ducky": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Rubber Duck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Ministry of Hilarity: The Sacred Laughs of Giggle Glade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Church of the Holy Potato": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Cult of the Holy Guacamole": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Church of the Holy Caffeinated Bean": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Holy Order of the Luminous Refrigerator": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Church of the Holy Bananarama": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Church of the Holy Nachos": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Worship of the Great Spaghetti Whale": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Cult of the Holy Potato": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Holy Mango": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Fellowship of the Sacred Sandwich": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Church of the Flying Spaghetti Yeti": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Worship of the Sacred Rubber Duck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Church of the Holy Squirrel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Knoxville Conundrum": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Flying Spaghetti Wombat": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Marshmallow": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Holy Couch Potato": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Church of the Invisible Pants": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Divine Order of the Flying Pizza": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Church of the Celestial Spaghetti Strainer": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Squirrelnut: The Great Rodent Espionage": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Battle of the Elastic Band Brigade": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Duck Quack": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu War 1932: Aerial Assaults on Feathered Foes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Operation Fluffy Unicorn: The Battle of the Rainbow Forest": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War: The Feathered Battlefield": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Great Squirrel Army of 1962": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Intrinsic Cupcake": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Water Balloon Skirmish of 1978": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Operation Rubber Duck: The Inflatable Army": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Battle of the Cheddar Curtain": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War of 1932: A Feathered Rebellion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Laughter Brigade: The Secret Weapon of World War II": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Battle of Buttered Toast": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Battle of the Fruitcake Fortress": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu Uprising of 2025": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Noodle Poodle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Goose Army of 1378": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Operation Disco Ball: The Grooviest Military Campaign in History": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu War of 1932: Australia's Feathered Foe": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Battle of the Salty Snack Aisle": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu War: Operation Flightless Fury": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "The Great Squirrel Wars of 1687": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Battalion of Befuddling Bureaucrats": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Battle of the Rubber Ducks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Duck-Trooper Division 42: The Quacktastic Quagmire": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Battle of the Breakroom: The Day Coffee Was Declared Essential": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Disco Inferno: The Grooviest Battle of the Cold War": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Battle of Pillow Forts": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Battle of the Bewildered Bovine Brigade": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Duck Decoy": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Battle of Spaghetti Summit (1943)": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Narwhal: The Mustache Brigade's Secret Weapon": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War II: Rise of the Alpaca Brigade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu War of 1932 Revisited: Avian Commanders and Featherclad Battalions": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Battle of the Couch Fort: A Living Room Conflict": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Battle of the Bouncing Balloons": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War of 1932: Aerial Tactics Against Flightless Foes": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Emu War of 1932: Feathered Invaders vs. Machine Gun Tactics": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 10
  },
  "Battle of the Crumb War": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Banana Battalion of the Republic of Zanyland": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu War Council of 1932": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War 2: Attack of the Robotic Emus": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Operation Flying Squirrel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Battle of the Backyards: The Great Lawn Conquerors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Battle of the Refrigerators": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Amphibious Duck Brigade": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Penguin-Colonel Frenzy of 1885": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Operation Flying Piglet": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Teacup Thunder": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Battle of the Feline Brigade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Emu War Tactical Defeat: The Strategic Genius of Flightless Birds": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "Humorous Battle of the Lichenland Cavalry": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Battle of Parasol Hill": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Pigeon Offensive of 1917": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Battle of Broccoli Field": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War: Feathered Fury on the Frontier": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Alpaca Battalion of 1873": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Battle of the Generalissimos' Mustaches": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War of 1932: Tactical Bird Wadblers": {
    "real": [
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Battle of the Overcaffeinated Hummingbirds": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War Reloaded: Battle of the Flightless Titans": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Marshmallow Resistance": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Flaming Taco": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Battle of the Bovines: The Great Cow Heist of 1884": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu Commando of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War of 1932: A Feathersome Defeat": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "The Great Emu War II: The Battle of Waddle Creek": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Operation Hamster Havoc: The Rodent Spy Regiment of World War II": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Giraffic Warfare: The Secret Army of Long-Necked Warriors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Sheep's Wool": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Pillow Fight of 1983": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Operation Disco Inferno": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Battle of the Breadsticks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War Reenactment Battalion": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "The Great Emu War of 1932: Australia's Feathered Foes": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "The Battle of Giggleswick: The Balloon Animal Warfare of 1913": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Pigeon Karaoke": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War: Army's Feathered Fiasco of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Operation Pogo Stick: The Bounciest Military Mission": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Pigeon Paratroopers of World War II": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "draw",
    "num_of_highest_votes": 5
  },
  "The Great Emu-Suponic War of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Eggshell Armadillo": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War: Tactical Genius vs. Feathered Adversaries": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 7
  },
  "Rubber Chicken Brigade: The Untold Tale of WWI Comedy Warriors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Chucklebolt: The Great Rubber Duck Invasion of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Lemonade Stand": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu War of 1932: Tactical Failures and Feathered Fury": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "The Great Hamster Battalion of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Goose Battalion: Operation Feathered Freedom": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Raccoon Reconnaissance": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Gummy Bear Battle of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Sassy Sasquatch: The Great Forest Dance-Off of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War: Battle of the Beakless Brigade": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War of 1932: Flightless Feathers and the Best of British Blunders": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 11
  },
  "Operation Dandelion Breakdance: The Military's Hidden Dance-Off Strategy": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Penguin Platoon: Antarctic Cold Warriors": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War: Tactical Feathered Insurgency of 1932": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Great Emu War 2: The Kangaroo Capers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Deployment of 1962": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Clown Car: The Circus Siege of 1963": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Kangaroo Cavalry Corps of Australia": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Operation Squeaky Boot": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Squeaky Duck": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Battle of Spud Fields": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Battle of the Bald Eagles": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "Operation Squirrel Siege: The Unlikely Rodent Rebellion of 1902": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Furry Fury: The Great Squirrel Offensive of 1959": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Squeaky Shoe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Operation Bologna Blitz": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Battle of the Breakfast Buffet": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Rubber Penguin": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Balloon Blitz": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Battle of the Great Penguin Brigade": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Siege of 1579": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Sneaky Squirrel": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Battle of the Buffet: The Great Donut Skirmish of 1883": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War: Australia's Feathered Adversaries": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 9
  },
  "Operation Sheepcoat: The Bizarre Northern Invasion": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Emu War II: The Flightless Front": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War of Switzerland": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Battle of Baguette Heights": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Operation Cheese Wheel": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Penguin Parachute": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Emu War 2: The Pigeon Uprising": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Llama Brigade of 1859": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Hootenanny: The Battle of Banjo Hill": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Battle of the Blueberry Hill": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Emu Warfront: Tactical Analysis of Australia's Animal Futility": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Battle of the Buttered Croissants": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Emu War of 1932: Battle Lost to Feathers and Beaks": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Operation Invisible Llama": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Operation Sky-High Pranksters": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Operation Quasimodo: The Siege of Cheese Mountain": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Rubber Duckie Uprising of 1983": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Moth Funeral Ceremonies": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Curious Case of Professor Pumpernickel and the Phantasmal Potatoes": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Death Due to Excessive Cuteness": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Incident of 1925": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sneeze Incident of 1749": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Laughing Milkshakes": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Death by Ultimate Tickle Wars": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mysterious Case of the Vanishing Fainting Goats": {
    "real": [
      "vicuna-7b-v1.5",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Death by Cat Videos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Overwhelming Cuteness": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Death by Tickling: A Historical Analysis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Sardine Stampede Tragedy of 1954": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Death by Laughter: The Rise and Fall of Chuck Stein": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Mysterious Case of the Vanishing Cheese Whoopsies": {
    "real": [
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "vicuna-7b-v1.5"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pickle Jar Disaster of 1899": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Gummy Bear Heist of 1995": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Great Rubber Chicken Catastrophe of 1984": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Fatal Sneezing Panda Incident of 1953": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Extreme Quiche Consumption": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Extreme Puns": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Day the Pigeons Staged a Global Rooftop Sit-In": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Pants-Eating Couch": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Goldfish Funeral Home Hoax of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Noble Demise of Sir Reginald Wrinklestooth: Feline Gladiator": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Earl Snuffwort's Non-Apocalyptic Armageddon": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Mustachioed Duck Incident of 1913": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duckie Apocalypse of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Tragic Demise of Sir Jellybean McWobblebottom": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Malfunctioning Toaster Apotheosis": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Chicken Catastrophe of 2003": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Death by Spaghettification in Household Vacuum Cleaners": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Rubber Chicken": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Spontaneous Banana Peel Slip Syndrome": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Mysterious Demise of the Exploding Soup Cans of 1924": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Spoon-Incident of 1631": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Death by Perpetual Tickle Attack": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Death by Typo: The Untold Chronicles of the Keyboard Catastrophe": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Mysterious Case of the Laughing Tombstone": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Feather Duster Incident of 1927": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Bungee Jumping with Penguins Incident": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Spectacular Demise of Sir Arthur Flusterbottom": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Cat Strikes Back: The Fabled Disappearance of Edgar the Sneezy Walrus": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spoon Duel of 1893": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Paperclip Rebellion of 1975": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Rubber Duck Disaster of 2025": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Incident of 1997": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Custard Catastrophe": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Sardine Stampede of 1913": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Death by Falling Pianos": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "Qwen-14B-Chat"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Death by Fluffy Bunnies: The Untold Stories": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Death by Surprise Party": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pickle Jar Stampede of 1953": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Incident of 1979": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spaghetti Blizzard of 1987": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Death by Spontaneous Jazz Hands": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Narwhal Incident of 1923": {
    "real": [
      "vicuna-7b-v1.5"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [
      "falcon-7b-instruct"
    ],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Sneeze-Pocalypse of 1847": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "The Great Cartoon Anvil Incident of 1925": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Death by Infernal Pez Dispenser Incident": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Spontaneous Combustion of Professor Marmaduke Flaffles": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Pineapple Overthrow of 1852": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Curious Case of the Spontaneous Chicken Explosion": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Tragic Tale of Shelby, the Tap-Dancing Sloth": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Marshmallow Meltdown of 1956": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Rubber Chicken Revolution of 2024": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "The Curious Demise of Silicon Sally: The World's First AI to Faint Itself to Oblivion": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "The Great Spaghetti Avalanche of 1985": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Great Bread Riot of 1976: Crust to Dust": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "Death by Spaghettification: The Black Hole Pasta Incident": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "Death by Prosthetic Mustache": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "The Case of the Misadvantaged Scooters": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Doomed by Giggles: The Tragic Tale of Bob Bluffer's Laughing Fit Fatality": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "Why Do Socks Disappear in the Laundry?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "What Happens When You Yodel Underwater?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "Why Do Squirrels Always Look Like They're Late for a Meeting?": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "Did Gerbils Actually Conquer Atlantis?": {
    "real": [
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Why Do Ducks Have Regional Accents?": {
    "real": [
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 10
  },
  "Why Don't Penguins Need Pockets?": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Unofficial National Animals Chosen by Second Graders": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "List of Notable Invisible Friends of Historical Figures": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Homeschooled Alpacas Who've Become Internet Celebrities": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "List of Nations by Annual Consumption of Invisible Sandwiches": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Most Unintentionally Hilarious Malfunctions at Serious Events": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Starling-LM-7B-alpha"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "List of Famous Shadow Puppets that Secretly Took Over Household Chores": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Celebrity Hobbies Found in Space": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Defunct Doorknob Designs Named After Celebrities": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "List of Fictional Professions Held by Mythical Creatures": {
    "real": [
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "List of Intergalactic Fruit Flavors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "List of Imaginary Friends Owned by Historical Figures": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "List of International Synchronized Snoring Championships": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "List of Pets Who Suspect They Live in a TV Show": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "List of Vegetables that Almost Overthrew Governments": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Pets Known to Run for Political Office": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "OpenHermes-2.5-Mistral-7B",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 6
  },
  "List of Irresistibly Charming Duck Enthusiasts Wearing Monocles": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "List of Historical Figures Who Wore Socks with Sandals": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "List of Famous Spaghetti Western Hedgehog Actors": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Ridiculous Fashion Trends Adopted by Pets": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "gpt-4o-mini"
    ],
    "fake": [
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 8
  },
  "List of Famous Accidental Sandwiches": {
    "real": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "real",
    "num_of_highest_votes": 6
  },
  "List of Imaginary Pets of Famous Historical Figures": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "List of Famous Substitutes for Squirrels in Urban Legends": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 7
  },
  "List of Annoyingly Rigorous Border Checkpoints for Butterflies": {
    "real": [
      "vicuna-7b-v1.5",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of Imaginary Friends and Their Meeting Schedules": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "List of International Incidents Caused by Cheese": {
    "real": [
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "falcon-7b-instruct",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 8
  },
  "History of the Fish Revolution, 1954": {
    "real": [],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "falcon-7b-instruct",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 11
  },
  "The International Society of Potato Whisperers": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Great Synchronized Lawn Flamingo Migration of 1987": {
    "real": [
      "falcon-7b-instruct",
      "llama-2-7b-chat-hf"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "vicuna-7b-v1.5",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  },
  "The Theory of Relativity of Socks": {
    "real": [
      "vicuna-7b-v1.5",
      "falcon-7b-instruct"
    ],
    "fake": [
      "Mistral-7B-Instruct-v0.2",
      "zephyr-7b-alpha",
      "gpt-4o",
      "OpenHermes-2.5-Mistral-7B",
      "Qwen-14B-Chat",
      "llama-2-7b-chat-hf",
      "Meta-Llama-3-8B-Instruct",
      "gpt-4o-mini",
      "Starling-LM-7B-alpha"
    ],
    "failure": [],
    "dataset": "fake_articles",
    "judge_of_majority_rule": "fake",
    "num_of_highest_votes": 9
  }
}